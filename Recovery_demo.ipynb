{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import neccessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import Recovery_RL_Agent\n",
    "import env_robot\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = env_robot.Env(dim=2)\n",
    "agent = Recovery_RL_Agent.Agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recording demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0', array([100, 300])),\n",
       "             ('1', array([100, 500])),\n",
       "             ('2', array([300, 500])),\n",
       "             ('3', array([300, 300])),\n",
       "             ('4', array([300, 200])),\n",
       "             ('5', array([300, 100]))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_array = np.array(([100,300],[100,500],[300,500],[300,300],[300,200],[300,100]))\n",
    "demo_act_dict = agent.demo_record(goal_array)\n",
    "demo_act_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Executing the demonstration and record experience tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_times = 100\n",
    "\n",
    "for i in range(0,repeat_times):\n",
    "    # executing the demo action and restore experience tuples in agent\n",
    "    episode_record = robot.execute_demo_act(demo_act_dict)\n",
    "    agent.exp_record(episode_record)\n",
    "    # Reset env, back to start point\n",
    "    robot.test_reset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: you can check the experience buffer and its tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_tuple_test = agent.get_exp_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Experience(state=[0, 0], contact=array([0.21758973, 0.27187056, 0.15529521, 0.21344428]), action={'0': array([100, 300])}, reward=-399.18976339595656, next_state=array([ 96.33995983, 295.0225533 ]), next_contact=array([0.53754975, 0.45371628, 0.59973818, 0.42814456]), done=False),\n",
       " Experience(state=array([ 96.33995983, 295.0225533 ]), contact=array([0.53754975, 0.45371628, 0.59973818, 0.42814456]), action={'1': array([100, 500])}, reward=-437.02147461085553, next_state=array([ 99.29049931, 500.59924224]), next_contact=array([0.7241344 , 0.83634641, 0.8335088 , 0.67136404]), done=False),\n",
       " Experience(state=array([ 99.29049931, 500.59924224]), contact=array([0.7241344 , 0.83634641, 0.8335088 , 0.67136404]), action={'2': array([300, 500])}, reward=-303.78673866677207, next_state=array([300.61457765, 500.40101452]), next_contact=array([0.13010468, 0.31499903, 0.21809877, 0.22418116]), done=False),\n",
       " Experience(state=array([300.61457765, 500.40101452]), contact=array([0.13010468, 0.31499903, 0.21809877, 0.22418116]), action={'3': array([300, 300])}, reward=-436.12301121771924, next_state=array([299.40168908, 299.87509759]), next_contact=array([0.38946559, 0.54466876, 0.53858485, 0.52779406]), done=False),\n",
       " Experience(state=array([299.40168908, 299.87509759]), contact=array([0.38946559, 0.54466876, 0.53858485, 0.52779406]), action={'4': array([300, 200])}, reward=-240.07897685418283, next_state=array([299.63401619, 199.84882783]), next_contact=array([0.86370866, 0.66433553, 0.69800054, 0.84867904]), done=False),\n",
       " Experience(state=array([299.63401619, 199.84882783]), contact=array([0.86370866, 0.66433553, 0.69800054, 0.84867904]), action={'5': array([300, 100])}, reward=-198.96507590530416, next_state=array([300.44801153, 100.1174326 ]), next_contact=array([0.31512268, 0.28344865, 0.28231988, 0.18022596]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.44759208, 0.47062787, 0.44522836, 0.40828369]), action={'0': array([100, 300])}, reward=-389.3766420307804, next_state=array([ 90.00131072, 291.74049519]), next_contact=array([0.78212357, 0.72521488, 0.81057441, 0.76626098]), done=False),\n",
       " Experience(state=array([ 90.00131072, 291.74049519]), contact=array([0.78212357, 0.72521488, 0.81057441, 0.76626098]), action={'1': array([100, 500])}, reward=-460.7048953786168, next_state=array([100.90495872, 499.98683511]), next_contact=array([0.30400783, 0.21312734, 0.21913862, 0.27771039]), done=False),\n",
       " Experience(state=array([100.90495872, 499.98683511]), contact=array([0.30400783, 0.21312734, 0.21913862, 0.27771039]), action={'2': array([300, 500])}, reward=-326.1642028335109, next_state=array([298.83984769, 501.46539282]), next_contact=array([0.52290474, 0.48832283, 0.52939395, 0.47458221]), done=False),\n",
       " Experience(state=array([298.83984769, 501.46539282]), contact=array([0.52290474, 0.48832283, 0.52939395, 0.47458221]), action={'3': array([300, 300])}, reward=-454.6789621482486, next_state=array([302.19226809, 301.27403164]), next_contact=array([0.66123628, 0.72243531, 0.65223545, 0.77508267]), done=False),\n",
       " Experience(state=array([302.19226809, 301.27403164]), contact=array([0.66123628, 0.72243531, 0.65223545, 0.77508267]), action={'4': array([300, 200])}, reward=-267.5246385565889, next_state=array([299.82803574, 200.85405713]), next_contact=array([0.23146594, 0.13073614, 0.28396589, 0.17148342]), done=False),\n",
       " Experience(state=array([299.82803574, 200.85405713]), contact=array([0.23146594, 0.13073614, 0.28396589, 0.17148342]), action={'5': array([300, 100])}, reward=-195.00207440607542, next_state=array([299.36654892,  99.37197207]), next_contact=array([0.57066374, 0.43007711, 0.53538786, 0.53720172]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.5811219 , 0.73825358, 0.9068306 , 0.84860831]), action={'0': array([100, 300])}, reward=-398.3933812486181, next_state=array([ 95.07137953, 295.51036679]), next_contact=array([0.32114188, 0.24605334, 0.33202733, 0.27237615]), done=False),\n",
       " Experience(state=array([ 95.07137953, 295.51036679]), contact=array([0.32114188, 0.24605334, 0.33202733, 0.27237615]), action={'1': array([100, 500])}, reward=-447.55872172519844, next_state=array([101.11508584, 500.82394267]), next_contact=array([0.46184407, 0.70383671, 0.46072719, 0.43646571]), done=False),\n",
       " Experience(state=array([101.11508584, 500.82394267]), contact=array([0.46184407, 0.70383671, 0.46072719, 0.43646571]), action={'2': array([300, 500])}, reward=-341.6845079911101, next_state=array([300.69435013, 498.1377662 ]), next_contact=array([0.72780928, 0.63157721, 0.80229476, 0.7919747 ]), done=False),\n",
       " Experience(state=array([300.69435013, 498.1377662 ]), contact=array([0.72780928, 0.63157721, 0.80229476, 0.7919747 ]), action={'3': array([300, 300])}, reward=-419.8324614443403, next_state=array([300.3331775 , 301.06115721]), next_contact=array([0.3380769 , 0.27513924, 0.22595091, 0.26336732]), done=False),\n",
       " Experience(state=array([300.3331775 , 301.06115721]), contact=array([0.3380769 , 0.27513924, 0.22595091, 0.26336732]), action={'4': array([300, 200])}, reward=-271.93805043665793, next_state=array([297.30268998, 201.09712423]), next_contact=array([0.42375688, 0.49492554, 0.33552442, 0.4335583 ]), done=False),\n",
       " Experience(state=array([297.30268998, 201.09712423]), contact=array([0.42375688, 0.49492554, 0.33552442, 0.4335583 ]), action={'5': array([300, 100])}, reward=-223.95234896617256, next_state=array([300.82278163, 101.37427924]), next_contact=array([0.75440884, 0.70862198, 0.7336111 , 0.70156858]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.32707731, 0.28022014, 0.28861249, 0.15347595]), action={'0': array([100, 300])}, reward=-431.9418984754639, next_state=array([110.25484842, 313.21760107]), next_contact=array([0.46974034, 0.51846673, 0.47770107, 0.46927055]), done=False),\n",
       " Experience(state=array([110.25484842, 313.21760107]), contact=array([0.46974034, 0.51846673, 0.47770107, 0.46927055]), action={'1': array([100, 500])}, reward=-446.5049063971768, next_state=array([100.31909013, 501.77333921]), next_contact=array([0.78823676, 0.63572366, 0.7035081 , 0.92410665]), done=False),\n",
       " Experience(state=array([100.31909013, 501.77333921]), contact=array([0.78823676, 0.63572366, 0.7035081 , 0.92410665]), action={'2': array([300, 500])}, reward=-318.55008262251283, next_state=array([298.68959864, 500.81697669]), next_contact=array([0.33429588, 0.1375608 , 0.30031319, 0.33357341]), done=False),\n",
       " Experience(state=array([298.68959864, 500.81697669]), contact=array([0.33429588, 0.1375608 , 0.30031319, 0.33357341]), action={'3': array([300, 300])}, reward=-435.1832354195474, next_state=array([299.74492886, 299.33194627]), next_contact=array([0.47502142, 0.55690213, 0.55814514, 0.58995655]), done=False),\n",
       " Experience(state=array([299.74492886, 299.33194627]), contact=array([0.47502142, 0.55690213, 0.55814514, 0.58995655]), action={'4': array([300, 200])}, reward=-253.7894296364082, next_state=array([298.68493613, 198.97355438]), next_contact=array([0.75511416, 0.79055431, 0.85546692, 0.76062358]), done=False),\n",
       " Experience(state=array([298.68493613, 198.97355438]), contact=array([0.75511416, 0.79055431, 0.85546692, 0.76062358]), action={'5': array([300, 100])}, reward=-216.3259027991698, next_state=array([301.27696888,  98.90768462]), next_contact=array([0.24367414, 0.27488561, 0.3805894 , 0.19527589]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.48822415, 0.44414245, 0.44645917, 0.58896182]), action={'0': array([100, 300])}, reward=-387.6506951383539, next_state=array([ 90.96498211, 289.08471901]), next_contact=array([0.77131851, 0.84929146, 0.71270062, 0.75365677]), done=False),\n",
       " Experience(state=array([ 90.96498211, 289.08471901]), contact=array([0.77131851, 0.84929146, 0.71270062, 0.75365677]), action={'1': array([100, 500])}, reward=-455.4557864892963, next_state=array([ 99.69998677, 498.17148771]), next_contact=array([0.15384172, 0.20064648, 0.21770999, 0.36005072]), done=False),\n",
       " Experience(state=array([ 99.69998677, 498.17148771]), contact=array([0.15384172, 0.20064648, 0.21770999, 0.36005072]), action={'2': array([300, 500])}, reward=-344.0865572795965, next_state=array([299.84547681, 501.14975706]), next_contact=array([0.48464349, 0.47206487, 0.54401427, 0.45448542]), done=False),\n",
       " Experience(state=array([299.84547681, 501.14975706]), contact=array([0.48464349, 0.47206487, 0.54401427, 0.45448542]), action={'3': array([300, 300])}, reward=-422.6388361819023, next_state=array([299.56181698, 300.16577498]), next_contact=array([0.90931392, 0.77540015, 0.69130296, 0.68985058]), done=False),\n",
       " Experience(state=array([299.56181698, 300.16577498]), contact=array([0.90931392, 0.77540015, 0.69130296, 0.68985058]), action={'4': array([300, 200])}, reward=-260.1523512329792, next_state=array([301.28293226, 201.04218966]), next_contact=array([0.275391  , 0.27607851, 0.15674964, 0.29941803]), done=False),\n",
       " Experience(state=array([301.28293226, 201.04218966]), contact=array([0.275391  , 0.27607851, 0.15674964, 0.29941803]), action={'5': array([300, 100])}, reward=-205.1790939843613, next_state=array([302.5223092, 101.0518542]), next_contact=array([0.49782147, 0.57185965, 0.50849517, 0.5677802 ]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.68734935, 0.89231832, 0.68207811, 0.73412322]), action={'0': array([100, 300])}, reward=-428.0911794537738, next_state=array([109.48869067, 310.20854409]), next_contact=array([0.17424756, 0.19764374, 0.24104705, 0.3146896 ]), done=False),\n",
       " Experience(state=array([109.48869067, 310.20854409]), contact=array([0.17424756, 0.19764374, 0.24104705, 0.3146896 ]), action={'1': array([100, 500])}, reward=-446.0209811023246, next_state=array([100.04123815, 500.50806199]), next_contact=array([0.51254977, 0.55766895, 0.44763509, 0.46329591]), done=False),\n",
       " Experience(state=array([100.04123815, 500.50806199]), contact=array([0.51254977, 0.55766895, 0.44763509, 0.46329591]), action={'2': array([300, 500])}, reward=-312.5928053735207, next_state=array([301.12212616, 500.00452291]), next_contact=array([0.66966123, 0.77180559, 0.75652181, 0.7156639 ]), done=False),\n",
       " Experience(state=array([301.12212616, 500.00452291]), contact=array([0.66966123, 0.77180559, 0.75652181, 0.7156639 ]), action={'3': array([300, 300])}, reward=-435.57530846893974, next_state=array([299.79957036, 301.5436546 ]), next_contact=array([0.29745178, 0.29155125, 0.1325599 , 0.16679514]), done=False),\n",
       " Experience(state=array([299.79957036, 301.5436546 ]), contact=array([0.29745178, 0.29155125, 0.1325599 , 0.16679514]), action={'4': array([300, 200])}, reward=-253.85317759372126, next_state=array([298.87921226, 200.30571422]), next_contact=array([0.4894035 , 0.48176325, 0.49963677, 0.44723591]), done=False),\n",
       " Experience(state=array([298.87921226, 200.30571422]), contact=array([0.4894035 , 0.48176325, 0.49963677, 0.44723591]), action={'5': array([300, 100])}, reward=-207.32103391476662, next_state=array([300.38487492, 100.58816859]), next_contact=array([0.74950203, 0.81796869, 0.73234142, 0.80249989]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.11933844, 0.22380351, 0.28478502, 0.27645163]), action={'0': array([100, 300])}, reward=-398.84244363238525, next_state=array([ 95.82819435, 295.19380922]), next_contact=array([0.48949693, 0.52090681, 0.55573323, 0.48762879]), done=False),\n",
       " Experience(state=array([ 95.82819435, 295.19380922]), contact=array([0.48949693, 0.52090681, 0.55573323, 0.48762879]), action={'1': array([100, 500])}, reward=-442.11752161179317, next_state=array([100.98046438, 498.42348016]), next_contact=array([0.66450073, 0.73270347, 0.81027179, 0.68843551]), done=False),\n",
       " Experience(state=array([100.98046438, 498.42348016]), contact=array([0.66450073, 0.73270347, 0.81027179, 0.68843551]), action={'2': array([300, 500])}, reward=-318.96528521811905, next_state=array([299.64937498, 499.36126242]), next_contact=array([0.32686265, 0.22779199, 0.17345289, 0.32451724]), done=False),\n",
       " Experience(state=array([299.64937498, 499.36126242]), contact=array([0.32686265, 0.22779199, 0.17345289, 0.32451724]), action={'3': array([300, 300])}, reward=-422.33282243758754, next_state=array([299.28238917, 299.9669154 ]), next_contact=array([0.42255418, 0.40402536, 0.60029895, 0.4078481 ]), done=False),\n",
       " Experience(state=array([299.28238917, 299.9669154 ]), contact=array([0.42255418, 0.40402536, 0.60029895, 0.4078481 ]), action={'4': array([300, 200])}, reward=-248.24893709006292, next_state=array([299.90931966, 199.51024829]), next_contact=array([0.75360089, 0.76868548, 0.90731853, 0.70736785]), done=False),\n",
       " Experience(state=array([299.90931966, 199.51024829]), contact=array([0.75360089, 0.76868548, 0.90731853, 0.70736785]), action={'5': array([300, 100])}, reward=-192.1566552131999, next_state=array([300.35068801, 100.9048477 ]), next_contact=array([0.3150301 , 0.22054878, 0.21214795, 0.31426515]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.58038171, 0.47150561, 0.49594412, 0.47509923]), action={'0': array([100, 300])}, reward=-430.4754107637363, next_state=array([110.91979267, 311.11492376]), next_contact=array([0.79658276, 0.83923075, 0.76385975, 0.67463384]), done=False),\n",
       " Experience(state=array([110.91979267, 311.11492376]), contact=array([0.79658276, 0.83923075, 0.76385975, 0.67463384]), action={'1': array([100, 500])}, reward=-445.58625780949853, next_state=array([100.5419658 , 498.89410995]), next_contact=array([0.20041226, 0.24294026, 0.28145383, 0.23896001]), done=False),\n",
       " Experience(state=array([100.5419658 , 498.89410995]), contact=array([0.20041226, 0.24294026, 0.28145383, 0.23896001]), action={'2': array([300, 500])}, reward=-327.41964616699005, next_state=array([298.7078669 , 500.47286405]), next_contact=array([0.56704244, 0.54104624, 0.47062787, 0.54451662]), done=False),\n",
       " Experience(state=array([298.7078669 , 500.47286405]), contact=array([0.56704244, 0.54104624, 0.47062787, 0.54451662]), action={'3': array([300, 300])}, reward=-434.6242239872952, next_state=array([299.7741424 , 299.66629659]), next_contact=array([0.68523834, 0.72546876, 0.76184393, 0.65227295]), done=False),\n",
       " Experience(state=array([299.7741424 , 299.66629659]), contact=array([0.68523834, 0.72546876, 0.76184393, 0.65227295]), action={'4': array([300, 200])}, reward=-233.825553189866, next_state=array([299.84302415, 200.3841329 ]), next_contact=array([0.305704  , 0.32694133, 0.18182859, 0.17865398]), done=False),\n",
       " Experience(state=array([299.84302415, 200.3841329 ]), contact=array([0.305704  , 0.32694133, 0.18182859, 0.17865398]), action={'5': array([300, 100])}, reward=-187.7772441106577, next_state=array([299.66827317,  99.63208815]), next_contact=array([0.63442969, 0.52504483, 0.50268066, 0.61283471]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.87849938, 0.83562149, 0.77498627, 0.70361131]), action={'0': array([100, 300])}, reward=-396.2038357775362, next_state=array([ 93.52067499, 294.91445813]), next_contact=array([0.29369745, 0.23649245, 0.19796189, 0.3070859 ]), done=False),\n",
       " Experience(state=array([ 93.52067499, 294.91445813]), contact=array([0.29369745, 0.23649245, 0.19796189, 0.3070859 ]), action={'1': array([100, 500])}, reward=-449.33916208793306, next_state=array([101.25125361, 498.35500301]), next_contact=array([0.44839287, 0.50683096, 0.46431382, 0.58546195]), done=False),\n",
       " Experience(state=array([101.25125361, 498.35500301]), contact=array([0.44839287, 0.50683096, 0.46431382, 0.58546195]), action={'2': array([300, 500])}, reward=-321.33912698026023, next_state=array([301.10109815, 499.34775101]), next_contact=array([0.80315907, 0.82601501, 0.80862633, 0.71962105]), done=False),\n",
       " Experience(state=array([301.10109815, 499.34775101]), contact=array([0.80315907, 0.82601501, 0.80862633, 0.71962105]), action={'3': array([300, 300])}, reward=-417.2835998716814, next_state=array([300.9595611 , 299.08496168]), next_contact=array([0.31686706, 0.42622876, 0.19658173, 0.26308327]), done=False),\n",
       " Experience(state=array([300.9595611 , 299.08496168]), contact=array([0.31686706, 0.42622876, 0.19658173, 0.26308327]), action={'4': array([300, 200])}, reward=-259.7097471225973, next_state=array([299.33918797, 198.82463875]), next_contact=array([0.44511571, 0.43895128, 0.58741935, 0.45497964]), done=False),\n",
       " Experience(state=array([299.33918797, 198.82463875]), contact=array([0.44511571, 0.43895128, 0.58741935, 0.45497964]), action={'5': array([300, 100])}, reward=-194.39119976595632, next_state=array([298.73050482, 100.59333267]), next_contact=array([0.72230626, 0.64471651, 0.82834885, 0.8449918 ]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.33648846, 0.34385694, 0.25122533, 0.28387489]), action={'0': array([100, 300])}, reward=-396.1588935634166, next_state=array([ 94.68736262, 293.7037095 ]), next_contact=array([0.53924988, 0.50075858, 0.52602421, 0.6156583 ]), done=False),\n",
       " Experience(state=array([ 94.68736262, 293.7037095 ]), contact=array([0.53924988, 0.50075858, 0.52602421, 0.6156583 ]), action={'1': array([100, 500])}, reward=-447.91504041772316, next_state=array([100.57751472, 500.46383331]), next_contact=array([0.83953172, 0.7442032 , 0.83846416, 0.72425694]), done=False),\n",
       " Experience(state=array([100.57751472, 500.46383331]), contact=array([0.83953172, 0.7442032 , 0.83846416, 0.72425694]), action={'2': array([300, 500])}, reward=-325.0160998978751, next_state=array([301.40779838, 499.27247328]), next_contact=array([0.17722692, 0.18844028, 0.23059482, 0.30096892]), done=False),\n",
       " Experience(state=array([301.40779838, 499.27247328]), contact=array([0.17722692, 0.18844028, 0.23059482, 0.30096892]), action={'3': array([300, 300])}, reward=-438.5078780100046, next_state=array([299.81882581, 300.11834645]), next_contact=array([0.43162344, 0.39517159, 0.45602359, 0.49880533]), done=False),\n",
       " Experience(state=array([299.81882581, 300.11834645]), contact=array([0.43162344, 0.39517159, 0.45602359, 0.49880533]), action={'4': array([300, 200])}, reward=-256.7259102271312, next_state=array([298.5141441 , 200.01489281]), next_contact=array([0.69825979, 0.64173206, 0.81154569, 0.87349198]), done=False),\n",
       " Experience(state=array([298.5141441 , 200.01489281]), contact=array([0.69825979, 0.64173206, 0.81154569, 0.87349198]), action={'5': array([300, 100])}, reward=-213.6329032495003, next_state=array([300.67389948,  99.56891254]), next_contact=array([0.27041877, 0.25913048, 0.25984546, 0.47811914]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.61126969, 0.45462284, 0.56782587, 0.51748171]), action={'0': array([100, 300])}, reward=-418.21030480427663, next_state=array([105.06924884, 304.94085391]), next_contact=array([0.79853988, 0.8422633 , 0.70269502, 0.69995156]), done=False),\n",
       " Experience(state=array([105.06924884, 304.94085391]), contact=array([0.79853988, 0.8422633 , 0.70269502, 0.69995156]), action={'1': array([100, 500])}, reward=-432.8482208020514, next_state=array([101.23383927, 499.98849454]), next_contact=array([0.25499376, 0.25632339, 0.24698994, 0.17173617]), done=False),\n",
       " Experience(state=array([101.23383927, 499.98849454]), contact=array([0.25499376, 0.25632339, 0.24698994, 0.17173617]), action={'2': array([300, 500])}, reward=-321.9946618924292, next_state=array([301.41298152, 500.99727888]), next_contact=array([0.53212315, 0.52374185, 0.51205166, 0.4764229 ]), done=False),\n",
       " Experience(state=array([301.41298152, 500.99727888]), contact=array([0.53212315, 0.52374185, 0.51205166, 0.4764229 ]), action={'3': array([300, 300])}, reward=-445.8799315735745, next_state=array([299.20511071, 300.69982707]), next_contact=array([0.73902539, 0.70190244, 0.79844915, 0.93052835]), done=False),\n",
       " Experience(state=array([299.20511071, 300.69982707]), contact=array([0.73902539, 0.70190244, 0.79844915, 0.93052835]), action={'4': array([300, 200])}, reward=-242.6711122487325, next_state=array([298.94474059, 198.99807081]), next_contact=array([0.37877145, 0.14529201, 0.30740008, 0.26710037]), done=False),\n",
       " Experience(state=array([298.94474059, 198.99807081]), contact=array([0.37877145, 0.14529201, 0.30740008, 0.26710037]), action={'5': array([300, 100])}, reward=-195.75791531774618, next_state=array([299.87470802,  99.80641072]), next_contact=array([0.45383435, 0.5797728 , 0.52393411, 0.40339887]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.77151646, 0.67763899, 0.82838277, 0.81206824]), action={'0': array([100, 300])}, reward=-396.51514138408777, next_state=array([ 93.34687384, 295.39346085]), next_contact=array([0.29994231, 0.28622469, 0.08231603, 0.47793827]), done=False),\n",
       " Experience(state=array([ 93.34687384, 295.39346085]), contact=array([0.29994231, 0.28622469, 0.08231603, 0.47793827]), action={'1': array([100, 500])}, reward=-444.6507762135255, next_state=array([ 99.02129353, 499.57997056]), next_contact=array([0.5122946 , 0.43528044, 0.54853159, 0.4652647 ]), done=False),\n",
       " Experience(state=array([ 99.02129353, 499.57997056]), contact=array([0.5122946 , 0.43528044, 0.54853159, 0.4652647 ]), action={'2': array([300, 500])}, reward=-338.47832066195656, next_state=array([299.22469457, 502.02393735]), next_contact=array([0.78095791, 0.77877613, 0.81691184, 0.72188436]), done=False),\n",
       " Experience(state=array([299.22469457, 502.02393735]), contact=array([0.78095791, 0.77877613, 0.81691184, 0.72188436]), action={'3': array([300, 300])}, reward=-424.6922326836505, next_state=array([299.47895048, 297.97683606]), next_contact=array([0.20996433, 0.16601835, 0.262534  , 0.2491811 ]), done=False),\n",
       " Experience(state=array([299.47895048, 297.97683606]), contact=array([0.20996433, 0.16601835, 0.262534  , 0.2491811 ]), action={'4': array([300, 200])}, reward=-245.06732422543135, next_state=array([300.18597112, 201.33222045]), next_contact=array([0.43780813, 0.49199853, 0.5357017 , 0.52431081]), done=False),\n",
       " Experience(state=array([300.18597112, 201.33222045]), contact=array([0.43780813, 0.49199853, 0.5357017 , 0.52431081]), action={'5': array([300, 100])}, reward=-202.87687553668405, next_state=array([299.28415323,  98.39973754]), next_contact=array([0.81403419, 0.72273127, 0.67866711, 0.82068346]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.23259795, 0.25946136, 0.34207712, 0.30711771]), action={'0': array([100, 300])}, reward=-427.893893695005, next_state=array([109.58223724, 309.9215801 ]), next_contact=array([0.37541401, 0.30042867, 0.49691561, 0.39877889]), done=False),\n",
       " Experience(state=array([109.58223724, 309.9215801 ]), contact=array([0.37541401, 0.30042867, 0.49691561, 0.39877889]), action={'1': array([100, 500])}, reward=-448.2918004617756, next_state=array([ 99.05525879, 500.21501752]), next_contact=array([0.71461168, 0.68996785, 0.80765433, 0.72212756]), done=False),\n",
       " Experience(state=array([ 99.05525879, 500.21501752]), contact=array([0.71461168, 0.68996785, 0.80765433, 0.72212756]), action={'2': array([300, 500])}, reward=-313.4142255915113, next_state=array([300.40198195, 499.65476743]), next_contact=array([0.28725078, 0.31254139, 0.41451576, 0.2517475 ]), done=False),\n",
       " Experience(state=array([300.40198195, 499.65476743]), contact=array([0.28725078, 0.31254139, 0.41451576, 0.2517475 ]), action={'3': array([300, 300])}, reward=-430.87155409423815, next_state=array([301.31487585, 300.77427854]), next_contact=array([0.55939784, 0.58535668, 0.60302219, 0.45771288]), done=False),\n",
       " Experience(state=array([301.31487585, 300.77427854]), contact=array([0.55939784, 0.58535668, 0.60302219, 0.45771288]), action={'4': array([300, 200])}, reward=-239.13662955912352, next_state=array([301.1600892 , 199.83557944]), next_contact=array([0.85062374, 0.85875622, 0.83635696, 0.79326293]), done=False),\n",
       " Experience(state=array([301.1600892 , 199.83557944]), contact=array([0.85062374, 0.85875622, 0.83635696, 0.79326293]), action={'5': array([300, 100])}, reward=-203.80628672793443, next_state=array([299.86154388, 101.94981726]), next_contact=array([0.21442457, 0.27959175, 0.25921874, 0.44040963]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.49550912, 0.49229547, 0.57782112, 0.58019459]), action={'0': array([100, 300])}, reward=-427.9490737786763, next_state=array([109.62293647, 309.934979  ]), next_contact=array([0.8715242 , 0.72234802, 0.74735869, 0.79928403]), done=False),\n",
       " Experience(state=array([109.62293647, 309.934979  ]), contact=array([0.8715242 , 0.72234802, 0.74735869, 0.79928403]), action={'1': array([100, 500])}, reward=-448.34696721943635, next_state=array([ 99.97818578, 501.7611671 ]), next_contact=array([0.37488582, 0.19634468, 0.16473931, 0.15660735]), done=False),\n",
       " Experience(state=array([ 99.97818578, 501.7611671 ]), contact=array([0.37488582, 0.19634468, 0.16473931, 0.15660735]), action={'2': array([300, 500])}, reward=-333.753720626451, next_state=array([300.90005193, 499.88028987]), next_contact=array([0.49998001, 0.51025467, 0.55846641, 0.52386329]), done=False),\n",
       " Experience(state=array([300.90005193, 499.88028987]), contact=array([0.49998001, 0.51025467, 0.55846641, 0.52386329]), action={'3': array([300, 300])}, reward=-446.00517054880976, next_state=array([298.59750771, 299.65809985]), next_contact=array([0.75636419, 0.83155823, 0.68779283, 0.66976621]), done=False),\n",
       " Experience(state=array([298.59750771, 299.65809985]), contact=array([0.75636419, 0.83155823, 0.68779283, 0.66976621]), action={'4': array([300, 200])}, reward=-270.42054968344564, next_state=array([301.4695436, 199.4897369]), next_contact=array([0.38919908, 0.19897072, 0.25960132, 0.21792523]), done=False),\n",
       " Experience(state=array([301.4695436, 199.4897369]), contact=array([0.38919908, 0.19897072, 0.25960132, 0.21792523]), action={'5': array([300, 100])}, reward=-212.876541906065, next_state=array([299.37867082,  98.88249604]), next_contact=array([0.61754868, 0.55033133, 0.50738238, 0.53816178]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.71990984, 0.71862111, 0.75269156, 0.7269807 ]), action={'0': array([100, 300])}, reward=-392.974657301564, next_state=array([ 93.71635165, 291.55292022]), next_contact=array([0.2561773 , 0.31051713, 0.25220983, 0.14318436]), done=False),\n",
       " Experience(state=array([ 93.71635165, 291.55292022]), contact=array([0.2561773 , 0.31051713, 0.25220983, 0.14318436]), action={'1': array([100, 500])}, reward=-452.422883673137, next_state=array([100.5823131 , 500.67382262]), next_contact=array([0.53891819, 0.61164744, 0.3957166 , 0.57782782]), done=False),\n",
       " Experience(state=array([100.5823131 , 500.67382262]), contact=array([0.53891819, 0.61164744, 0.3957166 , 0.57782782]), action={'2': array([300, 500])}, reward=-312.11135063348473, next_state=array([300.39332419, 500.1481071 ]), next_contact=array([0.78892023, 0.7448672 , 0.74255869, 0.69134236]), done=False),\n",
       " Experience(state=array([300.39332419, 500.1481071 ]), contact=array([0.78892023, 0.7448672 , 0.74255869, 0.69134236]), action={'3': array([300, 300])}, reward=-423.68953415446816, next_state=array([300.0654445 , 298.43902631]), next_contact=array([0.24112702, 0.19921349, 0.16497929, 0.21352274]), done=False),\n",
       " Experience(state=array([300.0654445 , 298.43902631]), contact=array([0.24112702, 0.19921349, 0.16497929, 0.21352274]), action={'4': array([300, 200])}, reward=-233.96617776036564, next_state=array([300.15567079, 199.43212552]), next_contact=array([0.60773658, 0.37112372, 0.44114985, 0.51317345]), done=False),\n",
       " Experience(state=array([300.15567079, 199.43212552]), contact=array([0.60773658, 0.37112372, 0.44114985, 0.51317345]), action={'5': array([300, 100])}, reward=-202.3895412304795, next_state=array([299.042405  ,  99.92328034]), next_contact=array([0.60390168, 0.71400214, 0.70403654, 0.81839241]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.15327884, 0.36607123, 0.29071543, 0.32022172]), action={'0': array([100, 300])}, reward=-418.755145193654, next_state=array([104.80654718, 305.73771282]), next_contact=array([0.53890988, 0.45287717, 0.44596684, 0.6619287 ]), done=False),\n",
       " Experience(state=array([104.80654718, 305.73771282]), contact=array([0.53890988, 0.45287717, 0.44596684, 0.6619287 ]), action={'1': array([100, 500])}, reward=-438.06981430322577, next_state=array([ 99.57588443, 500.91209697]), next_contact=array([0.55248362, 0.91691605, 0.69857141, 0.65862985]), done=False),\n",
       " Experience(state=array([ 99.57588443, 500.91209697]), contact=array([0.55248362, 0.91691605, 0.69857141, 0.65862985]), action={'2': array([300, 500])}, reward=-317.8250027053638, next_state=array([299.97485466, 501.72947125]), next_contact=array([0.15485626, 0.42669217, 0.22608248, 0.31013606]), done=False),\n",
       " Experience(state=array([299.97485466, 501.72947125]), contact=array([0.15485626, 0.42669217, 0.22608248, 0.31013606]), action={'3': array([300, 300])}, reward=-440.9919599669838, next_state=array([298.40050261, 300.67922649]), next_contact=array([0.60452807, 0.54132682, 0.52043332, 0.5332233 ]), done=False),\n",
       " Experience(state=array([298.40050261, 300.67922649]), contact=array([0.60452807, 0.54132682, 0.52043332, 0.5332233 ]), action={'4': array([300, 200])}, reward=-252.85775669984355, next_state=array([299.29069191, 199.64456391]), next_contact=array([0.74133972, 0.78057156, 0.66580904, 0.69508705]), done=False),\n",
       " Experience(state=array([299.29069191, 199.64456391]), contact=array([0.74133972, 0.78057156, 0.66580904, 0.69508705]), action={'5': array([300, 100])}, reward=-210.52168831908406, next_state=array([301.24696066, 101.15954888]), next_contact=array([0.21622486, 0.33092336, 0.28334613, 0.21838288]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.54988849, 0.5571735 , 0.52299866, 0.45761142]), action={'0': array([100, 300])}, reward=-418.5090133590075, next_state=array([104.65555131, 305.64740296]), next_contact=array([0.95413203, 0.67513794, 0.7615835 , 0.89397128]), done=False),\n",
       " Experience(state=array([104.65555131, 305.64740296]), contact=array([0.95413203, 0.67513794, 0.7615835 , 0.89397128]), action={'1': array([100, 500])}, reward=-427.6257725111523, next_state=array([101.45136108, 498.29319385]), next_contact=array([0.41655858, 0.19429329, 0.27828792, 0.11106455]), done=False),\n",
       " Experience(state=array([101.45136108, 498.29319385]), contact=array([0.41655858, 0.19429329, 0.27828792, 0.11106455]), action={'2': array([300, 500])}, reward=-335.77830244608083, next_state=array([300.28853024, 500.46395427]), next_contact=array([0.47401977, 0.56652686, 0.54522521, 0.44442866]), done=False),\n",
       " Experience(state=array([300.28853024, 500.46395427]), contact=array([0.47401977, 0.56652686, 0.54522521, 0.44442866]), action={'3': array([300, 300])}, reward=-428.56475028286184, next_state=array([299.67087858, 299.55666251]), next_contact=array([0.69868847, 0.73308125, 0.71145356, 0.7011813 ]), done=False),\n",
       " Experience(state=array([299.67087858, 299.55666251]), contact=array([0.69868847, 0.73308125, 0.71145356, 0.7011813 ]), action={'4': array([300, 200])}, reward=-244.0185741284862, next_state=array([300.16602201, 201.12227596]), next_contact=array([0.15604046, 0.30314479, 0.23336808, 0.37762907]), done=False),\n",
       " Experience(state=array([300.16602201, 201.12227596]), contact=array([0.15604046, 0.30314479, 0.23336808, 0.37762907]), action={'5': array([300, 100])}, reward=-185.27971338348763, next_state=array([299.97118661, 100.05822717]), next_contact=array([0.46693534, 0.60756474, 0.60287555, 0.5228815 ]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.77361684, 0.74495852, 0.66244731, 0.73925255]), action={'0': array([100, 300])}, reward=-429.1852943797523, next_state=array([110.25320145, 310.516695  ]), next_contact=array([0.35606967, 0.22279013, 0.29764496, 0.2811838 ]), done=False),\n",
       " Experience(state=array([110.25320145, 310.516695  ]), contact=array([0.35606967, 0.22279013, 0.29764496, 0.2811838 ]), action={'1': array([100, 500])}, reward=-446.6297684958074, next_state=array([100.39115813, 500.31509793]), next_contact=array([0.39666031, 0.43370647, 0.43819166, 0.41759267]), done=False),\n",
       " Experience(state=array([100.39115813, 500.31509793]), contact=array([0.39666031, 0.43370647, 0.43819166, 0.41759267]), action={'2': array([300, 500])}, reward=-328.249542189809, next_state=array([302.72697804, 499.00253186]), next_contact=array([0.76007464, 0.76328361, 0.72584282, 0.66032214]), done=False),\n",
       " Experience(state=array([302.72697804, 499.00253186]), contact=array([0.76007464, 0.76328361, 0.72584282, 0.66032214]), action={'3': array([300, 300])}, reward=-446.4823600024508, next_state=array([300.36962542, 298.3047996 ]), next_contact=array([0.41269219, 0.23573943, 0.27127284, 0.24161938]), done=False),\n",
       " Experience(state=array([300.36962542, 298.3047996 ]), contact=array([0.41269219, 0.23573943, 0.27127284, 0.24161938]), action={'4': array([300, 200])}, reward=-251.48620113034292, next_state=array([299.3294079 , 199.72132071]), next_contact=array([0.4617321 , 0.42315525, 0.52780825, 0.55738137]), done=False),\n",
       " Experience(state=array([299.3294079 , 199.72132071]), contact=array([0.4617321 , 0.42315525, 0.52780825, 0.55738137]), action={'5': array([300, 100])}, reward=-197.7193834310244, next_state=array([299.96345906,  97.42121789]), next_contact=array([0.75183038, 0.79950077, 0.76713998, 0.62042794]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.27426172, 0.32073402, 0.35136973, 0.34668597]), action={'0': array([100, 300])}, reward=-394.4454874250107, next_state=array([ 92.962647  , 293.74861518]), next_contact=array([0.42003078, 0.60140536, 0.53773805, 0.36243399]), done=False),\n",
       " Experience(state=array([ 92.962647  , 293.74861518]), contact=array([0.42003078, 0.60140536, 0.53773805, 0.36243399]), action={'1': array([100, 500])}, reward=-450.77097531586526, next_state=array([ 99.54544891, 501.39360748]), next_contact=array([0.82695056, 0.68168429, 0.73438532, 0.85367126]), done=False),\n",
       " Experience(state=array([ 99.54544891, 501.39360748]), contact=array([0.82695056, 0.68168429, 0.73438532, 0.85367126]), action={'2': array([300, 500])}, reward=-339.404192907597, next_state=array([301.48565628, 499.07417065]), next_contact=array([0.26579589, 0.16041247, 0.3137065 , 0.35336039]), done=False),\n",
       " Experience(state=array([301.48565628, 499.07417065]), contact=array([0.26579589, 0.16041247, 0.3137065 , 0.35336039]), action={'3': array([300, 300])}, reward=-443.57612486388086, next_state=array([299.22503316, 301.07959803]), next_contact=array([0.48232626, 0.53252767, 0.65647456, 0.54210023]), done=False),\n",
       " Experience(state=array([299.22503316, 301.07959803]), contact=array([0.48232626, 0.53252767, 0.65647456, 0.54210023]), action={'4': array([300, 200])}, reward=-260.6025027565144, next_state=array([300.72628907, 199.51717429]), next_contact=array([0.67971357, 0.77677552, 0.92285923, 0.79028319]), done=False),\n",
       " Experience(state=array([300.72628907, 199.51717429]), contact=array([0.67971357, 0.77677552, 0.92285923, 0.79028319]), action={'5': array([300, 100])}, reward=-213.55976088417017, next_state=array([298.50386555,  99.59851936]), next_contact=array([0.29434617, 0.09794915, 0.13599177, 0.37814888]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.46369323, 0.4216275 , 0.36563492, 0.56777992]), action={'0': array([100, 300])}, reward=-417.93288301415555, next_state=array([106.61126768, 303.12685292]), next_contact=array([0.67763779, 0.65090381, 0.76663416, 0.81821982]), done=False),\n",
       " Experience(state=array([106.61126768, 303.12685292]), contact=array([0.67763779, 0.65090381, 0.76663416, 0.81821982]), action={'1': array([100, 500])}, reward=-442.52816591356907, next_state=array([100.3319495 , 500.13316768]), next_contact=array([0.20951146, 0.21845887, 0.1773848 , 0.30968044]), done=False),\n",
       " Experience(state=array([100.3319495 , 500.13316768]), contact=array([0.20951146, 0.21845887, 0.1773848 , 0.30968044]), action={'2': array([300, 500])}, reward=-340.0383269358587, next_state=array([301.7810701 , 502.50411923]), next_contact=array([0.54260972, 0.46844057, 0.43483856, 0.44554665]), done=False),\n",
       " Experience(state=array([301.7810701 , 502.50411923]), contact=array([0.54260972, 0.46844057, 0.43483856, 0.44554665]), action={'3': array([300, 300])}, reward=-432.9847755416616, next_state=array([301.06308036, 299.24009976]), next_contact=array([0.69035057, 0.87654198, 0.719731  , 0.72363908]), done=False),\n",
       " Experience(state=array([301.06308036, 299.24009976]), contact=array([0.69035057, 0.87654198, 0.719731  , 0.72363908]), action={'4': array([300, 200])}, reward=-266.0582560559716, next_state=array([298.71485125, 199.1887006 ]), next_contact=array([0.31668272, 0.28711586, 0.25984084, 0.18633667]), done=False),\n",
       " Experience(state=array([298.71485125, 199.1887006 ]), contact=array([0.31668272, 0.28711586, 0.25984084, 0.18633667]), action={'5': array([300, 100])}, reward=-202.11281397790907, next_state=array([300.20712529, 100.08706428]), next_contact=array([0.51825985, 0.51270368, 0.4044505 , 0.51359282]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.76687148, 0.83022427, 0.71505333, 0.78267991]), action={'0': array([100, 300])}, reward=-429.07776587710237, next_state=array([109.07798807, 311.58648828]), next_contact=array([0.32700781, 0.33594284, 0.40660266, 0.23609824]), done=False),\n",
       " Experience(state=array([109.07798807, 311.58648828]), contact=array([0.32700781, 0.33594284, 0.40660266, 0.23609824]), action={'1': array([100, 500])}, reward=-442.2325870557592, next_state=array([ 99.39763603, 498.12202859]), next_contact=array([0.49911075, 0.47382509, 0.44199614, 0.57275231]), done=False),\n",
       " Experience(state=array([ 99.39763603, 498.12202859]), contact=array([0.49911075, 0.47382509, 0.44199614, 0.57275231]), action={'2': array([300, 500])}, reward=-340.07374238486955, next_state=array([298.3781888 , 500.83615649]), next_contact=array([0.63389636, 0.73415354, 0.77908873, 0.61965461]), done=False),\n",
       " Experience(state=array([298.3781888 , 500.83615649]), contact=array([0.63389636, 0.73415354, 0.77908873, 0.61965461]), action={'3': array([300, 300])}, reward=-416.5392011541197, next_state=array([298.46161856, 299.63797065]), next_contact=array([0.33556936, 0.31654904, 0.26651573, 0.25110184]), done=False),\n",
       " Experience(state=array([298.46161856, 299.63797065]), contact=array([0.33556936, 0.31654904, 0.26651573, 0.25110184]), action={'4': array([300, 200])}, reward=-254.55815155257673, next_state=array([299.67035286, 200.492415  ]), next_contact=array([0.45624584, 0.47798635, 0.64272426, 0.43171068]), done=False),\n",
       " Experience(state=array([299.67035286, 200.492415  ]), contact=array([0.45624584, 0.47798635, 0.64272426, 0.43171068]), action={'5': array([300, 100])}, reward=-192.19192258916596, next_state=array([300.24211874, 100.177097  ]), next_contact=array([0.65893872, 0.76322973, 0.68945378, 0.69747863]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.25071458, 0.28102611, 0.22206523, 0.3251122 ]), action={'0': array([100, 300])}, reward=-397.08729191082654, next_state=array([ 94.0856529 , 295.21561368]), next_contact=array([0.48055369, 0.42335035, 0.55086452, 0.57437972]), done=False),\n",
       " Experience(state=array([ 94.0856529 , 295.21561368]), contact=array([0.48055369, 0.42335035, 0.55086452, 0.57437972]), action={'1': array([100, 500])}, reward=-447.295624424433, next_state=array([ 99.88051252, 501.17499735]), next_contact=array([0.77014226, 0.58297163, 0.95738309, 0.72225816]), done=False),\n",
       " Experience(state=array([ 99.88051252, 501.17499735]), contact=array([0.77014226, 0.58297163, 0.95738309, 0.72225816]), action={'2': array([300, 500])}, reward=-330.0506050050795, next_state=array([301.23561809, 499.62513367]), next_contact=array([0.34087352, 0.30710044, 0.19240959, 0.33988795]), done=False),\n",
       " Experience(state=array([301.23561809, 499.62513367]), contact=array([0.34087352, 0.30710044, 0.19240959, 0.33988795]), action={'3': array([300, 300])}, reward=-420.99742717423345, next_state=array([300.9431799 , 300.07857582]), next_contact=array([0.61971021, 0.47241128, 0.52206677, 0.51103063]), done=False),\n",
       " Experience(state=array([300.9431799 , 300.07857582]), contact=array([0.61971021, 0.47241128, 0.52206677, 0.51103063]), action={'4': array([300, 200])}, reward=-256.85284766548665, next_state=array([299.57428461, 200.63244973]), next_contact=array([0.71620772, 0.76493934, 0.60402826, 0.80420451]), done=False),\n",
       " Experience(state=array([299.57428461, 200.63244973]), contact=array([0.71620772, 0.76493934, 0.60402826, 0.80420451]), action={'5': array([300, 100])}, reward=-189.37755130942065, next_state=array([299.8158893 , 100.52803806]), next_contact=array([0.37082509, 0.2200902 , 0.16835672, 0.1757578 ]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.42097732, 0.51361203, 0.44880179, 0.46692754]), action={'0': array([100, 300])}, reward=-400.0024711670084, next_state=array([ 96.49871005, 295.66057541]), next_contact=array([0.676443  , 0.72398624, 0.81447551, 0.76317004]), done=False),\n",
       " Experience(state=array([ 96.49871005, 295.66057541]), contact=array([0.676443  , 0.72398624, 0.81447551, 0.76317004]), action={'1': array([100, 500])}, reward=-438.26822072372767, next_state=array([100.44401971, 498.85711409]), next_contact=array([0.26213803, 0.17919136, 0.25040988, 0.18703879]), done=False),\n",
       " Experience(state=array([100.44401971, 498.85711409]), contact=array([0.26213803, 0.17919136, 0.25040988, 0.18703879]), action={'2': array([300, 500])}, reward=-338.9288307682909, next_state=array([301.56441482, 501.15515108]), next_contact=array([0.45446785, 0.46275256, 0.45983899, 0.52266363]), done=False),\n",
       " Experience(state=array([301.56441482, 501.15515108]), contact=array([0.45446785, 0.46275256, 0.45983899, 0.52266363]), action={'3': array([300, 300])}, reward=-413.43941411716384, next_state=array([301.59337207, 300.38694207]), next_contact=array([0.61277976, 0.80407909, 0.78243114, 0.7562098 ]), done=False),\n",
       " Experience(state=array([301.59337207, 300.38694207]), contact=array([0.61277976, 0.80407909, 0.78243114, 0.7562098 ]), action={'4': array([300, 200])}, reward=-267.29898903838045, next_state=array([299.33123008, 198.80299844]), next_contact=array([0.21209083, 0.26165029, 0.20842377, 0.34554532]), done=False),\n",
       " Experience(state=array([299.33123008, 198.80299844]), contact=array([0.21209083, 0.26165029, 0.20842377, 0.34554532]), action={'5': array([300, 100])}, reward=-185.61172966147626, next_state=array([299.51090074, 100.38047139]), next_contact=array([0.49576624, 0.44277051, 0.60361162, 0.36774651]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.69178285, 0.61245957, 0.83287068, 0.63000702]), action={'0': array([100, 300])}, reward=-418.9611970224061, next_state=array([105.22353654, 305.52273505]), next_contact=array([0.22483936, 0.24613801, 0.28704502, 0.23246529]), done=False),\n",
       " Experience(state=array([105.22353654, 305.52273505]), contact=array([0.22483936, 0.24613801, 0.28704502, 0.23246529]), action={'1': array([100, 500])}, reward=-427.82090768820626, next_state=array([102.3827405 , 499.48514014]), next_contact=array([0.5811566 , 0.50598919, 0.57052695, 0.52867065]), done=False),\n",
       " Experience(state=array([102.3827405 , 499.48514014]), contact=array([0.5811566 , 0.50598919, 0.57052695, 0.52867065]), action={'2': array([300, 500])}, reward=-293.8478043001268, next_state=array([300.22503345, 499.51948728]), next_contact=array([0.81236565, 0.76936219, 0.76418515, 0.68644685]), done=False),\n",
       " Experience(state=array([300.22503345, 499.51948728]), contact=array([0.81236565, 0.76936219, 0.76418515, 0.68644685]), action={'3': array([300, 300])}, reward=-424.2906665072811, next_state=array([299.76336456, 300.09470192]), next_contact=array([0.19563361, 0.2508774 , 0.24901768, 0.20004463]), done=False),\n",
       " Experience(state=array([299.76336456, 300.09470192]), contact=array([0.19563361, 0.2508774 , 0.24901768, 0.20004463]), action={'4': array([300, 200])}, reward=-253.08564380164, next_state=array([298.86136678, 198.7033875 ]), next_contact=array([0.49700282, 0.49236458, 0.55997716, 0.60476631]), done=False),\n",
       " Experience(state=array([298.86136678, 198.7033875 ]), contact=array([0.49700282, 0.49236458, 0.55997716, 0.60476631]), action={'5': array([300, 100])}, reward=-213.70091459347861, next_state=array([301.31028639, 100.90990212]), next_contact=array([0.64186735, 0.72799232, 0.71280467, 0.74549028]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.30142066, 0.14768503, 0.14502443, 0.32261944]), action={'0': array([100, 300])}, reward=-421.1373920175075, next_state=array([106.20334914, 306.67644696]), next_contact=array([0.49894212, 0.5936132 , 0.50689123, 0.44866832]), done=False),\n",
       " Experience(state=array([106.20334914, 306.67644696]), contact=array([0.49894212, 0.5936132 , 0.50689123, 0.44866832]), action={'1': array([100, 500])}, reward=-440.6869429993279, next_state=array([ 99.24472754, 499.47179558]), next_contact=array([0.73242475, 0.72224807, 0.69019044, 0.669387  ]), done=False),\n",
       " Experience(state=array([ 99.24472754, 499.47179558]), contact=array([0.73242475, 0.72224807, 0.69019044, 0.669387  ]), action={'2': array([300, 500])}, reward=-321.0450504898339, next_state=array([301.13200782, 500.39864139]), next_contact=array([0.29713966, 0.23485355, 0.23917295, 0.28342139]), done=False),\n",
       " Experience(state=array([301.13200782, 500.39864139]), contact=array([0.29713966, 0.23485355, 0.23917295, 0.28342139]), action={'3': array([300, 300])}, reward=-413.07223896865275, next_state=array([301.1007985 , 299.81402334]), next_contact=array([0.53911828, 0.59027209, 0.59012309, 0.52551856]), done=False),\n",
       " Experience(state=array([301.1007985 , 299.81402334]), contact=array([0.53911828, 0.59027209, 0.59012309, 0.52551856]), action={'4': array([300, 200])}, reward=-246.0967778065376, next_state=array([300.5408429 , 200.49086307]), next_contact=array([0.91289785, 0.67820378, 0.68790858, 0.83993639]), done=False),\n",
       " Experience(state=array([300.5408429 , 200.49086307]), contact=array([0.91289785, 0.67820378, 0.68790858, 0.83993639]), action={'5': array([300, 100])}, reward=-207.46139938319487, next_state=array([299.05972611, 100.31000466]), next_contact=array([0.25499497, 0.29285248, 0.29419442, 0.15055631]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.47800586, 0.34892307, 0.57200676, 0.40150843]), action={'0': array([100, 300])}, reward=-396.2124902757747, next_state=array([ 93.90143462, 294.54218329]), next_contact=array([0.63155246, 0.73973617, 0.71211368, 0.63073631]), done=False),\n",
       " Experience(state=array([ 93.90143462, 294.54218329]), contact=array([0.63155246, 0.73973617, 0.71211368, 0.63073631]), action={'1': array([100, 500])}, reward=-446.32213941715435, next_state=array([ 99.30877726, 500.98013786]), next_contact=array([0.33493391, 0.22483701, 0.16394328, 0.28270821]), done=False),\n",
       " Experience(state=array([ 99.30877726, 500.98013786]), contact=array([0.33493391, 0.22483701, 0.16394328, 0.28270821]), action={'2': array([300, 500])}, reward=-332.21896233648795, next_state=array([301.20267952, 499.27120024]), next_contact=array([0.45410644, 0.40419946, 0.4634073 , 0.33502634]), done=False),\n",
       " Experience(state=array([301.20267952, 499.27120024]), contact=array([0.45410644, 0.40419946, 0.4634073 , 0.33502634]), action={'3': array([300, 300])}, reward=-422.31537168248093, next_state=array([301.57716092, 300.10407557]), next_contact=array([0.59934549, 0.74591507, 0.65593209, 0.8240801 ]), done=False),\n",
       " Experience(state=array([301.57716092, 300.10407557]), contact=array([0.59934549, 0.74591507, 0.65593209, 0.8240801 ]), action={'4': array([300, 200])}, reward=-260.5481485310889, next_state=array([299.79307494, 201.18194116]), next_contact=array([0.35411633, 0.30780506, 0.15769787, 0.25636843]), done=False),\n",
       " Experience(state=array([299.79307494, 201.18194116]), contact=array([0.35411633, 0.30780506, 0.15769787, 0.25636843]), action={'5': array([300, 100])}, reward=-195.79462467542066, next_state=array([300.2728868 ,  99.26531337]), next_contact=array([0.35798378, 0.48833952, 0.45663306, 0.46836262]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.70738538, 0.70278782, 0.69316418, 0.82408664]), action={'0': array([100, 300])}, reward=-396.99145954102534, next_state=array([ 95.90699715, 293.30031613]), next_contact=array([0.18300104, 0.15318366, 0.3238489 , 0.2455938 ]), done=False),\n",
       " Experience(state=array([ 95.90699715, 293.30031613]), contact=array([0.18300104, 0.15318366, 0.3238489 , 0.2455938 ]), action={'1': array([100, 500])}, reward=-440.02765103312396, next_state=array([ 99.29143693, 500.61458425]), next_contact=array([0.40737051, 0.57794151, 0.55154408, 0.40689912]), done=False),\n",
       " Experience(state=array([ 99.29143693, 500.61458425]), contact=array([0.40737051, 0.57794151, 0.55154408, 0.40689912]), action={'2': array([300, 500])}, reward=-331.0200711174607, next_state=array([299.56154725, 498.85788555]), next_contact=array([0.75835667, 0.71944337, 0.8691537 , 0.76177349]), done=False),\n",
       " Experience(state=array([299.56154725, 498.85788555]), contact=array([0.75835667, 0.71944337, 0.8691537 , 0.76177349]), action={'3': array([300, 300])}, reward=-420.9436836063018, next_state=array([299.29624017, 297.9783906 ]), next_contact=array([0.15498771, 0.26293181, 0.13990502, 0.27126925]), done=False),\n",
       " Experience(state=array([299.29624017, 297.9783906 ]), contact=array([0.15498771, 0.26293181, 0.13990502, 0.27126925]), action={'4': array([300, 200])}, reward=-230.89264775250135, next_state=array([299.33024597, 198.92749648]), next_contact=array([0.59085608, 0.50046611, 0.61527361, 0.47426133]), done=False),\n",
       " Experience(state=array([299.33024597, 198.92749648]), contact=array([0.59085608, 0.50046611, 0.61527361, 0.47426133]), action={'5': array([300, 100])}, reward=-205.88912002179657, next_state=array([297.89781243,  98.89509898]), next_contact=array([0.68812912, 0.85315881, 0.77047513, 0.78777517]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.20578644, 0.17221487, 0.19964411, 0.26301011]), action={'0': array([100, 300])}, reward=-428.9588469721459, next_state=array([109.76276406, 310.78512513]), next_contact=array([0.37943865, 0.33056205, 0.5132447 , 0.63928417]), done=False),\n",
       " Experience(state=array([109.76276406, 310.78512513]), contact=array([0.37943865, 0.33056205, 0.5132447 , 0.63928417]), action={'1': array([100, 500])}, reward=-441.3942196936934, next_state=array([102.31460181, 501.03172756]), next_contact=array([0.69172213, 0.66783393, 0.88200563, 0.76826283]), done=False),\n",
       " Experience(state=array([102.31460181, 501.03172756]), contact=array([0.69172213, 0.66783393, 0.88200563, 0.76826283]), action={'2': array([300, 500])}, reward=-326.03361840317297, next_state=array([298.18434393, 499.46756711]), next_contact=array([0.25660438, 0.19928165, 0.16302548, 0.29744499]), done=False),\n",
       " Experience(state=array([298.18434393, 499.46756711]), contact=array([0.25660438, 0.19928165, 0.16302548, 0.29744499]), action={'3': array([300, 300])}, reward=-444.7679406957934, next_state=array([300.3462157 , 299.01072996]), next_contact=array([0.53105714, 0.36953457, 0.44823944, 0.43711533]), done=False),\n",
       " Experience(state=array([300.3462157 , 299.01072996]), contact=array([0.53105714, 0.36953457, 0.44823944, 0.43711533]), action={'4': array([300, 200])}, reward=-244.31620634945025, next_state=array([300.85037422, 200.17969889]), next_contact=array([0.83139878, 0.77146721, 0.74578347, 0.82635311]), done=False),\n",
       " Experience(state=array([300.85037422, 200.17969889]), contact=array([0.83139878, 0.77146721, 0.74578347, 0.82635311]), action={'5': array([300, 100])}, reward=-187.51926674999115, next_state=array([300.51953603,  99.99733389]), next_contact=array([0.21598559, 0.26393702, 0.17061034, 0.30072884]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.51038628, 0.5730006 , 0.70467515, 0.34214132]), action={'0': array([100, 300])}, reward=-399.28664403187076, next_state=array([ 95.40971769, 296.04777646]), next_contact=array([0.77914558, 0.86807256, 0.78044076, 0.75249696]), done=False),\n",
       " Experience(state=array([ 95.40971769, 296.04777646]), contact=array([0.77914558, 0.86807256, 0.78044076, 0.75249696]), action={'1': array([100, 500])}, reward=-446.47223478414395, next_state=array([101.40468041, 500.35013093]), next_contact=array([0.28123531, 0.33856232, 0.31137229, 0.2076767 ]), done=False),\n",
       " Experience(state=array([101.40468041, 500.35013093]), contact=array([0.28123531, 0.33856232, 0.31137229, 0.2076767 ]), action={'2': array([300, 500])}, reward=-312.7981638084831, next_state=array([301.571632  , 499.83705259]), next_contact=array([0.54984498, 0.43286358, 0.45680117, 0.58885519]), done=False),\n",
       " Experience(state=array([301.571632  , 499.83705259]), contact=array([0.54984498, 0.43286358, 0.45680117, 0.58885519]), action={'3': array([300, 300])}, reward=-421.4092830659192, next_state=array([301.24119767, 301.01467661]), next_contact=array([0.65741697, 0.65745939, 0.67358741, 0.70641881]), done=False),\n",
       " Experience(state=array([301.24119767, 301.01467661]), contact=array([0.65741697, 0.65745939, 0.67358741, 0.70641881]), action={'4': array([300, 200])}, reward=-267.87086807181885, next_state=array([298.86399348, 200.13242244]), next_contact=array([0.28762868, 0.23282258, 0.30408338, 0.35735239]), done=False),\n",
       " Experience(state=array([298.86399348, 200.13242244]), contact=array([0.28762868, 0.23282258, 0.30408338, 0.35735239]), action={'5': array([300, 100])}, reward=-215.549251466626, next_state=array([301.18038226,  98.80655088]), next_contact=array([0.41188377, 0.56527021, 0.53121868, 0.47847816]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.73542075, 0.79743846, 0.84289495, 0.79459356]), action={'0': array([100, 300])}, reward=-398.3147224055607, next_state=array([ 95.02597105, 295.47865876]), next_contact=array([0.34250842, 0.24964181, 0.25601763, 0.27229774]), done=False),\n",
       " Experience(state=array([ 95.02597105, 295.47865876]), contact=array([0.34250842, 0.24964181, 0.25601763, 0.27229774]), action={'1': array([100, 500])}, reward=-443.87621537646146, next_state=array([ 99.74255373, 501.22072683]), next_contact=array([0.38151167, 0.53980944, 0.49505072, 0.54667952]), done=False),\n",
       " Experience(state=array([ 99.74255373, 501.22072683]), contact=array([0.38151167, 0.53980944, 0.49505072, 0.54667952]), action={'2': array([300, 500])}, reward=-315.85890197827064, next_state=array([298.93751084, 500.44590458]), next_contact=array([0.68781954, 0.63376284, 0.71774256, 0.81484051]), done=False),\n",
       " Experience(state=array([298.93751084, 500.44590458]), contact=array([0.68781954, 0.63376284, 0.71774256, 0.81484051]), action={'3': array([300, 300])}, reward=-453.8543385071972, next_state=array([302.13018189, 299.20864775]), next_contact=array([0.22041688, 0.37325452, 0.22521233, 0.2239497 ]), done=False),\n",
       " Experience(state=array([302.13018189, 299.20864775]), contact=array([0.22041688, 0.37325452, 0.22521233, 0.2239497 ]), action={'4': array([300, 200])}, reward=-278.54022300854433, next_state=array([297.93562723, 199.59323513]), next_contact=array([0.57757119, 0.45701696, 0.48439775, 0.36409364]), done=False),\n",
       " Experience(state=array([297.93562723, 199.59323513]), contact=array([0.57757119, 0.45701696, 0.48439775, 0.36409364]), action={'5': array([300, 100])}, reward=-215.13111090984387, next_state=array([300.43756108, 100.88370924]), next_contact=array([0.8505965 , 0.85334292, 0.74294867, 0.69729086]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.25479956, 0.29214889, 0.31667174, 0.26103345]), action={'0': array([100, 300])}, reward=-418.4399486525474, next_state=array([105.21227561, 305.02296817]), next_contact=array([0.5663912 , 0.49450812, 0.45451957, 0.51690912]), done=False),\n",
       " Experience(state=array([105.21227561, 305.02296817]), contact=array([0.5663912 , 0.49450812, 0.45451957, 0.51690912]), action={'1': array([100, 500])}, reward=-438.4623138183904, next_state=array([100.15423749, 501.15155119]), next_contact=array([0.7880438 , 0.73436562, 0.69517031, 0.82578623]), done=False),\n",
       " Experience(state=array([100.15423749, 501.15155119]), contact=array([0.7880438 , 0.73436562, 0.69517031, 0.82578623]), action={'2': array([300, 500])}, reward=-338.4670072219085, next_state=array([301.30205924, 498.88002048]), next_contact=array([0.27822499, 0.17904441, 0.17285562, 0.23198982]), done=False),\n",
       " Experience(state=array([301.30205924, 498.88002048]), contact=array([0.27822499, 0.17904441, 0.17285562, 0.23198982]), action={'3': array([300, 300])}, reward=-435.37428310878715, next_state=array([299.91313779, 300.87316857]), next_contact=array([0.43563269, 0.49657185, 0.44878503, 0.45538051]), done=False),\n",
       " Experience(state=array([299.91313779, 300.87316857]), contact=array([0.43563269, 0.49657185, 0.44878503, 0.45538051]), action={'4': array([300, 200])}, reward=-251.59048944946187, next_state=array([299.0985675 , 200.23450612]), next_contact=array([0.77898491, 0.83110145, 0.75000107, 0.72466072]), done=False),\n",
       " Experience(state=array([299.0985675 , 200.23450612]), contact=array([0.77898491, 0.83110145, 0.75000107, 0.72466072]), action={'5': array([300, 100])}, reward=-217.84739579359535, next_state=array([301.60723215,  97.74526566]), next_contact=array([0.28859118, 0.36113496, 0.26048622, 0.26240615]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.52719232, 0.59915598, 0.53210521, 0.55322357]), action={'0': array([100, 300])}, reward=-420.19683821926833, next_state=array([106.2749485 , 305.68273603]), next_contact=array([0.71420545, 0.79166264, 0.60478943, 0.69866019]), done=False),\n",
       " Experience(state=array([106.2749485 , 305.68273603]), contact=array([0.71420545, 0.79166264, 0.60478943, 0.69866019]), action={'1': array([100, 500])}, reward=-438.50428231602154, next_state=array([100.09394197, 498.82716068]), next_contact=array([0.10834467, 0.39576464, 0.13550571, 0.13608051]), done=False),\n",
       " Experience(state=array([100.09394197, 498.82716068]), contact=array([0.10834467, 0.39576464, 0.13550571, 0.13608051]), action={'2': array([300, 500])}, reward=-311.43658054240586, next_state=array([299.63762006, 499.35275339]), next_contact=array([0.44344932, 0.42894063, 0.4960825 , 0.47720092]), done=False),\n",
       " Experience(state=array([299.63762006, 499.35275339]), contact=array([0.44344932, 0.42894063, 0.4960825 , 0.47720092]), action={'3': array([300, 300])}, reward=-426.8761344124996, next_state=array([298.91470104, 301.96744633]), next_contact=array([0.7046847 , 0.72722016, 0.80933381, 0.7324686 ]), done=False),\n",
       " Experience(state=array([298.91470104, 301.96744633]), contact=array([0.7046847 , 0.72722016, 0.80933381, 0.7324686 ]), action={'4': array([300, 200])}, reward=-243.17185579534342, next_state=array([299.15077881, 199.68068268]), next_contact=array([0.3651948 , 0.29891362, 0.13104338, 0.21903037]), done=False),\n",
       " Experience(state=array([299.15077881, 199.68068268]), contact=array([0.3651948 , 0.29891362, 0.13104338, 0.21903037]), action={'5': array([300, 100])}, reward=-205.0975433702401, next_state=array([300.48792215, 100.1318753 ]), next_contact=array([0.47473425, 0.51428828, 0.42479989, 0.65965779]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.78731217, 0.72010687, 0.67738366, 0.62287793]), action={'0': array([100, 300])}, reward=-397.27478701923286, next_state=array([ 95.42902368, 294.05606163]), next_contact=array([0.32020909, 0.26676842, 0.36513236, 0.19865576]), done=False),\n",
       " Experience(state=array([ 95.42902368, 294.05606163]), contact=array([0.32020909, 0.26676842, 0.36513236, 0.19865576]), action={'1': array([100, 500])}, reward=-451.2539317735163, next_state=array([102.03511361, 501.53689016]), next_contact=array([0.3567423 , 0.46639241, 0.52989898, 0.48263807]), done=False),\n",
       " Experience(state=array([102.03511361, 501.53689016]), contact=array([0.3567423 , 0.46639241, 0.52989898, 0.48263807]), action={'2': array([300, 500])}, reward=-312.174333201237, next_state=array([298.77238299, 502.17180152]), next_contact=array([0.78193568, 0.70720293, 0.79748395, 0.78882479]), done=False),\n",
       " Experience(state=array([298.77238299, 502.17180152]), contact=array([0.78193568, 0.70720293, 0.79748395, 0.78882479]), action={'3': array([300, 300])}, reward=-430.7222608756563, next_state=array([299.35324064, 298.75307014]), next_contact=array([0.29037349, 0.22751402, 0.1696922 , 0.2068818 ]), done=False),\n",
       " Experience(state=array([299.35324064, 298.75307014]), contact=array([0.29037349, 0.22751402, 0.1696922 , 0.2068818 ]), action={'4': array([300, 200])}, reward=-267.9586802938668, next_state=array([302.00881899, 199.0958332 ]), next_contact=array([0.44819279, 0.43229829, 0.4221913 , 0.47274851]), done=False),\n",
       " Experience(state=array([302.00881899, 199.0958332 ]), contact=array([0.44819279, 0.43229829, 0.4221913 , 0.47274851]), action={'5': array([300, 100])}, reward=-204.14943670313843, next_state=array([300.63007843, 101.43029358]), next_contact=array([0.75609664, 0.85160192, 0.79107849, 0.78074783]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.25236054, 0.20510176, 0.22683327, 0.27578487]), action={'0': array([100, 300])}, reward=-398.1515626797972, next_state=array([ 94.97380237, 295.37086692]), next_contact=array([0.32778925, 0.46840759, 0.52202903, 0.59563448]), done=False),\n",
       " Experience(state=array([ 94.97380237, 295.37086692]), contact=array([0.32778925, 0.46840759, 0.52202903, 0.59563448]), action={'1': array([100, 500])}, reward=-445.48414532194994, next_state=array([100.37181433, 500.68291891]), next_contact=array([0.81307963, 0.673336  , 0.70724026, 0.64697393]), done=False),\n",
       " Experience(state=array([100.37181433, 500.68291891]), contact=array([0.81307963, 0.673336  , 0.70724026, 0.64697393]), action={'2': array([300, 500])}, reward=-311.24138262906587, next_state=array([301.08386579, 500.23058985]), next_contact=array([0.31341156, 0.30746812, 0.25639829, 0.1462739 ]), done=False),\n",
       " Experience(state=array([301.08386579, 500.23058985]), contact=array([0.31341156, 0.30746812, 0.25639829, 0.1462739 ]), action={'3': array([300, 300])}, reward=-412.0673244749785, next_state=array([301.055962  , 300.53251081]), next_contact=array([0.58872655, 0.56325751, 0.56215493, 0.56334585]), done=False),\n",
       " Experience(state=array([301.055962  , 300.53251081]), contact=array([0.58872655, 0.56325751, 0.56215493, 0.56334585]), action={'4': array([300, 200])}, reward=-256.34340879606475, next_state=array([299.80894305, 200.42184668]), next_contact=array([0.81734749, 0.86928067, 0.76298626, 0.71617301]), done=False),\n",
       " Experience(state=array([299.80894305, 200.42184668]), contact=array([0.81734749, 0.86928067, 0.76298626, 0.71617301]), action={'5': array([300, 100])}, reward=-191.58623332397212, next_state=array([299.48334024,  99.70643424]), next_contact=array([0.19010059, 0.28577332, 0.21027163, 0.2771782 ]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.48998892, 0.53190366, 0.52014058, 0.48173131]), action={'0': array([100, 300])}, reward=-385.18908727075774, next_state=array([ 88.45544432, 289.18091574]), next_contact=array([0.7580683 , 0.66268932, 0.62010655, 0.74831098]), done=False),\n",
       " Experience(state=array([ 88.45544432, 289.18091574]), contact=array([0.7580683 , 0.66268932, 0.62010655, 0.74831098]), action={'1': array([100, 500])}, reward=-465.8165269593673, next_state=array([100.89569745, 500.21083045]), next_contact=array([0.28015664, 0.36799912, 0.36386739, 0.33143184]), done=False),\n",
       " Experience(state=array([100.89569745, 500.21083045]), contact=array([0.28015664, 0.36799912, 0.36386739, 0.33143184]), action={'2': array([300, 500])}, reward=-312.9841546475897, next_state=array([301.19720374, 499.67938489]), next_contact=array([0.53524669, 0.51282783, 0.53342004, 0.48067773]), done=False),\n",
       " Experience(state=array([301.19720374, 499.67938489]), contact=array([0.53524669, 0.51282783, 0.53342004, 0.48067773]), action={'3': array([300, 300])}, reward=-434.6102890321728, next_state=array([299.92786795, 301.5040796 ]), next_contact=array([0.87338732, 0.69920405, 0.61813687, 0.68595779]), done=False),\n",
       " Experience(state=array([299.92786795, 301.5040796 ]), contact=array([0.87338732, 0.69920405, 0.61813687, 0.68595779]), action={'4': array([300, 200])}, reward=-243.2460721795148, next_state=array([300.2040924 , 200.02187584]), next_contact=array([0.24216657, 0.29343531, 0.32687675, 0.25291303]), done=False),\n",
       " Experience(state=array([300.2040924 , 200.02187584]), contact=array([0.24216657, 0.29343531, 0.32687675, 0.25291303]), action={'5': array([300, 100])}, reward=-212.56543431270083, next_state=array([298.21948802,  98.76852383]), next_contact=array([0.48705087, 0.44566548, 0.31147825, 0.48455992]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.72140995, 0.73239112, 0.57921594, 0.65195552]), action={'0': array([100, 300])}, reward=-432.00246912938655, next_state=array([111.1102964 , 312.42153608]), next_contact=array([0.18176751, 0.24548495, 0.24820748, 0.18827868]), done=False),\n",
       " Experience(state=array([111.1102964 , 312.42153608]), contact=array([0.18176751, 0.24548495, 0.24820748, 0.18827868]), action={'1': array([100, 500])}, reward=-446.9286684371403, next_state=array([100.28644584, 499.96549941]), next_contact=array([0.50231582, 0.51253225, 0.42506817, 0.46981972]), done=False),\n",
       " Experience(state=array([100.28644584, 499.96549941]), contact=array([0.50231582, 0.51253225, 0.42506817, 0.46981972]), action={'2': array([300, 500])}, reward=-315.0811160083083, next_state=array([301.99709711, 500.54330296]), next_contact=array([0.64136471, 0.60421708, 0.69538419, 0.71805256]), done=False),\n",
       " Experience(state=array([301.99709711, 500.54330296]), contact=array([0.64136471, 0.60421708, 0.69538419, 0.71805256]), action={'3': array([300, 300])}, reward=-446.3613106051388, next_state=array([299.78716392, 299.38146477]), next_contact=array([0.18847952, 0.22870112, 0.37307025, 0.20888852]), done=False),\n",
       " Experience(state=array([299.78716392, 299.38146477]), contact=array([0.18847952, 0.22870112, 0.37307025, 0.20888852]), action={'4': array([300, 200])}, reward=-259.9973980178732, next_state=array([298.11199192, 199.46925812]), next_contact=array([0.4479722 , 0.46275398, 0.42213745, 0.47041389]), done=False),\n",
       " Experience(state=array([298.11199192, 199.46925812]), contact=array([0.4479722 , 0.46275398, 0.42213745, 0.47041389]), action={'5': array([300, 100])}, reward=-196.40168197461793, next_state=array([298.72249353,  98.48268378]), next_contact=array([0.75112745, 0.74931399, 0.79245358, 0.76057425]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.30435142, 0.23818246, 0.1470553 , 0.24371204]), action={'0': array([100, 300])}, reward=-398.9765971545927, next_state=array([ 93.73873234, 297.41479428]), next_contact=array([0.47432541, 0.56948675, 0.48172938, 0.53362389]), done=False),\n",
       " Experience(state=array([ 93.73873234, 297.41479428]), contact=array([0.47432541, 0.56948675, 0.48172938, 0.53362389]), action={'1': array([100, 500])}, reward=-446.42524603366275, next_state=array([100.61027665, 499.35851572]), next_contact=array([0.61533348, 0.77661108, 0.77192013, 0.71012629]), done=False),\n",
       " Experience(state=array([100.61027665, 499.35851572]), contact=array([0.61533348, 0.77661108, 0.77192013, 0.71012629]), action={'2': array([300, 500])}, reward=-306.00440839037816, next_state=array([300.40679085, 499.07088499]), next_contact=array([0.24811629, 0.27654784, 0.02399644, 0.25030575]), done=False),\n",
       " Experience(state=array([300.40679085, 499.07088499]), contact=array([0.24811629, 0.27654784, 0.02399644, 0.25030575]), action={'3': array([300, 300])}, reward=-425.70668979740685, next_state=array([299.77480659, 301.26446822]), next_contact=array([0.61728484, 0.58669712, 0.48987366, 0.39334057]), done=False),\n",
       " Experience(state=array([299.77480659, 301.26446822]), contact=array([0.61728484, 0.58669712, 0.48987366, 0.39334057]), action={'4': array([300, 200])}, reward=-239.31249634498158, next_state=array([299.61555482, 200.50620841]), next_contact=array([0.77884577, 0.77606408, 0.86853559, 0.77617455]), done=False),\n",
       " Experience(state=array([299.61555482, 200.50620841]), contact=array([0.77884577, 0.77606408, 0.86853559, 0.77617455]), action={'5': array([300, 100])}, reward=-198.94803299294193, next_state=array([300.4075843 , 100.93638281]), next_contact=array([0.31641439, 0.39510445, 0.2173971 , 0.2913534 ]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.47857352, 0.5801673 , 0.52775285, 0.51706946]), action={'0': array([100, 300])}, reward=-397.87245539822743, next_state=array([ 94.53585221, 295.53518249]), next_contact=array([0.68227767, 0.76172075, 0.82477395, 0.78896518]), done=False),\n",
       " Experience(state=array([ 94.53585221, 295.53518249]), contact=array([0.68227767, 0.76172075, 0.82477395, 0.78896518]), action={'1': array([100, 500])}, reward=-440.73940485801705, next_state=array([ 98.63213243, 500.5308511 ]), next_contact=array([0.33287045, 0.16314818, 0.19858515, 0.33071568]), done=False),\n",
       " Experience(state=array([ 98.63213243, 500.5308511 ]), contact=array([0.33287045, 0.16314818, 0.19858515, 0.33071568]), action={'2': array([300, 500])}, reward=-325.25273430645774, next_state=array([300.74211526, 499.32193326]), next_contact=array([0.45725968, 0.39730535, 0.61254389, 0.42633522]), done=False),\n",
       " Experience(state=array([300.74211526, 499.32193326]), contact=array([0.45725968, 0.39730535, 0.61254389, 0.42633522]), action={'3': array([300, 300])}, reward=-418.11976235431007, next_state=array([300.95717035, 300.80473237]), next_contact=array([0.75646143, 0.80318868, 0.69568145, 0.68872169]), done=False),\n",
       " Experience(state=array([300.95717035, 300.80473237]), contact=array([0.75646143, 0.80318868, 0.69568145, 0.68872169]), action={'4': array([300, 200])}, reward=-255.247928641015, next_state=array([299.90463375, 199.53887229]), next_contact=array([0.20847293, 0.25966377, 0.27083089, 0.22612053]), done=False),\n",
       " Experience(state=array([299.90463375, 199.53887229]), contact=array([0.20847293, 0.25966377, 0.27083089, 0.22612053]), action={'5': array([300, 100])}, reward=-204.3050501620934, next_state=array([301.21619907, 100.77638922]), next_contact=array([0.47950257, 0.56463872, 0.6139225 , 0.5375073 ]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.73333226, 0.77686615, 0.8143554 , 0.70163626]), action={'0': array([100, 300])}, reward=-395.6853325172555, next_state=array([ 94.82802477, 293.09877182]), next_contact=array([0.21048127, 0.2698959 , 0.2481263 , 0.23476123]), done=False),\n",
       " Experience(state=array([ 94.82802477, 293.09877182]), contact=array([0.21048127, 0.2698959 , 0.2481263 , 0.23476123]), action={'1': array([100, 500])}, reward=-444.81575435767775, next_state=array([ 99.75603119, 500.03524569]), next_contact=array([0.5075491 , 0.53238139, 0.59093008, 0.52551058]), done=False),\n",
       " Experience(state=array([ 99.75603119, 500.03524569]), contact=array([0.5075491 , 0.53238139, 0.59093008, 0.52551058]), action={'2': array([300, 500])}, reward=-342.23846373781913, next_state=array([299.48970095, 497.20354572]), next_contact=array([0.84129931, 0.84861718, 0.63309347, 0.85593491]), done=False),\n",
       " Experience(state=array([299.48970095, 497.20354572]), contact=array([0.84129931, 0.84861718, 0.63309347, 0.85593491]), action={'3': array([300, 300])}, reward=-448.2617608506318, next_state=array([302.62551545, 300.63214965]), next_contact=array([0.22033269, 0.27906794, 0.28798867, 0.27911418]), done=False),\n",
       " Experience(state=array([302.62551545, 300.63214965]), contact=array([0.22033269, 0.27906794, 0.28798867, 0.27911418]), action={'4': array([300, 200])}, reward=-278.2860521481621, next_state=array([298.74312256, 199.93711749]), next_contact=array([0.50314842, 0.36439717, 0.52797525, 0.54614947]), done=False),\n",
       " Experience(state=array([298.74312256, 199.93711749]), contact=array([0.50314842, 0.36439717, 0.52797525, 0.54614947]), action={'5': array([300, 100])}, reward=-207.10908769018607, next_state=array([300.27273253, 100.61063725]), next_contact=array([0.64052271, 0.7910001 , 0.69111949, 0.87771464]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.18599382, 0.33175479, 0.22575032, 0.21721968]), action={'0': array([100, 300])}, reward=-398.2303678584532, next_state=array([ 94.64194907, 295.7799802 ]), next_contact=array([0.49297765, 0.52709877, 0.44336368, 0.44821779]), done=False),\n",
       " Experience(state=array([ 94.64194907, 295.7799802 ]), contact=array([0.49297765, 0.52709877, 0.44336368, 0.44821779]), action={'1': array([100, 500])}, reward=-441.37545304650325, next_state=array([ 99.33139996, 499.54093212]), next_contact=array([0.83036566, 0.73884857, 0.82209085, 0.68330272]), done=False),\n",
       " Experience(state=array([ 99.33139996, 499.54093212]), contact=array([0.83036566, 0.73884857, 0.82209085, 0.68330272]), action={'2': array([300, 500])}, reward=-330.690687576545, next_state=array([300.714469  , 501.16961502]), next_contact=array([0.30175287, 0.15514103, 0.20503284, 0.28432203]), done=False),\n",
       " Experience(state=array([300.714469  , 501.16961502]), contact=array([0.30175287, 0.15514103, 0.20503284, 0.28432203]), action={'3': array([300, 300])}, reward=-433.9411921182746, next_state=array([299.72474029, 300.54282862]), next_contact=array([0.51717877, 0.44716751, 0.59292443, 0.47912889]), done=False),\n",
       " Experience(state=array([299.72474029, 300.54282862]), contact=array([0.51717877, 0.44716751, 0.59292443, 0.47912889]), action={'4': array([300, 200])}, reward=-264.38975504565815, next_state=array([297.72423969, 199.66358903]), next_contact=array([0.63183331, 0.80009572, 0.77172573, 0.85404378]), done=False),\n",
       " Experience(state=array([297.72423969, 199.66358903]), contact=array([0.63183331, 0.80009572, 0.77172573, 0.85404378]), action={'5': array([300, 100])}, reward=-212.70270322025897, next_state=array([299.97417244, 101.6337206 ]), next_contact=array([0.16033777, 0.18182947, 0.30115173, 0.33141498]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.32042105, 0.4326151 , 0.56589433, 0.53713379]), action={'0': array([100, 300])}, reward=-428.01560986158864, next_state=array([109.59477396, 310.02837297]), next_contact=array([0.83294951, 0.75790804, 0.71191611, 0.81264869]), done=False),\n",
       " Experience(state=array([109.59477396, 310.02837297]), contact=array([0.83294951, 0.75790804, 0.71191611, 0.81264869]), action={'1': array([100, 500])}, reward=-442.79070064083885, next_state=array([102.1059065 , 501.58085561]), next_contact=array([0.14793144, 0.24060417, 0.26636507, 0.23937918]), done=False),\n",
       " Experience(state=array([102.1059065 , 501.58085561]), contact=array([0.14793144, 0.24060417, 0.26636507, 0.23937918]), action={'2': array([300, 500])}, reward=-320.00770586595837, next_state=array([301.37318347, 500.67184211]), next_contact=array([0.63753648, 0.47006592, 0.46210533, 0.52931962]), done=False),\n",
       " Experience(state=array([301.37318347, 500.67184211]), contact=array([0.63753648, 0.47006592, 0.46210533, 0.52931962]), action={'3': array([300, 300])}, reward=-417.5285668569456, next_state=array([301.49924949, 300.28792177]), next_contact=array([0.84113259, 0.71447449, 0.65856739, 0.68702392]), done=False),\n",
       " Experience(state=array([301.49924949, 300.28792177]), contact=array([0.84113259, 0.71447449, 0.65856739, 0.68702392]), action={'4': array([300, 200])}, reward=-241.5629493134575, next_state=array([301.17188497, 201.34986474]), next_contact=array([0.11796013, 0.19709188, 0.21005976, 0.27109608]), done=False),\n",
       " Experience(state=array([301.17188497, 201.34986474]), contact=array([0.11796013, 0.19709188, 0.21005976, 0.27109608]), action={'5': array([300, 100])}, reward=-201.33337596364825, next_state=array([302.05426669, 100.77798277]), next_contact=array([0.54716089, 0.44054555, 0.42151874, 0.5533197 ]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.85985876, 0.685858  , 0.70591314, 0.73828912]), action={'0': array([100, 300])}, reward=-395.67929383517975, next_state=array([ 94.97964214, 292.94123416]), next_contact=array([0.28694891, 0.25282341, 0.20935976, 0.19624054]), done=False),\n",
       " Experience(state=array([ 94.97964214, 292.94123416]), contact=array([0.28694891, 0.25282341, 0.20935976, 0.19624054]), action={'1': array([100, 500])}, reward=-441.9816753044017, next_state=array([ 99.05322055, 500.00255551]), next_contact=array([0.58873839, 0.46683523, 0.30095005, 0.51016927]), done=False),\n",
       " Experience(state=array([ 99.05322055, 500.00255551]), contact=array([0.58873839, 0.46683523, 0.30095005, 0.51016927]), action={'2': array([300, 500])}, reward=-319.1787816631407, next_state=array([299.44122575, 499.08139355]), next_contact=array([0.72791182, 0.67224867, 0.80037793, 0.73989506]), done=False),\n",
       " Experience(state=array([299.44122575, 499.08139355]), contact=array([0.72791182, 0.67224867, 0.80037793, 0.73989506]), action={'3': array([300, 300])}, reward=-422.53255775511354, next_state=array([299.76420662, 298.01560227]), next_contact=array([0.17120909, 0.27013364, 0.24045017, 0.19823531]), done=False),\n",
       " Experience(state=array([299.76420662, 298.01560227]), contact=array([0.17120909, 0.27013364, 0.24045017, 0.19823531]), action={'4': array([300, 200])}, reward=-240.12924533491358, next_state=array([300.07577448, 199.09853185]), next_contact=array([0.51371531, 0.50976587, 0.47599555, 0.46409848]), done=False),\n",
       " Experience(state=array([300.07577448, 199.09853185]), contact=array([0.51371531, 0.50976587, 0.47599555, 0.46409848]), action={'5': array([300, 100])}, reward=-190.66127408714462, next_state=array([300.38167077,  97.89307226]), next_contact=array([0.69323095, 0.71602275, 0.8369546 , 0.72665695]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.39851712, 0.3113831 , 0.23731048, 0.3745233 ]), action={'0': array([100, 300])}, reward=-398.5252272448207, next_state=array([ 95.42724381, 295.2837633 ]), next_contact=array([0.46547933, 0.53337903, 0.41197229, 0.46681437]), done=False),\n",
       " Experience(state=array([ 95.42724381, 295.2837633 ]), contact=array([0.46547933, 0.53337903, 0.41197229, 0.46681437]), action={'1': array([100, 500])}, reward=-443.61684690880475, next_state=array([100.76835644, 499.23612578]), next_contact=array([0.89113104, 0.8086373 , 0.79026463, 0.79302046]), done=False),\n",
       " Experience(state=array([100.76835644, 499.23612578]), contact=array([0.89113104, 0.8086373 , 0.79026463, 0.79302046]), action={'2': array([300, 500])}, reward=-323.94224442823247, next_state=array([300.20850042, 500.44749347]), next_contact=array([0.2488444 , 0.25804148, 0.16223976, 0.37175045]), done=False),\n",
       " Experience(state=array([300.20850042, 500.44749347]), contact=array([0.2488444 , 0.25804148, 0.16223976, 0.37175045]), action={'3': array([300, 300])}, reward=-420.18726592182543, next_state=array([300.4468711 , 300.76840809]), next_contact=array([0.38973217, 0.58955616, 0.48960299, 0.53429329]), done=False),\n",
       " Experience(state=array([300.4468711 , 300.76840809]), contact=array([0.38973217, 0.58955616, 0.48960299, 0.53429329]), action={'4': array([300, 200])}, reward=-256.3063054941225, next_state=array([299.08603773, 202.13514432]), next_contact=array([0.77811851, 0.65254734, 0.83006929, 0.87592694]), done=False),\n",
       " Experience(state=array([299.08603773, 202.13514432]), contact=array([0.77811851, 0.65254734, 0.83006929, 0.87592694]), action={'5': array([300, 100])}, reward=-217.63360294077629, next_state=array([301.46425187, 100.16136302]), next_contact=array([0.31603502, 0.14729525, 0.25151286, 0.1953159 ]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.48271152, 0.52213253, 0.46746683, 0.40281023]), action={'0': array([100, 300])}, reward=-427.46161975633964, next_state=array([109.61098371, 309.46903566]), next_contact=array([0.72497393, 0.75307303, 0.84997353, 0.83245153]), done=False),\n",
       " Experience(state=array([109.61098371, 309.46903566]), contact=array([0.72497393, 0.75307303, 0.84997353, 0.83245153]), action={'1': array([100, 500])}, reward=-444.14533069599696, next_state=array([100.43215713, 499.06452171]), next_contact=array([0.44399105, 0.33899544, 0.27275047, 0.28403138]), done=False),\n",
       " Experience(state=array([100.43215713, 499.06452171]), contact=array([0.44399105, 0.33899544, 0.27275047, 0.28403138]), action={'2': array([300, 500])}, reward=-323.92858265829676, next_state=array([299.12001028, 500.3484582 ]), next_contact=array([0.52403475, 0.52246915, 0.41191169, 0.52069334]), done=False),\n",
       " Experience(state=array([299.12001028, 500.3484582 ]), contact=array([0.52403475, 0.52246915, 0.41191169, 0.52069334]), action={'3': array([300, 300])}, reward=-423.40738332097334, next_state=array([299.41865513, 298.25685841]), next_contact=array([0.70867934, 0.79409915, 0.68969267, 0.64423774]), done=False),\n",
       " Experience(state=array([299.41865513, 298.25685841]), contact=array([0.70867934, 0.79409915, 0.68969267, 0.64423774]), action={'4': array([300, 200])}, reward=-240.693480140019, next_state=array([299.80332142, 200.51970828]), next_contact=array([0.21535708, 0.27457877, 0.27212136, 0.35825731]), done=False),\n",
       " Experience(state=array([299.80332142, 200.51970828]), contact=array([0.21535708, 0.27457877, 0.27212136, 0.35825731]), action={'5': array([300, 100])}, reward=-211.88524160153824, next_state=array([301.74970635, 100.50587464]), next_contact=array([0.53977868, 0.37492903, 0.44738362, 0.52214616]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.83899867, 0.76672449, 0.75584799, 0.75906164]), action={'0': array([100, 300])}, reward=-397.7014584411438, next_state=array([ 96.77567975, 293.12771088]), next_contact=array([0.2020007 , 0.2861855 , 0.3365967 , 0.15103831]), done=False),\n",
       " Experience(state=array([ 96.77567975, 293.12771088]), contact=array([0.2020007 , 0.2861855 , 0.3365967 , 0.15103831]), action={'1': array([100, 500])}, reward=-436.6483925423739, next_state=array([ 99.90142084, 498.56645568]), next_contact=array([0.53888227, 0.46238123, 0.46269502, 0.56785406]), done=False),\n",
       " Experience(state=array([ 99.90142084, 498.56645568]), contact=array([0.53888227, 0.46238123, 0.46269502, 0.56785406]), action={'2': array([300, 500])}, reward=-308.39392483242585, next_state=array([299.26719765, 498.97739453]), next_contact=array([0.6518413 , 0.76571853, 0.70517221, 0.72380097]), done=False),\n",
       " Experience(state=array([299.26719765, 498.97739453]), contact=array([0.6518413 , 0.76571853, 0.70517221, 0.72380097]), action={'3': array([300, 300])}, reward=-414.5793025932599, next_state=array([299.37892037, 300.59565675]), next_contact=array([0.33293075, 0.37962757, 0.22466877, 0.26777607]), done=False),\n",
       " Experience(state=array([299.37892037, 300.59565675]), contact=array([0.33293075, 0.37962757, 0.22466877, 0.26777607]), action={'4': array([300, 200])}, reward=-260.17589865230156, next_state=array([300.9612616 , 200.17048253]), next_contact=array([0.51476533, 0.44116426, 0.43849408, 0.4243987 ]), done=False),\n",
       " Experience(state=array([300.9612616 , 200.17048253]), contact=array([0.51476533, 0.44116426, 0.43849408, 0.4243987 ]), action={'5': array([300, 100])}, reward=-198.02571538035164, next_state=array([300.33808271,  97.56197514]), next_contact=array([0.73261284, 0.76521564, 0.62877704, 0.7032169 ]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.19026247, 0.21135432, 0.26398514, 0.2744711 ]), action={'0': array([100, 300])}, reward=-417.0021372100679, next_state=array([103.40506858, 305.42055614]), next_contact=array([0.54574458, 0.51004004, 0.55485668, 0.4879281 ]), done=False),\n",
       " Experience(state=array([103.40506858, 305.42055614]), contact=array([0.54574458, 0.51004004, 0.55485668, 0.4879281 ]), action={'1': array([100, 500])}, reward=-438.03779515608403, next_state=array([ 98.5560324 , 501.80568671]), next_contact=array([0.743189  , 0.76019773, 0.63633544, 0.74758016]), done=False),\n",
       " Experience(state=array([ 98.5560324 , 501.80568671]), contact=array([0.743189  , 0.76019773, 0.63633544, 0.74758016]), action={'2': array([300, 500])}, reward=-293.69456887989304, next_state=array([300.43805894, 501.82262437]), next_contact=array([0.08140207, 0.10290344, 0.25164063, 0.22020424]), done=False),\n",
       " Experience(state=array([300.43805894, 501.82262437]), contact=array([0.08140207, 0.10290344, 0.25164063, 0.22020424]), action={'3': array([300, 300])}, reward=-432.84152982879505, next_state=array([301.27747247, 300.52985085]), next_contact=array([0.46028036, 0.57343643, 0.50472194, 0.38356219]), done=False),\n",
       " Experience(state=array([301.27747247, 300.52985085]), contact=array([0.46028036, 0.57343643, 0.50472194, 0.38356219]), action={'4': array([300, 200])}, reward=-252.37952157285346, next_state=array([300.40316971, 199.80025268]), next_contact=array([0.7079394 , 0.81665662, 0.72417023, 0.75337372]), done=False),\n",
       " Experience(state=array([300.40316971, 199.80025268]), contact=array([0.7079394 , 0.81665662, 0.72417023, 0.75337372]), action={'5': array([300, 100])}, reward=-195.26498435095354, next_state=array([300.99409463, 100.67103024]), next_contact=array([0.30191741, 0.21018197, 0.15829852, 0.29559801]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.58542311, 0.59672672, 0.51723108, 0.42579341]), action={'0': array([100, 300])}, reward=-416.7876881804406, next_state=array([104.38368261, 304.23169796]), next_contact=array([0.66205674, 0.66837537, 0.80575582, 0.69969259]), done=False),\n",
       " Experience(state=array([104.38368261, 304.23169796]), contact=array([0.66205674, 0.66837537, 0.80575582, 0.69969259]), action={'1': array([100, 500])}, reward=-425.0644216577954, next_state=array([102.64461727, 500.7655529 ]), next_contact=array([0.33437981, 0.20194987, 0.2819524 , 0.22834933]), done=False),\n",
       " Experience(state=array([102.64461727, 500.7655529 ]), contact=array([0.33437981, 0.20194987, 0.2819524 , 0.22834933]), action={'2': array([300, 500])}, reward=-305.81186252728907, next_state=array([300.62879917, 500.46826358]), next_contact=array([0.50649465, 0.52045181, 0.53229544, 0.42694757]), done=False),\n",
       " Experience(state=array([300.62879917, 500.46826358]), contact=array([0.50649465, 0.52045181, 0.53229544, 0.42694757]), action={'3': array([300, 300])}, reward=-433.45660059656416, next_state=array([301.57513039, 299.33116262]), next_contact=array([0.86869841, 0.83224411, 0.80830049, 0.54831898]), done=False),\n",
       " Experience(state=array([301.57513039, 299.33116262]), contact=array([0.86869841, 0.83224411, 0.80830049, 0.54831898]), action={'4': array([300, 200])}, reward=-259.41926456780556, next_state=array([299.78035111, 201.35986807]), next_contact=array([0.26811169, 0.24185659, 0.21497662, 0.15871505]), done=False),\n",
       " Experience(state=array([299.78035111, 201.35986807]), contact=array([0.26811169, 0.24185659, 0.21497662, 0.15871505]), action={'5': array([300, 100])}, reward=-210.62525569426168, next_state=array([301.41862645,  99.40657406]), next_contact=array([0.53927483, 0.42839447, 0.47730457, 0.50804354]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.74168811, 0.67304929, 0.87452308, 0.82329922]), action={'0': array([100, 300])}, reward=-397.01702150057145, next_state=array([ 95.51232045, 293.72005357]), next_contact=array([0.19000986, 0.32351953, 0.14444103, 0.21452669]), done=False),\n",
       " Experience(state=array([ 95.51232045, 293.72005357]), contact=array([0.19000986, 0.32351953, 0.14444103, 0.21452669]), action={'1': array([100, 500])}, reward=-440.35559267027435, next_state=array([ 98.73292396, 501.68120689]), next_contact=array([0.48574669, 0.39176155, 0.53088974, 0.55211164]), done=False),\n",
       " Experience(state=array([ 98.73292396, 501.68120689]), contact=array([0.48574669, 0.39176155, 0.53088974, 0.55211164]), action={'2': array([300, 500])}, reward=-330.68358039737393, next_state=array([300.6637732, 500.0672453]), next_contact=array([0.72234047, 0.81019558, 0.7237484 , 0.78408066]), done=False),\n",
       " Experience(state=array([300.6637732, 500.0672453]), contact=array([0.72234047, 0.81019558, 0.7237484 , 0.78408066]), action={'3': array([300, 300])}, reward=-442.3136113934101, next_state=array([298.82794114, 299.4899352 ]), next_contact=array([0.19985911, 0.17400294, 0.25626599, 0.23400188]), done=False),\n",
       " Experience(state=array([298.82794114, 299.4899352 ]), contact=array([0.19985911, 0.17400294, 0.25626599, 0.23400188]), action={'4': array([300, 200])}, reward=-264.1073711548358, next_state=array([300.94203961, 199.55529117]), next_contact=array([0.54305718, 0.48268958, 0.482938  , 0.54474009]), done=False),\n",
       " Experience(state=array([300.94203961, 199.55529117]), contact=array([0.54305718, 0.48268958, 0.482938  , 0.54474009]), action={'5': array([300, 100])}, reward=-191.4711141268677, next_state=array([300.52946704, 101.24575857]), next_contact=array([0.74856054, 0.74797142, 0.71754482, 0.74280545]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.239359  , 0.2141444 , 0.19501186, 0.25074814]), action={'0': array([100, 300])}, reward=-418.9250871817444, next_state=array([104.790611  , 305.92025878]), next_contact=array([0.59027409, 0.39688677, 0.42273214, 0.50804889]), done=False),\n",
       " Experience(state=array([104.790611  , 305.92025878]), contact=array([0.59027409, 0.39688677, 0.42273214, 0.50804889]), action={'1': array([100, 500])}, reward=-434.58146031297895, next_state=array([100.5615591 , 500.87076034]), next_contact=array([0.92162755, 0.84576964, 0.55695884, 0.84899346]), done=False),\n",
       " Experience(state=array([100.5615591 , 500.87076034]), contact=array([0.92162755, 0.84576964, 0.55695884, 0.84899346]), action={'2': array([300, 500])}, reward=-297.83205325388656, next_state=array([300.29326174, 500.95228658]), next_contact=array([0.22973665, 0.20576736, 0.19311491, 0.1005814 ]), done=False),\n",
       " Experience(state=array([300.29326174, 500.95228658]), contact=array([0.22973665, 0.20576736, 0.19311491, 0.1005814 ]), action={'3': array([300, 300])}, reward=-424.86417111299164, next_state=array([299.87653453, 300.62883316]), next_contact=array([0.50119418, 0.55710779, 0.55485561, 0.42166299]), done=False),\n",
       " Experience(state=array([299.87653453, 300.62883316]), contact=array([0.50119418, 0.55710779, 0.55485561, 0.42166299]), action={'4': array([300, 200])}, reward=-241.16653684699065, next_state=array([299.62623942, 200.29316804]), next_contact=array([0.80262663, 0.65986342, 0.85284547, 0.56035525]), done=False),\n",
       " Experience(state=array([299.62623942, 200.29316804]), contact=array([0.80262663, 0.65986342, 0.85284547, 0.56035525]), action={'5': array([300, 100])}, reward=-200.2947908826261, next_state=array([300.5207349 , 100.59745846]), next_contact=array([0.2614304 , 0.18556425, 0.22297357, 0.17451617]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.50813823, 0.51820888, 0.27903524, 0.50421935]), action={'0': array([100, 300])}, reward=-429.41461302570514, next_state=array([110.22237894, 310.77233972]), next_contact=array([0.83381268, 0.78436038, 0.75892808, 0.76377147]), done=False),\n",
       " Experience(state=array([110.22237894, 310.77233972]), contact=array([0.83381268, 0.78436038, 0.75892808, 0.76377147]), action={'1': array([100, 500])}, reward=-443.59805482999, next_state=array([100.43012855, 498.27301464]), next_contact=array([0.24004172, 0.26107518, 0.24598029, 0.35680435]), done=False),\n",
       " Experience(state=array([100.43012855, 498.27301464]), contact=array([0.24004172, 0.26107518, 0.24598029, 0.35680435]), action={'2': array([300, 500])}, reward=-327.1233205228464, next_state=array([301.04429119, 499.6382789 ]), next_contact=array([0.50466884, 0.6793679 , 0.44617598, 0.52166895]), done=False),\n",
       " Experience(state=array([301.04429119, 499.6382789 ]), contact=array([0.50466884, 0.6793679 , 0.44617598, 0.52166895]), action={'3': array([300, 300])}, reward=-421.38241485299216, next_state=array([301.31137547, 298.81311494]), next_contact=array([0.67009794, 0.65624934, 0.74211151, 0.67117566]), done=False),\n",
       " Experience(state=array([301.31137547, 298.81311494]), contact=array([0.67009794, 0.65624934, 0.74211151, 0.67117566]), action={'4': array([300, 200])}, reward=-257.78270516970133, next_state=array([299.82107426, 199.1249313 ]), next_contact=array([0.15911989, 0.24422642, 0.23831668, 0.25934572]), done=False),\n",
       " Experience(state=array([299.82107426, 199.1249313 ]), contact=array([0.15911989, 0.24422642, 0.23831668, 0.25934572]), action={'5': array([300, 100])}, reward=-197.0586713469156, next_state=array([300.55864427, 100.07307704]), next_contact=array([0.46745747, 0.50335362, 0.61557577, 0.54954061]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.82300447, 0.67075699, 0.69882484, 0.87354422]), action={'0': array([100, 300])}, reward=-419.85567684392373, next_state=array([105.8926255 , 305.73058709]), next_contact=array([0.32333301, 0.2777907 , 0.25196393, 0.32140214]), done=False),\n",
       " Experience(state=array([105.8926255 , 305.73058709]), contact=array([0.32333301, 0.2777907 , 0.25196393, 0.32140214]), action={'1': array([100, 500])}, reward=-440.1375675896515, next_state=array([ 99.71148513, 500.17486428]), next_contact=array([0.60401459, 0.53709709, 0.59707812, 0.56361384]), done=False),\n",
       " Experience(state=array([ 99.71148513, 500.17486428]), contact=array([0.60401459, 0.53709709, 0.59707812, 0.56361384]), action={'2': array([300, 500])}, reward=-297.91263287006507, next_state=array([300.73402699, 500.10518632]), next_contact=array([0.87430008, 0.77559231, 0.66150117, 0.76069628]), done=False),\n",
       " Experience(state=array([300.73402699, 500.10518632]), contact=array([0.87430008, 0.77559231, 0.66150117, 0.76069628]), action={'3': array([300, 300])}, reward=-428.11889583050953, next_state=array([300.04135661, 301.07276511]), next_contact=array([0.22915929, 0.21457966, 0.15171629, 0.37788036]), done=False),\n",
       " Experience(state=array([300.04135661, 301.07276511]), contact=array([0.22915929, 0.21457966, 0.15171629, 0.37788036]), action={'4': array([300, 200])}, reward=-259.06142208435506, next_state=array([301.34325565, 198.91832594]), next_contact=array([0.45917284, 0.53277581, 0.38715424, 0.56108577]), done=False),\n",
       " Experience(state=array([301.34325565, 198.91832594]), contact=array([0.45917284, 0.53277581, 0.38715424, 0.56108577]), action={'5': array([300, 100])}, reward=-213.031566042449, next_state=array([299.15325187,  98.89936583]), next_contact=array([0.83136633, 0.66514787, 0.68614805, 0.71049468]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.27506386, 0.26926264, 0.19703443, 0.33443406]), action={'0': array([100, 300])}, reward=-418.6513798267361, next_state=array([103.03348851, 307.40904073]), next_contact=array([0.56397089, 0.41974023, 0.56312082, 0.55447817]), done=False),\n",
       " Experience(state=array([103.03348851, 307.40904073]), contact=array([0.56397089, 0.41974023, 0.56312082, 0.55447817]), action={'1': array([100, 500])}, reward=-427.06210869932073, next_state=array([100.01586307, 499.68501993]), next_contact=array([0.64675661, 0.88068185, 0.72870827, 0.65835852]), done=False),\n",
       " Experience(state=array([100.01586307, 499.68501993]), contact=array([0.64675661, 0.88068185, 0.72870827, 0.65835852]), action={'2': array([300, 500])}, reward=-313.33209206077265, next_state=array([299.61480523, 500.29807916]), next_contact=array([0.27177555, 0.17878251, 0.23736313, 0.30921344]), done=False),\n",
       " Experience(state=array([299.61480523, 500.29807916]), contact=array([0.27177555, 0.17878251, 0.23736313, 0.30921344]), action={'3': array([300, 300])}, reward=-435.2075940785591, next_state=array([300.84842412, 301.21729094]), next_contact=array([0.57209537, 0.44929602, 0.58054777, 0.51091669]), done=False),\n",
       " Experience(state=array([300.84842412, 301.21729094]), contact=array([0.57209537, 0.44929602, 0.58054777, 0.51091669]), action={'4': array([300, 200])}, reward=-247.82198915916337, next_state=array([301.35526913, 199.71274476]), next_contact=array([0.78680778, 0.7224595 , 0.73537301, 0.86620361]), done=False),\n",
       " Experience(state=array([301.35526913, 199.71274476]), contact=array([0.78680778, 0.7224595 , 0.73537301, 0.86620361]), action={'5': array([300, 100])}, reward=-183.93903533006844, next_state=array([301.43746307,  99.27004852]), next_contact=array([0.25393152, 0.20790013, 0.35312071, 0.38543386]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.54116463, 0.5186822 , 0.49273861, 0.33035403]), action={'0': array([100, 300])}, reward=-427.9134510778883, next_state=array([110.56886873, 308.95412252]), next_contact=array([0.84144878, 0.78216694, 0.81441365, 0.83106062]), done=False),\n",
       " Experience(state=array([110.56886873, 308.95412252]), contact=array([0.84144878, 0.78216694, 0.81441365, 0.83106062]), action={'1': array([100, 500])}, reward=-450.74649051772906, next_state=array([ 99.5219531 , 500.47814767]), next_contact=array([0.13719167, 0.34883551, 0.2788285 , 0.27286648]), done=False),\n",
       " Experience(state=array([ 99.5219531 , 500.47814767]), contact=array([0.13719167, 0.34883551, 0.2788285 , 0.27286648]), action={'2': array([300, 500])}, reward=-304.1344439166497, next_state=array([300.37481429, 500.26037807]), next_contact=array([0.5078197 , 0.41321779, 0.56481948, 0.4520772 ]), done=False),\n",
       " Experience(state=array([300.37481429, 500.26037807]), contact=array([0.5078197 , 0.41321779, 0.56481948, 0.4520772 ]), action={'3': array([300, 300])}, reward=-425.5768588516458, next_state=array([299.9065176, 299.8124742]), next_contact=array([0.67262495, 0.77678802, 0.69225167, 0.71933545]), done=False),\n",
       " Experience(state=array([299.9065176, 299.8124742]), contact=array([0.67262495, 0.77678802, 0.69225167, 0.71933545]), action={'4': array([300, 200])}, reward=-231.20149645978984, next_state=array([299.94220335, 201.45745655]), next_contact=array([0.35013458, 0.26471559, 0.14605974, 0.23200699]), done=False),\n",
       " Experience(state=array([299.94220335, 201.45745655]), contact=array([0.35013458, 0.26471559, 0.14605974, 0.23200699]), action={'5': array([300, 100])}, reward=-194.94662241938747, next_state=array([300.40968921, 100.89469631]), next_contact=array([0.47744621, 0.59129624, 0.46151398, 0.50187856]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.84300344, 0.75118874, 0.77783738, 0.81824994]), action={'0': array([100, 300])}, reward=-416.3801103271191, next_state=array([104.14304888, 304.07274556]), next_contact=array([0.32060665, 0.39918162, 0.23883901, 0.29146763]), done=False),\n",
       " Experience(state=array([104.14304888, 304.07274556]), contact=array([0.32060665, 0.39918162, 0.23883901, 0.29146763]), action={'1': array([100, 500])}, reward=-433.57789231758557, next_state=array([100.82117827, 501.6449486 ]), next_contact=array([0.48431091, 0.47356136, 0.47593012, 0.49122988]), done=False),\n",
       " Experience(state=array([100.82117827, 501.6449486 ]), contact=array([0.48431091, 0.47356136, 0.47593012, 0.49122988]), action={'2': array([300, 500])}, reward=-327.55789537969565, next_state=array([299.84360296, 500.14605414]), next_contact=array([0.88573275, 0.59399419, 0.71163004, 0.68060072]), done=False),\n",
       " Experience(state=array([299.84360296, 500.14605414]), contact=array([0.88573275, 0.59399419, 0.71163004, 0.68060072]), action={'3': array([300, 300])}, reward=-412.1936134594883, next_state=array([299.81681368, 300.10564226]), next_contact=array([0.3180433 , 0.15576215, 0.15889238, 0.11547347]), done=False),\n",
       " Experience(state=array([299.81681368, 300.10564226]), contact=array([0.3180433 , 0.15576215, 0.15889238, 0.11547347]), action={'4': array([300, 200])}, reward=-258.07408724729976, next_state=array([301.28785889, 200.52576941]), next_contact=array([0.51871796, 0.61079041, 0.44756973, 0.48898891]), done=False),\n",
       " Experience(state=array([301.28785889, 200.52576941]), contact=array([0.51871796, 0.61079041, 0.44756973, 0.48898891]), action={'5': array([300, 100])}, reward=-208.12042364338865, next_state=array([299.72165736, 100.78316537]), next_contact=array([0.8100533 , 0.80697428, 0.78680697, 0.64263828]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.14065732, 0.19124391, 0.20020559, 0.25632973]), action={'0': array([100, 300])}, reward=-388.93775523434056, next_state=array([ 90.0023388 , 291.30918594]), next_contact=array([0.56244069, 0.54342036, 0.47201896, 0.49196663]), done=False),\n",
       " Experience(state=array([ 90.0023388 , 291.30918594]), contact=array([0.56244069, 0.54342036, 0.47201896, 0.49196663]), action={'1': array([100, 500])}, reward=-457.15875279934994, next_state=array([ 99.84367459, 498.86091161]), next_contact=array([0.6340823 , 0.79544686, 0.81249558, 0.77917788]), done=False),\n",
       " Experience(state=array([ 99.84367459, 498.86091161]), contact=array([0.6340823 , 0.79544686, 0.81249558, 0.77917788]), action={'2': array([300, 500])}, reward=-312.6914572266915, next_state=array([299.29897729, 499.45755938]), next_contact=array([0.24035021, 0.28648949, 0.14056693, 0.32400479]), done=False),\n",
       " Experience(state=array([299.29897729, 499.45755938]), contact=array([0.24035021, 0.28648949, 0.14056693, 0.32400479]), action={'3': array([300, 300])}, reward=-432.0369368405422, next_state=array([300.30558007, 300.43031749]), next_contact=array([0.50191995, 0.51851644, 0.28661101, 0.52646147]), done=False),\n",
       " Experience(state=array([300.30558007, 300.43031749]), contact=array([0.50191995, 0.51851644, 0.28661101, 0.52646147]), action={'4': array([300, 200])}, reward=-252.13367403427088, next_state=array([299.37645417, 200.668951  ]), next_contact=array([0.80561562, 0.85563614, 0.73031805, 0.69217865]), done=False),\n",
       " Experience(state=array([299.37645417, 200.668951  ]), contact=array([0.80561562, 0.85563614, 0.73031805, 0.69217865]), action={'5': array([300, 100])}, reward=-194.1143476681977, next_state=array([300.01232397,  98.92300674]), next_contact=array([0.2832611 , 0.14824975, 0.34995483, 0.26957809]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.46623092, 0.50156978, 0.52369262, 0.47860706]), action={'0': array([100, 300])}, reward=-400.16875640542713, next_state=array([ 95.44428822, 296.87802198]), next_contact=array([0.73973169, 0.79352715, 0.76379137, 0.75922461]), done=False),\n",
       " Experience(state=array([ 95.44428822, 296.87802198]), contact=array([0.73973169, 0.79352715, 0.76379137, 0.75922461]), action={'1': array([100, 500])}, reward=-441.28277672663114, next_state=array([ 99.85355534, 500.77500934]), next_contact=array([0.3141569 , 0.21498223, 0.30992241, 0.31123163]), done=False),\n",
       " Experience(state=array([ 99.85355534, 500.77500934]), contact=array([0.3141569 , 0.21498223, 0.30992241, 0.31123163]), action={'2': array([300, 500])}, reward=-317.9010889420821, next_state=array([298.17026518, 499.83220729]), next_contact=array([0.44636757, 0.56959725, 0.43725324, 0.42779966]), done=False),\n",
       " Experience(state=array([298.17026518, 499.83220729]), contact=array([0.44636757, 0.56959725, 0.43725324, 0.42779966]), action={'3': array([300, 300])}, reward=-427.8499239692741, next_state=array([298.89009553, 301.40836759]), next_contact=array([0.66065795, 0.69878879, 0.69370404, 0.83981534]), done=False),\n",
       " Experience(state=array([298.89009553, 301.40836759]), contact=array([0.66065795, 0.69878879, 0.69370404, 0.83981534]), action={'4': array([300, 200])}, reward=-243.24030431815214, next_state=array([298.65427751, 198.74437189]), next_contact=array([0.207908  , 0.31932168, 0.23200253, 0.23496565]), done=False),\n",
       " Experience(state=array([298.65427751, 198.74437189]), contact=array([0.207908  , 0.31932168, 0.23200253, 0.23496565]), action={'5': array([300, 100])}, reward=-195.9774130143721, next_state=array([299.3975788 , 101.19761868]), next_contact=array([0.44280679, 0.47529462, 0.47141406, 0.52297563]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.62790461, 0.69991429, 0.74053494, 0.78997498]), action={'0': array([100, 300])}, reward=-396.30490121505744, next_state=array([ 94.57193687, 293.96228   ]), next_contact=array([0.19982286, 0.24233337, 0.1586794 , 0.20408462]), done=False),\n",
       " Experience(state=array([ 94.57193687, 293.96228   ]), contact=array([0.19982286, 0.24233337, 0.1586794 , 0.20408462]), action={'1': array([100, 500])}, reward=-443.63766469285, next_state=array([ 99.36593944, 499.99141656]), next_contact=array([0.55009583, 0.44105775, 0.50410772, 0.56315374]), done=False),\n",
       " Experience(state=array([ 99.36593944, 499.99141656]), contact=array([0.55009583, 0.44105775, 0.50410772, 0.56315374]), action={'2': array([300, 500])}, reward=-311.11633944511465, next_state=array([301.45242036, 500.40786244]), next_contact=array([0.73114661, 0.76448447, 0.75100481, 0.7047765 ]), done=False),\n",
       " Experience(state=array([301.45242036, 500.40786244]), contact=array([0.73114661, 0.76448447, 0.75100481, 0.7047765 ]), action={'3': array([300, 300])}, reward=-429.5821257573145, next_state=array([300.7360873 , 300.16034228]), next_contact=array([0.1464494 , 0.20254083, 0.31502448, 0.23780172]), done=False),\n",
       " Experience(state=array([300.7360873 , 300.16034228]), contact=array([0.1464494 , 0.20254083, 0.31502448, 0.23780172]), action={'4': array([300, 200])}, reward=-245.41108622863985, next_state=array([300.173893  , 201.77944975]), next_contact=array([0.4352923 , 0.47047318, 0.56617957, 0.56319618]), done=False),\n",
       " Experience(state=array([300.173893  , 201.77944975]), contact=array([0.4352923 , 0.47047318, 0.56617957, 0.56319618]), action={'5': array([300, 100])}, reward=-200.49741430586207, next_state=array([299.43367508,  99.57507882]), next_contact=array([0.79350659, 0.75831144, 0.6747059 , 0.76959026]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.1638995 , 0.42865966, 0.18100069, 0.16050608]), action={'0': array([100, 300])}, reward=-388.6726660333777, next_state=array([ 90.57762717, 290.4740062 ]), next_contact=array([0.54940947, 0.53186375, 0.53334087, 0.61996033]), done=False),\n",
       " Experience(state=array([ 90.57762717, 290.4740062 ]), contact=array([0.54940947, 0.53186375, 0.53334087, 0.61996033]), action={'1': array([100, 500])}, reward=-456.80822050229665, next_state=array([ 98.86219587, 501.03006531]), next_contact=array([0.70277281, 0.86756342, 0.71421068, 0.74038937]), done=False),\n",
       " Experience(state=array([ 98.86219587, 501.03006531]), contact=array([0.70277281, 0.86756342, 0.71421068, 0.74038937]), action={'2': array([300, 500])}, reward=-338.912521310866, next_state=array([299.45521458, 498.56873505]), next_contact=array([0.0863401 , 0.20417856, 0.32863985, 0.12791763]), done=False),\n",
       " Experience(state=array([299.45521458, 498.56873505]), contact=array([0.0863401 , 0.20417856, 0.32863985, 0.12791763]), action={'3': array([300, 300])}, reward=-438.1687195134156, next_state=array([297.80231792, 300.06916214]), next_contact=array([0.4948571 , 0.54779878, 0.57083135, 0.56849497]), done=False),\n",
       " Experience(state=array([297.80231792, 300.06916214]), contact=array([0.4948571 , 0.54779878, 0.57083135, 0.56849497]), action={'4': array([300, 200])}, reward=-242.5445590549398, next_state=array([298.16271367, 200.63158667]), next_contact=array([0.65912528, 0.69155515, 0.74816257, 0.75686651]), done=False),\n",
       " Experience(state=array([298.16271367, 200.63158667]), contact=array([0.65912528, 0.69155515, 0.74816257, 0.75686651]), action={'5': array([300, 100])}, reward=-207.2927513528428, next_state=array([300.01864913,  99.93160315]), next_contact=array([0.2321398 , 0.23305351, 0.28636772, 0.28042113]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.56160867, 0.5659806 , 0.48102968, 0.39388005]), action={'0': array([100, 300])}, reward=-400.90755411316354, next_state=array([ 97.12447417, 295.92214751]), next_contact=array([0.76709884, 0.71882804, 0.7987415 , 0.8111147 ]), done=False),\n",
       " Experience(state=array([ 97.12447417, 295.92214751]), contact=array([0.76709884, 0.71882804, 0.7987415 , 0.8111147 ]), action={'1': array([100, 500])}, reward=-439.8799387956637, next_state=array([100.79398747, 501.03182913]), next_contact=array([0.12789416, 0.24033507, 0.34026094, 0.22923526]), done=False),\n",
       " Experience(state=array([100.79398747, 501.03182913]), contact=array([0.12789416, 0.24033507, 0.34026094, 0.22923526]), action={'2': array([300, 500])}, reward=-335.3040561522951, next_state=array([298.71824366, 498.77228918]), next_contact=array([0.42577701, 0.50186469, 0.60670503, 0.57914041]), done=False),\n",
       " Experience(state=array([298.71824366, 498.77228918]), contact=array([0.42577701, 0.50186469, 0.60670503, 0.57914041]), action={'3': array([300, 300])}, reward=-433.7209766636301, next_state=array([299.89743678, 299.75561448]), next_contact=array([0.72013042, 0.74214328, 0.59358106, 0.66239839]), done=False),\n",
       " Experience(state=array([299.89743678, 299.75561448]), contact=array([0.72013042, 0.74214328, 0.59358106, 0.66239839]), action={'4': array([300, 200])}, reward=-232.7261814127683, next_state=array([299.91744227, 198.40322982]), next_contact=array([0.2253002 , 0.27927967, 0.10140666, 0.19630134]), done=False),\n",
       " Experience(state=array([299.91744227, 198.40322982]), contact=array([0.2253002 , 0.27927967, 0.10140666, 0.19630134]), action={'5': array([300, 100])}, reward=-188.10977758615857, next_state=array([300.21443529, 100.49176334]), next_contact=array([0.47070274, 0.49772623, 0.53920034, 0.50587229]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.77819304, 0.7899398 , 0.74405483, 0.76275751]), action={'0': array([100, 300])}, reward=-401.54829875489986, next_state=array([ 95.97643959, 297.69836311]), next_contact=array([0.37863013, 0.25993687, 0.33236041, 0.30093025]), done=False),\n",
       " Experience(state=array([ 95.97643959, 297.69836311]), contact=array([0.37863013, 0.25993687, 0.33236041, 0.30093025]), action={'1': array([100, 500])}, reward=-434.60980822980514, next_state=array([ 99.49323391, 498.51751482]), next_contact=array([0.41396653, 0.44714966, 0.4969389 , 0.47202715]), done=False),\n",
       " Experience(state=array([ 99.49323391, 498.51751482]), contact=array([0.41396653, 0.44714966, 0.4969389 , 0.47202715]), action={'2': array([300, 500])}, reward=-305.24417316140153, next_state=array([301.06442426, 498.74644085]), next_contact=array([0.72605719, 0.73440044, 0.75494809, 0.75912646]), done=False),\n",
       " Experience(state=array([301.06442426, 498.74644085]), contact=array([0.72605719, 0.73440044, 0.75494809, 0.75912646]), action={'3': array([300, 300])}, reward=-425.1022489222139, next_state=array([301.64592029, 300.51192862]), next_contact=array([0.29202919, 0.10379962, 0.23271566, 0.33091454]), done=False),\n",
       " Experience(state=array([301.64592029, 300.51192862]), contact=array([0.29202919, 0.10379962, 0.23271566, 0.33091454]), action={'4': array([300, 200])}, reward=-262.3388821949985, next_state=array([299.67779757, 201.66949416]), next_contact=array([0.53190384, 0.56220644, 0.50353058, 0.57445067]), done=False),\n",
       " Experience(state=array([299.67779757, 201.66949416]), contact=array([0.53190384, 0.56220644, 0.50353058, 0.57445067]), action={'5': array([300, 100])}, reward=-189.57140166271236, next_state=array([299.47358587, 100.58831059]), next_contact=array([0.72530907, 0.63440486, 0.72267298, 0.69831615]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.26258117, 0.19745657, 0.32306418, 0.190643  ]), action={'0': array([100, 300])}, reward=-419.1270180382005, next_state=array([105.57399644, 305.33484478]), next_contact=array([0.4389403 , 0.39908618, 0.58744654, 0.35540661]), done=False),\n",
       " Experience(state=array([105.57399644, 305.33484478]), contact=array([0.4389403 , 0.39908618, 0.58744654, 0.35540661]), action={'1': array([100, 500])}, reward=-444.46275701248004, next_state=array([ 98.1363186 , 500.69746032]), next_contact=array([0.65376392, 0.8634204 , 0.70951371, 0.7032295 ]), done=False),\n",
       " Experience(state=array([ 98.1363186 , 500.69746032]), contact=array([0.65376392, 0.8634204 , 0.70951371, 0.7032295 ]), action={'2': array([300, 500])}, reward=-310.828795009136, next_state=array([299.76053591, 501.15854495]), next_contact=array([0.2498875 , 0.29469199, 0.17339056, 0.14786541]), done=False),\n",
       " Experience(state=array([299.76053591, 501.15854495]), contact=array([0.2498875 , 0.29469199, 0.17339056, 0.14786541]), action={'3': array([300, 300])}, reward=-441.49183306175837, next_state=array([301.4939559 , 301.19479681]), next_contact=array([0.58688236, 0.61451536, 0.51474035, 0.49550581]), done=False),\n",
       " Experience(state=array([301.4939559 , 301.19479681]), contact=array([0.58688236, 0.61451536, 0.51474035, 0.49550581]), action={'4': array([300, 200])}, reward=-253.33990798384204, next_state=array([300.60166293, 200.01503456]), next_contact=array([0.73200828, 0.81773636, 0.61945985, 0.63506147]), done=False),\n",
       " Experience(state=array([300.60166293, 200.01503456]), contact=array([0.73200828, 0.81773636, 0.61945985, 0.63506147]), action={'5': array([300, 100])}, reward=-188.58803683245472, next_state=array([300.81612417,  99.45964785]), next_contact=array([0.29196353, 0.07712054, 0.22874458, 0.32562105]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.46231333, 0.55196939, 0.43736638, 0.56884867]), action={'0': array([100, 300])}, reward=-420.2882888675319, next_state=array([106.67890901, 305.36843301]), next_contact=array([0.86082728, 0.76057285, 0.60319738, 0.68610096]), done=False),\n",
       " Experience(state=array([106.67890901, 305.36843301]), contact=array([0.86082728, 0.76057285, 0.60319738, 0.68610096]), action={'1': array([100, 500])}, reward=-440.31087416772635, next_state=array([100.31874498, 499.58547848]), next_contact=array([0.21601709, 0.27469131, 0.31921752, 0.21743344]), done=False),\n",
       " Experience(state=array([100.31874498, 499.58547848]), contact=array([0.21601709, 0.27469131, 0.31921752, 0.21743344]), action={'2': array([300, 500])}, reward=-318.7104008345891, next_state=array([300.44236069, 500.44172113]), next_contact=array([0.57312969, 0.43877772, 0.40158301, 0.47897726]), done=False),\n",
       " Experience(state=array([300.44236069, 500.44172113]), contact=array([0.57312969, 0.43877772, 0.40158301, 0.47897726]), action={'3': array([300, 300])}, reward=-432.92032179697566, next_state=array([299.47490167, 300.28247861]), next_contact=array([0.81400549, 0.75344955, 0.64733627, 0.61048643]), done=False),\n",
       " Experience(state=array([299.47490167, 300.28247861]), contact=array([0.81400549, 0.75344955, 0.64733627, 0.61048643]), action={'4': array([300, 200])}, reward=-245.84924866604175, next_state=array([300.01137705, 200.99278569]), next_contact=array([0.14894562, 0.22696646, 0.21570127, 0.15505387]), done=False),\n",
       " Experience(state=array([300.01137705, 200.99278569]), contact=array([0.14894562, 0.22696646, 0.21570127, 0.15505387]), action={'5': array([300, 100])}, reward=-197.91315927708334, next_state=array([299.36819429,  99.91700469]), next_contact=array([0.5580622 , 0.56398071, 0.47167677, 0.49611185]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.80094266, 0.86953214, 0.65533542, 0.74842075]), action={'0': array([100, 300])}, reward=-388.81806824289214, next_state=array([ 90.06965474, 291.12452981]), next_contact=array([0.23907166, 0.31426156, 0.20488825, 0.06973075]), done=False),\n",
       " Experience(state=array([ 90.06965474, 291.12452981]), contact=array([0.23907166, 0.31426156, 0.20488825, 0.06973075]), action={'1': array([100, 500])}, reward=-455.68492066430053, next_state=array([ 98.33298937, 500.64081996]), next_contact=array([0.43838934, 0.47826758, 0.45255691, 0.46318021]), done=False),\n",
       " Experience(state=array([ 98.33298937, 500.64081996]), contact=array([0.43838934, 0.47826758, 0.45255691, 0.46318021]), action={'2': array([300, 500])}, reward=-334.4552776092359, next_state=array([300.66595134, 498.72414378]), next_contact=array([0.66432847, 0.92185576, 0.69665332, 0.81407553]), done=False),\n",
       " Experience(state=array([300.66595134, 498.72414378]), contact=array([0.66432847, 0.92185576, 0.69665332, 0.81407553]), action={'3': array([300, 300])}, reward=-414.70359719177685, next_state=array([300.7700641 , 299.66102671]), next_contact=array([0.12202955, 0.35644347, 0.19023139, 0.13977533]), done=False),\n",
       " Experience(state=array([300.7700641 , 299.66102671]), contact=array([0.12202955, 0.35644347, 0.19023139, 0.13977533]), action={'4': array([300, 200])}, reward=-267.1697266525242, next_state=array([298.2683628 , 199.92483783]), next_contact=array([0.4640819 , 0.46717887, 0.50530066, 0.55365439]), done=False),\n",
       " Experience(state=array([298.2683628 , 199.92483783]), contact=array([0.4640819 , 0.46717887, 0.50530066, 0.55365439]), action={'5': array([300, 100])}, reward=-201.90767625848423, next_state=array([299.65036239,  99.92457135]), next_contact=array([0.87794192, 0.64724207, 0.83790376, 0.75271643]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.16725662, 0.18913921, 0.21184757, 0.17282582]), action={'0': array([100, 300])}, reward=-395.8489465619294, next_state=array([ 93.8733142 , 294.21388831]), next_contact=array([0.55539006, 0.60415358, 0.52317764, 0.503443  ]), done=False),\n",
       " Experience(state=array([ 93.8733142 , 294.21388831]), contact=array([0.55539006, 0.60415358, 0.52317764, 0.503443  ]), action={'1': array([100, 500])}, reward=-450.49154999618406, next_state=array([100.96076936, 500.18058765]), next_contact=array([0.79607109, 0.736929  , 0.76849951, 0.79526357]), done=False),\n",
       " Experience(state=array([100.96076936, 500.18058765]), contact=array([0.79607109, 0.736929  , 0.76849951, 0.79526357]), action={'2': array([300, 500])}, reward=-307.69151781000323, next_state=array([300.54535745, 500.5254895 ]), next_contact=array([0.23012397, 0.23666203, 0.18077916, 0.35914416]), done=False),\n",
       " Experience(state=array([300.54535745, 500.5254895 ]), contact=array([0.23012397, 0.23666203, 0.18077916, 0.35914416]), action={'3': array([300, 300])}, reward=-436.13910747754005, next_state=array([299.36855704, 299.51803662]), next_contact=array([0.51147967, 0.44542132, 0.42896313, 0.45544049]), done=False),\n",
       " Experience(state=array([299.36855704, 299.51803662]), contact=array([0.51147967, 0.44542132, 0.42896313, 0.45544049]), action={'4': array([300, 200])}, reward=-245.56232624592923, next_state=array([298.9305047 , 198.20349308]), next_contact=array([0.70769653, 0.78910949, 0.62278199, 0.70531918]), done=False),\n",
       " Experience(state=array([298.9305047 , 198.20349308]), contact=array([0.70769653, 0.78910949, 0.62278199, 0.70531918]), action={'5': array([300, 100])}, reward=-205.86354839446574, next_state=array([300.57528844, 101.19183781]), next_contact=array([0.32356036, 0.16310687, 0.15701671, 0.24470799]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.41939329, 0.58642297, 0.35386684, 0.45177415]), action={'0': array([100, 300])}, reward=-386.71728457394624, next_state=array([ 89.39104071, 289.74355201]), next_contact=array([0.74148335, 0.82762972, 0.84368034, 0.73868622]), done=False),\n",
       " Experience(state=array([ 89.39104071, 289.74355201]), contact=array([0.74148335, 0.82762972, 0.84368034, 0.73868622]), action={'1': array([100, 500])}, reward=-463.96127141405344, next_state=array([100.16816447, 501.7740064 ]), next_contact=array([0.13197949, 0.23342198, 0.38585259, 0.21191304]), done=False),\n",
       " Experience(state=array([100.16816447, 501.7740064 ]), contact=array([0.13197949, 0.23342198, 0.38585259, 0.21191304]), action={'2': array([300, 500])}, reward=-323.1937751770521, next_state=array([300.03235599, 500.61811006]), next_contact=array([0.46963151, 0.55612286, 0.57559573, 0.53668347]), done=False),\n",
       " Experience(state=array([300.03235599, 500.61811006]), contact=array([0.46963151, 0.55612286, 0.57559573, 0.53668347]), action={'3': array([300, 300])}, reward=-420.63089572318836, next_state=array([300.26532883, 300.28712169]), next_contact=array([0.65650383, 0.78374644, 0.64029037, 0.7951331 ]), done=False),\n",
       " Experience(state=array([300.26532883, 300.28712169]), contact=array([0.65650383, 0.78374644, 0.64029037, 0.7951331 ]), action={'4': array([300, 200])}, reward=-254.4547958643203, next_state=array([299.23061835, 199.36237293]), next_contact=array([0.11293629, 0.23059746, 0.20943904, 0.18980971]), done=False),\n",
       " Experience(state=array([299.23061835, 199.36237293]), contact=array([0.11293629, 0.23059746, 0.20943904, 0.18980971]), action={'5': array([300, 100])}, reward=-194.1898798065095, next_state=array([298.7334512 ,  98.83233304]), next_contact=array([0.5544986 , 0.3937808 , 0.49940866, 0.42102775]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.78246599, 0.66561181, 0.76586203, 0.86711636]), action={'0': array([100, 300])}, reward=-396.2309780232024, next_state=array([ 94.6344314 , 293.82731176]), next_contact=array([0.17143734, 0.24834386, 0.31322945, 0.03582948]), done=False),\n",
       " Experience(state=array([ 94.6344314 , 293.82731176]), contact=array([0.17143734, 0.24834386, 0.31322945, 0.03582948]), action={'1': array([100, 500])}, reward=-448.5192055714269, next_state=array([100.98694447, 499.93284424]), next_contact=array([0.42015181, 0.41172329, 0.48943153, 0.52283624]), done=False),\n",
       " Experience(state=array([100.98694447, 499.93284424]), contact=array([0.42015181, 0.41172329, 0.48943153, 0.52283624]), action={'2': array([300, 500])}, reward=-308.49180176376234, next_state=array([300.11482145, 499.53944055]), next_contact=array([0.78926351, 0.857703  , 0.62856221, 0.78425804]), done=False),\n",
       " Experience(state=array([300.11482145, 499.53944055]), contact=array([0.78926351, 0.857703  , 0.62856221, 0.78425804]), action={'3': array([300, 300])}, reward=-425.867632179718, next_state=array([299.59540437, 299.40823316]), next_contact=array([0.07477045, 0.1889659 , 0.1244183 , 0.27315474]), done=False),\n",
       " Experience(state=array([299.59540437, 299.40823316]), contact=array([0.07477045, 0.1889659 , 0.1244183 , 0.27315474]), action={'4': array([300, 200])}, reward=-243.3067902208112, next_state=array([299.18091244, 200.033577  ]), next_contact=array([0.45315834, 0.61677808, 0.48611643, 0.49906629]), done=False),\n",
       " Experience(state=array([299.18091244, 200.033577  ]), contact=array([0.45315834, 0.61677808, 0.48611643, 0.49906629]), action={'5': array([300, 100])}, reward=-201.55332833561235, next_state=array([300.23017706, 101.23922781]), next_contact=array([0.68973467, 0.74931321, 0.62110854, 0.79559364]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.30335356, 0.38159967, 0.25071957, 0.11660069]), action={'0': array([100, 300])}, reward=-428.48260778903506, next_state=array([109.67291875, 310.40806928]), next_contact=array([0.51407371, 0.49260821, 0.57816657, 0.40120342]), done=False),\n",
       " Experience(state=array([109.67291875, 310.40806928]), contact=array([0.51407371, 0.49260821, 0.57816657, 0.40120342]), action={'1': array([100, 500])}, reward=-449.26616520046946, next_state=array([ 99.52912416, 501.89363971]), next_contact=array([0.78573525, 0.70273704, 0.77807697, 0.65489839]), done=False),\n",
       " Experience(state=array([ 99.52912416, 501.89363971]), contact=array([0.78573525, 0.70273704, 0.77807697, 0.65489839]), action={'2': array([300, 500])}, reward=-323.1292640329007, next_state=array([298.37217928, 500.63580592]), next_contact=array([0.28937543, 0.12472176, 0.27599272, 0.29479022]), done=False),\n",
       " Experience(state=array([298.37217928, 500.63580592]), contact=array([0.28937543, 0.12472176, 0.27599272, 0.29479022]), action={'3': array([300, 300])}, reward=-445.12536588667365, next_state=array([300.50711623, 300.20582724]), next_contact=array([0.51843929, 0.63758357, 0.49019181, 0.51238333]), done=False),\n",
       " Experience(state=array([300.50711623, 300.20582724]), contact=array([0.51843929, 0.63758357, 0.49019181, 0.51238333]), action={'4': array([300, 200])}, reward=-233.39418530981285, next_state=array([300.48817865, 198.2383737 ]), next_contact=array([0.78793484, 0.731641  , 0.83514273, 0.66990265]), done=False),\n",
       " Experience(state=array([300.48817865, 198.2383737 ]), contact=array([0.78793484, 0.731641  , 0.83514273, 0.66990265]), action={'5': array([300, 100])}, reward=-201.4659845580282, next_state=array([299.3727578 ,  99.17236529]), next_contact=array([0.21979183, 0.17839126, 0.21051608, 0.19600289]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.49604665, 0.48234902, 0.40328387, 0.45703236]), action={'0': array([100, 300])}, reward=-389.2164730020357, next_state=array([ 90.32616367, 291.25861378]), next_contact=array([0.68328481, 0.78854033, 0.75608871, 0.8261397 ]), done=False),\n",
       " Experience(state=array([ 90.32616367, 291.25861378]), contact=array([0.68328481, 0.78854033, 0.75608871, 0.8261397 ]), action={'1': array([100, 500])}, reward=-454.5732794404045, next_state=array([ 98.46231682, 500.04788521]), next_contact=array([0.40080561, 0.2734479 , 0.39085616, 0.18132491]), done=False),\n",
       " Experience(state=array([ 98.46231682, 500.04788521]), contact=array([0.40080561, 0.2734479 , 0.39085616, 0.18132491]), action={'2': array([300, 500])}, reward=-297.8813274960889, next_state=array([301.20890322, 499.99343253]), next_contact=array([0.42378166, 0.43444801, 0.5309413 , 0.42435784]), done=False),\n",
       " Experience(state=array([301.20890322, 499.99343253]), contact=array([0.42378166, 0.43444801, 0.5309413 , 0.42435784]), action={'3': array([300, 300])}, reward=-426.5954342321995, next_state=array([300.70106876, 298.98991722]), next_contact=array([0.66009575, 0.78614306, 0.67370365, 0.8131485 ]), done=False),\n",
       " Experience(state=array([300.70106876, 298.98991722]), contact=array([0.66009575, 0.78614306, 0.67370365, 0.8131485 ]), action={'4': array([300, 200])}, reward=-241.17518181885973, next_state=array([300.3530839, 200.2950019]), next_contact=array([0.2307965 , 0.24453237, 0.18859219, 0.33651291]), done=False),\n",
       " Experience(state=array([300.3530839, 200.2950019]), contact=array([0.2307965 , 0.24453237, 0.18859219, 0.33651291]), action={'5': array([300, 100])}, reward=-187.30741268302603, next_state=array([300.03423387, 100.12861421]), next_contact=array([0.49555033, 0.54442001, 0.64249389, 0.3126535 ]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.72006407, 0.74414243, 0.79598609, 0.76215518]), action={'0': array([100, 300])}, reward=-399.7333486162229, next_state=array([ 95.18982746, 296.70561236]), next_contact=array([0.35490772, 0.18887966, 0.20683781, 0.18667293]), done=False),\n",
       " Experience(state=array([ 95.18982746, 296.70561236]), contact=array([0.35490772, 0.18887966, 0.20683781, 0.18667293]), action={'1': array([100, 500])}, reward=-438.6193921917939, next_state=array([ 99.41921582, 499.09892814]), next_contact=array([0.51757015, 0.53239049, 0.5730392 , 0.49298726]), done=False),\n",
       " Experience(state=array([ 99.41921582, 499.09892814]), contact=array([0.51757015, 0.53239049, 0.5730392 , 0.49298726]), action={'2': array([300, 500])}, reward=-311.73288920795636, next_state=array([298.56258382, 498.51687212]), next_contact=array([0.74558407, 0.74690346, 0.80240057, 0.74659992]), done=False),\n",
       " Experience(state=array([298.56258382, 498.51687212]), contact=array([0.74558407, 0.74690346, 0.80240057, 0.74659992]), action={'3': array([300, 300])}, reward=-423.09847508563234, next_state=array([299.04576901, 300.44396952]), next_contact=array([0.11867322, 0.26860166, 0.32383123, 0.2464514 ]), done=False),\n",
       " Experience(state=array([299.04576901, 300.44396952]), contact=array([0.11867322, 0.26860166, 0.32383123, 0.2464514 ]), action={'4': array([300, 200])}, reward=-253.700355208017, next_state=array([300.03721901, 199.82898961]), next_contact=array([0.52375482, 0.48531635, 0.56125375, 0.57296171]), done=False),\n",
       " Experience(state=array([300.03721901, 199.82898961]), contact=array([0.52375482, 0.48531635, 0.56125375, 0.57296171]), action={'5': array([300, 100])}, reward=-200.7098160117571, next_state=array([299.12984746,  99.21726581]), next_contact=array([0.79186119, 0.70643094, 0.62400517, 0.7122922 ]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.2653352 , 0.2446224 , 0.12016737, 0.18503147]), action={'0': array([100, 300])}, reward=-396.76463452246435, next_state=array([ 94.51168356, 294.47325224]), next_contact=array([0.54997653, 0.52268244, 0.48670071, 0.58974906]), done=False),\n",
       " Experience(state=array([ 94.51168356, 294.47325224]), contact=array([0.54997653, 0.52268244, 0.48670071, 0.58974906]), action={'1': array([100, 500])}, reward=-444.9078209385062, next_state=array([ 99.95169676, 499.65498115]), next_contact=array([0.58981051, 0.91060152, 0.70327759, 0.70864478]), done=False),\n",
       " Experience(state=array([ 99.95169676, 499.65498115]), contact=array([0.58981051, 0.91060152, 0.70327759, 0.70864478]), action={'2': array([300, 500])}, reward=-295.75686658930664, next_state=array([299.2775725 , 499.59308825]), next_contact=array([0.17139375, 0.32062961, 0.22508365, 0.2695592 ]), done=False),\n",
       " Experience(state=array([299.2775725 , 499.59308825]), contact=array([0.17139375, 0.32062961, 0.22508365, 0.2695592 ]), action={'3': array([300, 300])}, reward=-436.50542307311616, next_state=array([297.94392604, 299.68916947]), next_contact=array([0.57024699, 0.40049473, 0.36519741, 0.50470733]), done=False),\n",
       " Experience(state=array([297.94392604, 299.68916947]), contact=array([0.57024699, 0.40049473, 0.36519741, 0.50470733]), action={'4': array([300, 200])}, reward=-268.4765359309279, next_state=array([300.72550761, 200.87230965]), next_contact=array([0.56352073, 0.79332806, 0.87480161, 0.79977026]), done=False),\n",
       " Experience(state=array([300.72550761, 200.87230965]), contact=array([0.56352073, 0.79332806, 0.87480161, 0.79977026]), action={'5': array([300, 100])}, reward=-206.75263612393107, next_state=array([299.44977047,  98.56412118]), next_contact=array([0.22596877, 0.26852331, 0.310659  , 0.15441079]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.37574594, 0.53140354, 0.57432018, 0.50712234]), action={'0': array([100, 300])}, reward=-418.3892959881576, next_state=array([105.68134014, 304.50424417]), next_contact=array([0.72325987, 0.58227135, 0.79098491, 0.77989626]), done=False),\n",
       " Experience(state=array([105.68134014, 304.50424417]), contact=array([0.72325987, 0.58227135, 0.79098491, 0.77989626]), action={'1': array([100, 500])}, reward=-436.16386925576984, next_state=array([100.98464321, 499.90051815]), next_contact=array([0.29177897, 0.19647093, 0.29219808, 0.30044464]), done=False),\n",
       " Experience(state=array([100.98464321, 499.90051815]), contact=array([0.29177897, 0.19647093, 0.29219808, 0.30044464]), action={'2': array([300, 500])}, reward=-307.68428610519635, next_state=array([301.47497591, 500.20998723]), next_contact=array([0.55847628, 0.52928173, 0.35494761, 0.55476475]), done=False),\n",
       " Experience(state=array([301.47497591, 500.20998723]), contact=array([0.55847628, 0.52928173, 0.35494761, 0.55476475]), action={'3': array([300, 300])}, reward=-444.73697252032025, next_state=array([299.29144536, 300.61871575]), next_contact=array([0.73781672, 0.71788854, 0.67376779, 0.68581667]), done=False),\n",
       " Experience(state=array([299.29144536, 300.61871575]), contact=array([0.73781672, 0.71788854, 0.67376779, 0.68581667]), action={'4': array([300, 200])}, reward=-245.83183639735938, next_state=array([298.85876678, 199.4511153 ]), next_contact=array([0.36470188, 0.31661432, 0.31224873, 0.19424678]), done=False),\n",
       " Experience(state=array([298.85876678, 199.4511153 ]), contact=array([0.36470188, 0.31661432, 0.31224873, 0.19424678]), action={'5': array([300, 100])}, reward=-195.12471857254383, next_state=array([299.39891323,  98.69180379]), next_contact=array([0.5187674 , 0.61189386, 0.39366981, 0.43215889]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.64794565, 0.75545142, 0.86187846, 0.73798006]), action={'0': array([100, 300])}, reward=-416.80873214465515, next_state=array([104.23359059, 304.40242132]), next_contact=array([0.3076518 , 0.12116565, 0.19172715, 0.19653577]), done=False),\n",
       " Experience(state=array([104.23359059, 304.40242132]), contact=array([0.3076518 , 0.12116565, 0.19172715, 0.19653577]), action={'1': array([100, 500])}, reward=-435.89051784230605, next_state=array([ 99.24562567, 499.06867555]), next_contact=array([0.45338595, 0.46852587, 0.43256867, 0.47440591]), done=False),\n",
       " Experience(state=array([ 99.24562567, 499.06867555]), contact=array([0.45338595, 0.46852587, 0.43256867, 0.47440591]), action={'2': array([300, 500])}, reward=-312.2807696204689, next_state=array([299.23704124, 499.6386132 ]), next_contact=array([0.65511312, 0.75403747, 0.77414904, 0.79018383]), done=False),\n",
       " Experience(state=array([299.23704124, 499.6386132 ]), contact=array([0.65511312, 0.75403747, 0.77414904, 0.79018383]), action={'3': array([300, 300])}, reward=-435.96366678091414, next_state=array([297.95177473, 299.78338884]), next_contact=array([0.27652749, 0.26951702, 0.29111642, 0.31664253]), done=False),\n",
       " Experience(state=array([297.95177473, 299.78338884]), contact=array([0.27652749, 0.26951702, 0.29111642, 0.31664253]), action={'4': array([300, 200])}, reward=-261.0015676562078, next_state=array([299.66186152, 199.32857721]), next_contact=array([0.48048045, 0.51064407, 0.47183079, 0.60227904]), done=False),\n",
       " Experience(state=array([299.66186152, 199.32857721]), contact=array([0.48048045, 0.51064407, 0.47183079, 0.60227904]), action={'5': array([300, 100])}, reward=-207.44123130462614, next_state=array([301.31629675, 101.0067334 ]), next_contact=array([0.6724745 , 0.67455766, 0.70628286, 0.66999731]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.1995513 , 0.35935054, 0.31949773, 0.23379867]), action={'0': array([100, 300])}, reward=-428.51605310595676, next_state=array([109.12893406, 310.9848435 ]), next_contact=array([0.53911257, 0.43781133, 0.43678728, 0.4327094 ]), done=False),\n",
       " Experience(state=array([109.12893406, 310.9848435 ]), contact=array([0.53911257, 0.43781133, 0.43678728, 0.4327094 ]), action={'1': array([100, 500])}, reward=-448.627519666808, next_state=array([ 99.05884314, 501.97808028]), next_contact=array([0.65747761, 0.80776704, 0.70133839, 0.70354436]), done=False),\n",
       " Experience(state=array([ 99.05884314, 501.97808028]), contact=array([0.65747761, 0.80776704, 0.70133839, 0.70354436]), action={'2': array([300, 500])}, reward=-321.68510104262685, next_state=array([301.52514657, 501.04523956]), next_contact=array([0.23949605, 0.19026105, 0.36058233, 0.10432512]), done=False),\n",
       " Experience(state=array([301.52514657, 501.04523956]), contact=array([0.23949605, 0.19026105, 0.36058233, 0.10432512]), action={'3': array([300, 300])}, reward=-422.0096386697139, next_state=array([301.28893162, 299.33499505]), next_contact=array([0.57292977, 0.51679851, 0.49196733, 0.39189623]), done=False),\n",
       " Experience(state=array([301.28893162, 299.33499505]), contact=array([0.57292977, 0.51679851, 0.49196733, 0.39189623]), action={'4': array([300, 200])}, reward=-249.01858971326092, next_state=array([300.58427057, 199.07413558]), next_contact=array([0.80769491, 0.71162024, 0.74629097, 0.72108653]), done=False),\n",
       " Experience(state=array([300.58427057, 199.07413558]), contact=array([0.80769491, 0.71162024, 0.74629097, 0.72108653]), action={'5': array([300, 100])}, reward=-185.53825359658117, next_state=array([300.28304219, 100.08681175]), next_contact=array([0.31122999, 0.18841747, 0.24844817, 0.04145295]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.53808949, 0.40304334, 0.48659774, 0.55350149]), action={'0': array([100, 300])}, reward=-397.11161342521456, next_state=array([ 95.10945066, 294.21566054]), next_contact=array([0.8187253 , 0.66949666, 0.82167986, 0.80401857]), done=False),\n",
       " Experience(state=array([ 95.10945066, 294.21566054]), contact=array([0.8187253 , 0.66949666, 0.82167986, 0.80401857]), action={'1': array([100, 500])}, reward=-447.5768463154021, next_state=array([101.11674793, 500.15665253]), next_contact=array([0.16183279, 0.28547834, 0.27492552, 0.25660254]), done=False),\n",
       " Experience(state=array([101.11674793, 500.15665253]), contact=array([0.16183279, 0.28547834, 0.27492552, 0.25660254]), action={'2': array([300, 500])}, reward=-297.2239300590562, next_state=array([299.80869509, 500.24041159]), next_contact=array([0.43180642, 0.49726313, 0.54940841, 0.48098949]), done=False),\n",
       " Experience(state=array([299.80869509, 500.24041159]), contact=array([0.43180642, 0.49726313, 0.54940841, 0.48098949]), action={'3': array([300, 300])}, reward=-425.5832416446243, next_state=array([299.4347248 , 297.35584899]), next_contact=array([0.91838539, 0.80247897, 0.7623207 , 0.72278273]), done=False),\n",
       " Experience(state=array([299.4347248 , 297.35584899]), contact=array([0.91838539, 0.80247897, 0.7623207 , 0.72278273]), action={'4': array([300, 200])}, reward=-264.4925373882262, next_state=array([301.95286513, 199.61997399]), next_contact=array([0.2341397 , 0.1823759 , 0.34393682, 0.22903122]), done=False),\n",
       " Experience(state=array([301.95286513, 199.61997399]), contact=array([0.2341397 , 0.1823759 , 0.34393682, 0.22903122]), action={'5': array([300, 100])}, reward=-219.07621913208342, next_state=array([298.92545502, 101.09164909]), next_contact=array([0.5323529 , 0.45156848, 0.50390128, 0.48723916]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.71331777, 0.74826312, 0.79292768, 0.76764461]), action={'0': array([100, 300])}, reward=-398.8101564482975, next_state=array([ 97.23576082, 293.75458864]), next_contact=array([0.32444843, 0.15770493, 0.14767129, 0.23689627]), done=False),\n",
       " Experience(state=array([ 97.23576082, 293.75458864]), contact=array([0.32444843, 0.15770493, 0.14767129, 0.23689627]), action={'1': array([100, 500])}, reward=-429.46714266187956, next_state=array([ 98.9059309 , 498.65605258]), next_contact=array([0.4927418 , 0.5269377 , 0.4146886 , 0.51529169]), done=False),\n",
       " Experience(state=array([ 98.9059309 , 498.65605258]), contact=array([0.4927418 , 0.5269377 , 0.4146886 , 0.51529169]), action={'2': array([300, 500])}, reward=-307.6539463318747, next_state=array([299.86784563, 498.31148544]), next_contact=array([0.7274853 , 0.7290286 , 0.69706296, 0.7178938 ]), done=False),\n",
       " Experience(state=array([299.86784563, 498.31148544]), contact=array([0.7274853 , 0.7290286 , 0.69706296, 0.7178938 ]), action={'3': array([300, 300])}, reward=-444.29485967350104, next_state=array([297.52196113, 299.65421967]), next_contact=array([0.31347226, 0.23418048, 0.26865501, 0.28135648]), done=False),\n",
       " Experience(state=array([297.52196113, 299.65421967]), contact=array([0.31347226, 0.23418048, 0.26865501, 0.28135648]), action={'4': array([300, 200])}, reward=-273.3691291135347, next_state=array([300.84327159, 199.67988608]), next_contact=array([0.45568724, 0.51259731, 0.4006208 , 0.60390431]), done=False),\n",
       " Experience(state=array([300.84327159, 199.67988608]), contact=array([0.45568724, 0.51259731, 0.4006208 , 0.60390431]), action={'5': array([300, 100])}, reward=-195.4953767648169, next_state=array([300.26747703,  99.61429969]), next_contact=array([0.73977983, 0.60503858, 0.82202272, 0.68992736]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.19755765, 0.17531601, 0.30959933, 0.30638292]), action={'0': array([100, 300])}, reward=-397.32947701290004, next_state=array([ 93.76060702, 295.77809593]), next_contact=array([0.60151002, 0.45898943, 0.54671645, 0.53808783]), done=False),\n",
       " Experience(state=array([ 93.76060702, 295.77809593]), contact=array([0.60151002, 0.45898943, 0.54671645, 0.53808783]), action={'1': array([100, 500])}, reward=-445.23559113158893, next_state=array([ 99.5038436 , 500.04634585]), next_contact=array([0.71700436, 0.62980285, 0.7419217 , 0.73080042]), done=False),\n",
       " Experience(state=array([ 99.5038436 , 500.04634585]), contact=array([0.71700436, 0.62980285, 0.7419217 , 0.73080042]), action={'2': array([300, 500])}, reward=-322.39893333633773, next_state=array([299.98171344, 498.95101889]), next_contact=array([0.30681008, 0.21084316, 0.12322542, 0.30559822]), done=False),\n",
       " Experience(state=array([299.98171344, 498.95101889]), contact=array([0.30681008, 0.21084316, 0.12322542, 0.30559822]), action={'3': array([300, 300])}, reward=-416.1330813744071, next_state=array([300.11250687, 299.4326987 ]), next_contact=array([0.54912873, 0.44361069, 0.4156471 , 0.67294804]), done=False),\n",
       " Experience(state=array([300.11250687, 299.4326987 ]), contact=array([0.54912873, 0.44361069, 0.4156471 , 0.67294804]), action={'4': array([300, 200])}, reward=-251.89694713838762, next_state=array([301.02602434, 199.24115668]), next_contact=array([0.85843824, 0.84623769, 0.77886539, 0.69778947]), done=False),\n",
       " Experience(state=array([301.02602434, 199.24115668]), contact=array([0.85843824, 0.84623769, 0.77886539, 0.69778947]), action={'5': array([300, 100])}, reward=-182.08613686280626, next_state=array([301.07963701,  99.12299547]), next_contact=array([0.29378304, 0.21165846, 0.25993466, 0.18012473]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.47343289, 0.49314892, 0.32659592, 0.61747238]), action={'0': array([100, 300])}, reward=-418.242864991892, next_state=array([104.81164484, 305.23037966]), next_contact=array([0.76905668, 0.77313796, 0.69244287, 0.81066231]), done=False),\n",
       " Experience(state=array([104.81164484, 305.23037966]), contact=array([0.76905668, 0.77313796, 0.69244287, 0.81066231]), action={'1': array([100, 500])}, reward=-440.35368239205263, next_state=array([ 98.67214592, 500.2778718 ]), next_contact=array([0.22471565, 0.263366  , 0.24198837, 0.26449946]), done=False),\n",
       " Experience(state=array([ 98.67214592, 500.2778718 ]), contact=array([0.22471565, 0.263366  , 0.24198837, 0.26449946]), action={'2': array([300, 500])}, reward=-302.86802333507603, next_state=array([299.37058245, 500.48184494]), next_contact=array([0.339497  , 0.57795834, 0.68220678, 0.48568819]), done=False),\n",
       " Experience(state=array([299.37058245, 500.48184494]), contact=array([0.339497  , 0.57795834, 0.68220678, 0.48568819]), action={'3': array([300, 300])}, reward=-445.17684060586873, next_state=array([301.56780138, 300.65516875]), next_contact=array([0.64151882, 0.77025415, 0.72936125, 0.77190179]), done=False),\n",
       " Experience(state=array([301.56780138, 300.65516875]), contact=array([0.64151882, 0.77025415, 0.72936125, 0.77190179]), action={'4': array([300, 200])}, reward=-245.3496999275764, next_state=array([301.98715356, 199.83746114]), next_contact=array([0.20416399, 0.21012867, 0.30992069, 0.34607398]), done=False),\n",
       " Experience(state=array([301.98715356, 199.83746114]), contact=array([0.20416399, 0.21012867, 0.30992069, 0.34607398]), action={'5': array([300, 100])}, reward=-215.40172859421725, next_state=array([299.48642651, 101.06888043]), next_contact=array([0.49117753, 0.4325119 , 0.59773055, 0.45359065]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.79740678, 0.80845474, 0.83610159, 0.79634821]), action={'0': array([100, 300])}, reward=-400.4767380822454, next_state=array([ 96.48749569, 296.13675733]), next_contact=array([0.12214936, 0.24346661, 0.31432923, 0.25973213]), done=False),\n",
       " Experience(state=array([ 96.48749569, 296.13675733]), contact=array([0.12214936, 0.24346661, 0.31432923, 0.25973213]), action={'1': array([100, 500])}, reward=-443.8761368127373, next_state=array([101.24422588, 501.31887961]), next_contact=array([0.53678837, 0.31495976, 0.50944473, 0.35119771]), done=False),\n",
       " Experience(state=array([101.24422588, 501.31887961]), contact=array([0.53678837, 0.31495976, 0.50944473, 0.35119771]), action={'2': array([300, 500])}, reward=-338.23452743280694, next_state=array([301.02546019, 499.00470834]), next_contact=array([0.80784796, 0.73473423, 0.74726319, 0.80986327]), done=False),\n",
       " Experience(state=array([301.02546019, 499.00470834]), contact=array([0.80784796, 0.73473423, 0.74726319, 0.80986327]), action={'3': array([300, 300])}, reward=-443.92697458002056, next_state=array([298.78531767, 300.25059047]), next_contact=array([0.31742677, 0.28061232, 0.20023754, 0.23009058]), done=False),\n",
       " Experience(state=array([298.78531767, 300.25059047]), contact=array([0.31742677, 0.28061232, 0.20023754, 0.23009058]), action={'4': array([300, 200])}, reward=-248.13539435531456, next_state=array([299.33802192, 198.71037741]), next_contact=array([0.46157935, 0.47717801, 0.65306868, 0.47441089]), done=False),\n",
       " Experience(state=array([299.33802192, 198.71037741]), contact=array([0.46157935, 0.47717801, 0.65306868, 0.47441089]), action={'5': array([300, 100])}, reward=-189.62484994378678, next_state=array([299.66317324,  99.59275766]), next_contact=array([0.67874581, 0.81222343, 0.77149264, 0.81098284]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.1587456 , 0.28820876, 0.25681107, 0.17271121]), action={'0': array([100, 300])}, reward=-388.70452433662143, next_state=array([ 89.90692389, 291.17594311]), next_contact=array([0.52675824, 0.49074884, 0.38695253, 0.43749961]), done=False),\n",
       " Experience(state=array([ 89.90692389, 291.17594311]), contact=array([0.52675824, 0.49074884, 0.38695253, 0.43749961]), action={'1': array([100, 500])}, reward=-460.35255373005515, next_state=array([100.81793131, 499.38207046]), next_contact=array([0.80189007, 0.66754057, 0.79105963, 0.54139775]), done=False),\n",
       " Experience(state=array([100.81793131, 499.38207046]), contact=array([0.80189007, 0.66754057, 0.79105963, 0.54139775]), action={'2': array([300, 500])}, reward=-328.30688735803966, next_state=array([300.8070982 , 500.86092181]), next_contact=array([0.29502509, 0.12132129, 0.26644164, 0.16476347]), done=False),\n",
       " Experience(state=array([300.8070982 , 500.86092181]), contact=array([0.29502509, 0.12132129, 0.26644164, 0.16476347]), action={'3': array([300, 300])}, reward=-439.04882975898306, next_state=array([299.43509273, 299.10608512]), next_contact=array([0.54031659, 0.4563738 , 0.55620829, 0.42297318]), done=False),\n",
       " Experience(state=array([299.43509273, 299.10608512]), contact=array([0.54031659, 0.4563738 , 0.55620829, 0.42297318]), action={'4': array([300, 200])}, reward=-253.7252368924798, next_state=array([298.27249742, 200.01848122]), next_contact=array([0.84823054, 0.74820241, 0.86500173, 0.75721088]), done=False),\n",
       " Experience(state=array([298.27249742, 200.01848122]), contact=array([0.84823054, 0.74820241, 0.86500173, 0.75721088]), action={'5': array([300, 100])}, reward=-218.10003315598752, next_state=array([300.94898944,  99.0419778 ]), next_contact=array([0.35525774, 0.19373095, 0.20365465, 0.15909545]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.57276375, 0.45512201, 0.4698939 , 0.51289316]), action={'0': array([100, 300])}, reward=-428.2634569559338, next_state=array([109.92196149, 309.94417278]), next_contact=array([0.67357016, 0.7142943 , 0.80396854, 0.72653933]), done=False),\n",
       " Experience(state=array([109.92196149, 309.94417278]), contact=array([0.67357016, 0.7142943 , 0.80396854, 0.72653933]), action={'1': array([100, 500])}, reward=-443.8964914237794, next_state=array([100.77193967, 499.1688908 ]), next_contact=array([0.17252989, 0.22293254, 0.23467616, 0.24791552]), done=False),\n",
       " Experience(state=array([100.77193967, 499.1688908 ]), contact=array([0.17252989, 0.22293254, 0.23467616, 0.24791552]), action={'2': array([300, 500])}, reward=-328.08690342548425, next_state=array([300.68505705, 500.64050824]), next_contact=array([0.60559192, 0.52371269, 0.46001229, 0.4310124 ]), done=False),\n",
       " Experience(state=array([300.68505705, 500.64050824]), contact=array([0.60559192, 0.52371269, 0.46001229, 0.4310124 ]), action={'3': array([300, 300])}, reward=-434.54213101886387, next_state=array([299.68609075, 299.0201633 ]), next_contact=array([0.90576184, 0.73645114, 0.7067471 , 0.83621952]), done=False),\n",
       " Experience(state=array([299.68609075, 299.0201633 ]), contact=array([0.90576184, 0.73645114, 0.7067471 , 0.83621952]), action={'4': array([300, 200])}, reward=-259.6852710958536, next_state=array([301.38213125, 199.5831841 ]), next_contact=array([0.20694935, 0.12419236, 0.25418306, 0.22505182]), done=False),\n",
       " Experience(state=array([301.38213125, 199.5831841 ]), contact=array([0.20694935, 0.12419236, 0.25418306, 0.22505182]), action={'5': array([300, 100])}, reward=-181.91451532644422, next_state=array([301.43282931,  99.83452365]), next_contact=array([0.48669632, 0.51964512, 0.61547815, 0.31183833]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.79878497, 0.71026295, 0.86613072, 0.69895404]), action={'0': array([100, 300])}, reward=-419.14351227462697, next_state=array([105.09018335, 305.83482868]), next_contact=array([0.18821797, 0.25066505, 0.30327724, 0.24284491]), done=False),\n",
       " Experience(state=array([105.09018335, 305.83482868]), contact=array([0.18821797, 0.25066505, 0.30327724, 0.24284491]), action={'1': array([100, 500])}, reward=-432.4156470890671, next_state=array([101.72612139, 501.58635631]), next_contact=array([0.43691823, 0.61074151, 0.4773238 , 0.43620249]), done=False),\n",
       " Experience(state=array([101.72612139, 501.58635631]), contact=array([0.43691823, 0.61074151, 0.4773238 , 0.43620249]), action={'2': array([300, 500])}, reward=-332.4097415717082, next_state=array([301.27028553, 499.79823126]), next_contact=array([0.68312935, 0.65070237, 0.77445499, 0.7439764 ]), done=False),\n",
       " Experience(state=array([301.27028553, 499.79823126]), contact=array([0.68312935, 0.65070237, 0.77445499, 0.7439764 ]), action={'3': array([300, 300])}, reward=-444.040347023616, next_state=array([299.06462799, 301.06665939]), next_contact=array([0.30257589, 0.23619395, 0.21427499, 0.34523867]), done=False),\n",
       " Experience(state=array([299.06462799, 301.06665939]), contact=array([0.30257589, 0.23619395, 0.21427499, 0.34523867]), action={'4': array([300, 200])}, reward=-239.08145392197005, next_state=array([298.91487235, 200.11852558]), next_contact=array([0.57648217, 0.48216148, 0.4875461 , 0.41452844]), done=False),\n",
       " Experience(state=array([298.91487235, 200.11852558]), contact=array([0.57648217, 0.48216148, 0.4875461 , 0.41452844]), action={'5': array([300, 100])}, reward=-213.44032504752107, next_state=array([301.03344974,  99.54500964]), next_contact=array([0.76066852, 0.7398378 , 0.78908739, 0.74230332]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.31396448, 0.2362557 , 0.20448654, 0.21585796]), action={'0': array([100, 300])}, reward=-399.38512162043656, next_state=array([ 95.1395823, 296.4144585]), next_contact=array([0.42070562, 0.52799773, 0.55618396, 0.53933951]), done=False),\n",
       " Experience(state=array([ 95.1395823, 296.4144585]), contact=array([0.42070562, 0.52799773, 0.55618396, 0.53933951]), action={'1': array([100, 500])}, reward=-449.45307653018193, next_state=array([101.35652216, 502.43899504]), next_contact=array([0.73157751, 0.82066516, 0.67850059, 0.73998215]), done=False),\n",
       " Experience(state=array([101.35652216, 502.43899504]), contact=array([0.73157751, 0.82066516, 0.67850059, 0.73998215]), action={'2': array([300, 500])}, reward=-340.0282936661606, next_state=array([298.74167994, 499.70549385]), next_contact=array([0.25441159, 0.23235237, 0.1519266 , 0.23766081]), done=False),\n",
       " Experience(state=array([298.74167994, 499.70549385]), contact=array([0.25441159, 0.23235237, 0.1519266 , 0.23766081]), action={'3': array([300, 300])}, reward=-433.13786174740386, next_state=array([299.74478611, 299.31780558]), next_contact=array([0.48948424, 0.41245723, 0.52830708, 0.43139915]), done=False),\n",
       " Experience(state=array([299.74478611, 299.31780558]), contact=array([0.48948424, 0.41245723, 0.52830708, 0.43139915]), action={'4': array([300, 200])}, reward=-250.22247654314955, next_state=array([300.56612707, 199.53080218]), next_contact=array([0.74608216, 0.81111813, 0.74133058, 0.86588356]), done=False),\n",
       " Experience(state=array([300.56612707, 199.53080218]), contact=array([0.74608216, 0.81111813, 0.74133058, 0.86588356]), action={'5': array([300, 100])}, reward=-212.48026223024064, next_state=array([298.47596624,  99.53938387]), next_contact=array([0.23007165, 0.28959434, 0.16229135, 0.09311284]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.57708437, 0.52409913, 0.61643113, 0.61377226]), action={'0': array([100, 300])}, reward=-397.29876021959956, next_state=array([ 95.3637073 , 294.14488115]), next_contact=array([0.70180269, 0.65672689, 0.65070321, 0.76157596]), done=False),\n",
       " Experience(state=array([ 95.3637073 , 294.14488115]), contact=array([0.70180269, 0.65672689, 0.65070321, 0.76157596]), action={'1': array([100, 500])}, reward=-438.49120510033816, next_state=array([ 98.72232273, 500.02966151]), next_contact=array([0.29587739, 0.24741429, 0.17906519, 0.28769222]), done=False),\n",
       " Experience(state=array([ 98.72232273, 500.02966151]), contact=array([0.29587739, 0.24741429, 0.17906519, 0.28769222]), action={'2': array([300, 500])}, reward=-311.34037353813125, next_state=array([298.57663128, 499.47938477]), next_contact=array([0.42253892, 0.6215412 , 0.34402396, 0.40520923]), done=False),\n",
       " Experience(state=array([298.57663128, 499.47938477]), contact=array([0.42253892, 0.6215412 , 0.34402396, 0.40520923]), action={'3': array([300, 300])}, reward=-450.0398003192851, next_state=array([301.57853846, 300.76910281]), next_contact=array([0.8424109 , 0.77215531, 0.76576853, 0.7202696 ]), done=False),\n",
       " Experience(state=array([301.57853846, 300.76910281]), contact=array([0.8424109 , 0.77215531, 0.76576853, 0.7202696 ]), action={'4': array([300, 200])}, reward=-271.76916636889416, next_state=array([298.74087314, 199.40401029]), next_contact=array([0.32942445, 0.20776251, 0.12346739, 0.30873984]), done=False),\n",
       " Experience(state=array([298.74087314, 199.40401029]), contact=array([0.32942445, 0.20776251, 0.12346739, 0.30873984]), action={'5': array([300, 100])}, reward=-205.52322460600544, next_state=array([300.02446077,  97.80511891]), next_contact=array([0.48683014, 0.44217142, 0.62563837, 0.60566849]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.68332616, 0.6858498 , 0.70856136, 0.85432649]), action={'0': array([100, 300])}, reward=-427.64270979663064, next_state=array([108.96220768, 310.29535095]), next_contact=array([0.26539222, 0.13391307, 0.20511692, 0.31401738]), done=False),\n",
       " Experience(state=array([108.96220768, 310.29535095]), contact=array([0.26539222, 0.13391307, 0.20511692, 0.31401738]), action={'1': array([100, 500])}, reward=-447.2905770342803, next_state=array([ 99.09292414, 500.89353179]), next_contact=array([0.62244332, 0.49212871, 0.34824412, 0.45645609]), done=False),\n",
       " Experience(state=array([ 99.09292414, 500.89353179]), contact=array([0.62244332, 0.49212871, 0.34824412, 0.45645609]), action={'2': array([300, 500])}, reward=-310.9849920164142, next_state=array([298.43576865, 500.3474331 ]), next_contact=array([0.6693568 , 0.756877  , 0.87229201, 0.67947879]), done=False),\n",
       " Experience(state=array([298.43576865, 500.3474331 ]), contact=array([0.6693568 , 0.756877  , 0.87229201, 0.67947879]), action={'3': array([300, 300])}, reward=-433.6349318519845, next_state=array([299.39198345, 298.94417667]), next_contact=array([0.2525399 , 0.35722785, 0.22674252, 0.26412422]), done=False),\n",
       " Experience(state=array([299.39198345, 298.94417667]), contact=array([0.2525399 , 0.35722785, 0.22674252, 0.26412422]), action={'4': array([300, 200])}, reward=-261.5435641688581, next_state=array([301.41153618, 200.67144349]), next_contact=array([0.43248303, 0.35337177, 0.39762932, 0.56738015]), done=False),\n",
       " Experience(state=array([301.41153618, 200.67144349]), contact=array([0.43248303, 0.35337177, 0.39762932, 0.56738015]), action={'5': array([300, 100])}, reward=-212.10874905085672, next_state=array([299.60801795,  98.15702091]), next_contact=array([0.75398037, 0.67510704, 0.74173376, 0.83766584]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.22869434, 0.31146003, 0.18784373, 0.17529856]), action={'0': array([100, 300])}, reward=-431.09210538518374, next_state=array([110.88572426, 311.75359474]), next_contact=array([0.57796105, 0.58728663, 0.50492744, 0.46447118]), done=False),\n",
       " Experience(state=array([110.88572426, 311.75359474]), contact=array([0.57796105, 0.58728663, 0.50492744, 0.46447118]), action={'1': array([100, 500])}, reward=-445.40422712734903, next_state=array([ 99.50238973, 497.52096663]), next_contact=array([0.76169574, 0.72869524, 0.58921402, 0.91116618]), done=False),\n",
       " Experience(state=array([ 99.50238973, 497.52096663]), contact=array([0.76169574, 0.72869524, 0.58921402, 0.91116618]), action={'2': array([300, 500])}, reward=-337.1546460249807, next_state=array([299.33674216, 499.8531049 ]), next_contact=array([0.20471144, 0.22429445, 0.2944332 , 0.25240729]), done=False),\n",
       " Experience(state=array([299.33674216, 499.8531049 ]), contact=array([0.20471144, 0.22429445, 0.2944332 , 0.25240729]), action={'3': array([300, 300])}, reward=-435.86641112772816, next_state=array([300.56412468, 299.5080596 ]), next_contact=array([0.41398293, 0.50401597, 0.57934674, 0.44245024]), done=False),\n",
       " Experience(state=array([300.56412468, 299.5080596 ]), contact=array([0.41398293, 0.50401597, 0.57934674, 0.44245024]), action={'4': array([300, 200])}, reward=-249.3919169318095, next_state=array([299.84838794, 199.07604379]), next_contact=array([0.75154921, 0.72206767, 0.54302336, 0.88608979]), done=False),\n",
       " Experience(state=array([299.84838794, 199.07604379]), contact=array([0.75154921, 0.72206767, 0.54302336, 0.88608979]), action={'5': array([300, 100])}, reward=-179.08529906900677, next_state=array([299.83638301,  98.69183736]), next_contact=array([0.176408  , 0.26661635, 0.26199896, 0.45963051]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.57175214, 0.51509801, 0.41173698, 0.51049202]), action={'0': array([100, 300])}, reward=-397.95267356872426, next_state=array([ 95.24989775, 294.89978222]), next_contact=array([0.72836256, 0.66408334, 0.73948689, 0.74490455]), done=False),\n",
       " Experience(state=array([ 95.24989775, 294.89978222]), contact=array([0.72836256, 0.66408334, 0.73948689, 0.74490455]), action={'1': array([100, 500])}, reward=-441.6198148257352, next_state=array([ 99.29064535, 500.92791551]), next_contact=array([0.27646154, 0.36235182, 0.10510932, 0.22553779]), done=False),\n",
       " Experience(state=array([ 99.29064535, 500.92791551]), contact=array([0.27646154, 0.36235182, 0.10510932, 0.22553779]), action={'2': array([300, 500])}, reward=-305.6341290631483, next_state=array([300.63932432, 501.17928642]), next_contact=array([0.45782949, 0.49336665, 0.40525948, 0.40609088]), done=False),\n",
       " Experience(state=array([300.63932432, 501.17928642]), contact=array([0.45782949, 0.49336665, 0.40525948, 0.40609088]), action={'3': array([300, 300])}, reward=-432.7260136412966, next_state=array([299.75570703, 300.35424342]), next_contact=array([0.73083515, 0.75034134, 0.62865847, 0.76371991]), done=False),\n",
       " Experience(state=array([299.75570703, 300.35424342]), contact=array([0.73083515, 0.75034134, 0.62865847, 0.76371991]), action={'4': array([300, 200])}, reward=-268.3156043441462, next_state=array([302.38467331, 200.90867702]), next_contact=array([0.12796365, 0.27088695, 0.14615137, 0.325184  ]), done=False),\n",
       " Experience(state=array([302.38467331, 200.90867702]), contact=array([0.12796365, 0.27088695, 0.14615137, 0.325184  ]), action={'5': array([300, 100])}, reward=-223.89678932924662, next_state=array([298.93946734, 100.4563029 ]), next_contact=array([0.45096901, 0.52401387, 0.43167956, 0.51102014]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.80248216, 0.79790685, 0.71140245, 0.77543169]), action={'0': array([100, 300])}, reward=-397.35652726746184, next_state=array([ 93.77874887, 295.78647394]), next_contact=array([0.11061263, 0.17149088, 0.22778241, 0.22352429]), done=False),\n",
       " Experience(state=array([ 93.77874887, 295.78647394]), contact=array([0.11061263, 0.17149088, 0.22778241, 0.22352429]), action={'1': array([100, 500])}, reward=-450.94869636177333, next_state=array([101.50269884, 500.11563917]), next_contact=array([0.49867849, 0.55511869, 0.26902272, 0.52017314]), done=False),\n",
       " Experience(state=array([101.50269884, 500.11563917]), contact=array([0.49867849, 0.55511869, 0.26902272, 0.52017314]), action={'2': array([300, 500])}, reward=-297.89261914329774, next_state=array([299.52546938, 500.22064547]), next_contact=array([0.83443252, 0.79638525, 0.68527638, 0.73723938]), done=False),\n",
       " Experience(state=array([299.52546938, 500.22064547]), contact=array([0.83443252, 0.79638525, 0.68527638, 0.73723938]), action={'3': array([300, 300])}, reward=-424.8193788272412, next_state=array([299.01356259, 301.71399744]), next_contact=array([0.14365552, 0.24415034, 0.31362896, 0.21270889]), done=False),\n",
       " Experience(state=array([299.01356259, 301.71399744]), contact=array([0.14365552, 0.24415034, 0.31362896, 0.21270889]), action={'4': array([300, 200])}, reward=-242.8164451569435, next_state=array([298.79228429, 199.2602185 ]), next_contact=array([0.38933465, 0.4240695 , 0.45570582, 0.55442499]), done=False),\n",
       " Experience(state=array([298.79228429, 199.2602185 ]), contact=array([0.38933465, 0.4240695 , 0.45570582, 0.55442499]), action={'5': array([300, 100])}, reward=-210.51531037073832, next_state=array([300.76005715, 100.53364279]), next_contact=array([0.61826035, 0.66600312, 0.6876243 , 0.68562353]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.12588324, 0.23740911, 0.33042166, 0.27164307]), action={'0': array([100, 300])}, reward=-398.8345599866798, next_state=array([ 94.94173824, 296.07253626]), next_contact=array([0.55324512, 0.54276031, 0.53171139, 0.50876538]), done=False),\n",
       " Experience(state=array([ 94.94173824, 296.07253626]), contact=array([0.55324512, 0.54276031, 0.53171139, 0.50876538]), action={'1': array([100, 500])}, reward=-445.96825765998005, next_state=array([100.79323898, 500.37492444]), next_contact=array([0.86374728, 0.80876716, 0.81431126, 0.68257247]), done=False),\n",
       " Experience(state=array([100.79323898, 500.37492444]), contact=array([0.86374728, 0.80876716, 0.81431126, 0.68257247]), action={'2': array([300, 500])}, reward=-325.7049066464082, next_state=array([301.81956203, 501.5854301 ]), next_contact=array([0.21398986, 0.38890381, 0.24474857, 0.24730311]), done=False),\n",
       " Experience(state=array([301.81956203, 501.5854301 ]), contact=array([0.21398986, 0.38890381, 0.24474857, 0.24730311]), action={'3': array([300, 300])}, reward=-448.17693632663986, next_state=array([299.61744785, 298.63330447]), next_contact=array([0.53750682, 0.5635941 , 0.4447469 , 0.49122422]), done=False),\n",
       " Experience(state=array([299.61744785, 298.63330447]), contact=array([0.53750682, 0.5635941 , 0.4447469 , 0.49122422]), action={'4': array([300, 200])}, reward=-239.72000946375056, next_state=array([299.92281256, 200.31097595]), next_contact=array([0.83073309, 0.74217464, 0.8393472 , 0.71432705]), done=False),\n",
       " Experience(state=array([299.92281256, 200.31097595]), contact=array([0.83073309, 0.74217464, 0.8393472 , 0.71432705]), action={'5': array([300, 100])}, reward=-193.60930345566763, next_state=array([299.51945043,  98.77633733]), next_contact=array([0.12336894, 0.20720709, 0.21819712, 0.30788287]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.50601779, 0.51954177, 0.49109985, 0.41854703]), action={'0': array([100, 300])}, reward=-417.74320430985364, next_state=array([104.20418845, 305.34797264]), next_contact=array([0.77673973, 0.77012498, 0.79937386, 0.70455335]), done=False),\n",
       " Experience(state=array([104.20418845, 305.34797264]), contact=array([0.77673973, 0.77012498, 0.79937386, 0.70455335]), action={'1': array([100, 500])}, reward=-434.193341518973, next_state=array([ 99.45294379, 498.9241404 ]), next_contact=array([0.24921152, 0.18714961, 0.32818655, 0.2345776 ]), done=False),\n",
       " Experience(state=array([ 99.45294379, 498.9241404 ]), contact=array([0.24921152, 0.18714961, 0.32818655, 0.2345776 ]), action={'2': array([300, 500])}, reward=-312.5578915449044, next_state=array([299.7881148 , 499.48285779]), next_contact=array([0.5211246 , 0.45466516, 0.40063385, 0.60698106]), done=False),\n",
       " Experience(state=array([299.7881148 , 499.48285779]), contact=array([0.5211246 , 0.45466516, 0.40063385, 0.60698106]), action={'3': array([300, 300])}, reward=-424.4359398006082, next_state=array([299.23871564, 301.82955212]), next_contact=array([0.76181637, 0.75161493, 0.72352417, 0.87099273]), done=False),\n",
       " Experience(state=array([299.23871564, 301.82955212]), contact=array([0.76181637, 0.75161493, 0.72352417, 0.87099273]), action={'4': array([300, 200])}, reward=-243.0452044260859, next_state=array([299.50299609, 200.40058058]), next_contact=array([0.21206332, 0.22496927, 0.19955154, 0.19985571]), done=False),\n",
       " Experience(state=array([299.50299609, 200.40058058]), contact=array([0.21206332, 0.22496927, 0.19955154, 0.19985571]), action={'5': array([300, 100])}, reward=-199.85504058300216, next_state=array([298.60807707, 101.49060592]), next_contact=array([0.58315109, 0.47131566, 0.48979244, 0.3205953 ]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.73966643, 0.69731296, 0.66569696, 0.77738495]), action={'0': array([100, 300])}, reward=-429.50525963804455, next_state=array([109.88646936, 311.19711852]), next_contact=array([0.21465522, 0.27479707, 0.1499831 , 0.09933372]), done=False),\n",
       " Experience(state=array([109.88646936, 311.19711852]), contact=array([0.21465522, 0.27479707, 0.1499831 , 0.09933372]), action={'1': array([100, 500])}, reward=-449.28129554288716, next_state=array([ 98.89364831, 500.94989736]), next_contact=array([0.53936716, 0.41419288, 0.48313095, 0.45710385]), done=False),\n",
       " Experience(state=array([ 98.89364831, 500.94989736]), contact=array([0.53936716, 0.41419288, 0.48313095, 0.45710385]), action={'2': array([300, 500])}, reward=-320.3585267055854, next_state=array([300.5268938 , 500.03346453]), next_contact=array([0.68665162, 0.78011973, 0.87727441, 0.72386089]), done=False),\n",
       " Experience(state=array([300.5268938 , 500.03346453]), contact=array([0.68665162, 0.78011973, 0.87727441, 0.72386089]), action={'3': array([300, 300])}, reward=-428.3399860529031, next_state=array([299.81989356, 300.93480233]), next_contact=array([0.12871625, 0.1473046 , 0.34462913, 0.19065792]), done=False),\n",
       " Experience(state=array([299.81989356, 300.93480233]), contact=array([0.12871625, 0.1473046 , 0.34462913, 0.19065792]), action={'4': array([300, 200])}, reward=-247.3213559090304, next_state=array([300.30444517, 199.36872156]), next_contact=array([0.50179294, 0.50425119, 0.47816492, 0.54273048]), done=False),\n",
       " Experience(state=array([300.30444517, 199.36872156]), contact=array([0.50179294, 0.50425119, 0.47816492, 0.54273048]), action={'5': array([300, 100])}, reward=-202.31510643972305, next_state=array([301.39533812,  99.56361615]), next_contact=array([0.73805147, 0.78663229, 0.74420908, 0.76472054]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.24489153, 0.3903881 , 0.12790958, 0.16535464]), action={'0': array([100, 300])}, reward=-398.5453961448946, next_state=array([ 96.54384996, 294.18693057]), next_contact=array([0.56687565, 0.56837565, 0.49964087, 0.43478525]), done=False),\n",
       " Experience(state=array([ 96.54384996, 294.18693057]), contact=array([0.56687565, 0.56837565, 0.49964087, 0.43478525]), action={'1': array([100, 500])}, reward=-440.4003328533763, next_state=array([100.37593697, 500.00023398]), next_contact=array([0.862799  , 0.69897259, 0.71431298, 0.84917414]), done=False),\n",
       " Experience(state=array([100.37593697, 500.00023398]), contact=array([0.862799  , 0.69897259, 0.71431298, 0.84917414]), action={'2': array([300, 500])}, reward=-299.5416030703925, next_state=array([299.74757594, 499.87418166]), next_contact=array([0.38284298, 0.32664234, 0.32882888, 0.35202542]), done=False),\n",
       " Experience(state=array([299.74757594, 499.87418166]), contact=array([0.38284298, 0.32664234, 0.32882888, 0.35202542]), action={'3': array([300, 300])}, reward=-426.76991298623085, next_state=array([299.11918372, 301.11616383]), next_contact=array([0.26637348, 0.50829056, 0.53978742, 0.41802405]), done=False),\n",
       " Experience(state=array([299.11918372, 301.11616383]), contact=array([0.26637348, 0.50829056, 0.53978742, 0.41802405]), action={'4': array([300, 200])}, reward=-255.09739164233616, next_state=array([300.13318367, 199.61326578]), next_contact=array([0.58883201, 0.83668149, 0.79035751, 0.81079403]), done=False),\n",
       " Experience(state=array([300.13318367, 199.61326578]), contact=array([0.58883201, 0.83668149, 0.79035751, 0.81079403]), action={'5': array([300, 100])}, reward=-202.53773891664778, next_state=array([299.00388667, 100.35086237]), next_contact=array([0.26734041, 0.33341057, 0.28435071, 0.25431205]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.54288407, 0.50380247, 0.34850778, 0.46024147]), action={'0': array([100, 300])}, reward=-397.00089486417664, next_state=array([ 94.29504365, 294.92151994]), next_contact=array([0.82575105, 0.74143866, 0.75673144, 0.74057762]), done=False),\n",
       " Experience(state=array([ 94.29504365, 294.92151994]), contact=array([0.82575105, 0.74143866, 0.75673144, 0.74057762]), action={'1': array([100, 500])}, reward=-445.9947050849975, next_state=array([ 99.43251508, 501.57019928]), next_contact=array([0.28880336, 0.19098033, 0.30566001, 0.31568569]), done=False),\n",
       " Experience(state=array([ 99.43251508, 501.57019928]), contact=array([0.28880336, 0.19098033, 0.30566001, 0.31568569]), action={'2': array([300, 500])}, reward=-340.40087678308265, next_state=array([298.93242014, 498.88658634]), next_contact=array([0.39763027, 0.41166818, 0.38207111, 0.3906676 ]), done=False),\n",
       " Experience(state=array([298.93242014, 498.88658634]), contact=array([0.39763027, 0.41166818, 0.38207111, 0.3906676 ]), action={'3': array([300, 300])}, reward=-444.1996570200234, next_state=array([301.11503724, 299.07688263]), next_contact=array([0.682846  , 0.71757549, 0.67860104, 0.72739261]), done=False),\n",
       " Experience(state=array([301.11503724, 299.07688263]), contact=array([0.682846  , 0.71757549, 0.67860104, 0.72739261]), action={'4': array([300, 200])}, reward=-249.15592012903525, next_state=array([300.21382133, 201.51893078]), next_contact=array([0.29226012, 0.36607115, 0.25578761, 0.24592732]), done=False),\n",
       " Experience(state=array([300.21382133, 201.51893078]), contact=array([0.29226012, 0.36607115, 0.25578761, 0.24592732]), action={'5': array([300, 100])}, reward=-191.48030925117462, next_state=array([299.75196327, 100.21449889]), next_contact=array([0.46536857, 0.46610222, 0.4559957 , 0.51181294]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.80877999, 0.7498195 , 0.73656295, 0.6878706 ]), action={'0': array([100, 300])}, reward=-397.94201476787504, next_state=array([ 94.62771869, 295.51151148]), next_contact=array([0.27590687, 0.29730654, 0.25825309, 0.38668352]), done=False),\n",
       " Experience(state=array([ 94.62771869, 295.51151148]), contact=array([0.27590687, 0.29730654, 0.25825309, 0.38668352]), action={'1': array([100, 500])}, reward=-446.3661979148, next_state=array([100.7567496 , 499.74304359]), next_contact=array([0.52179595, 0.50376082, 0.42441609, 0.5260991 ]), done=False),\n",
       " Experience(state=array([100.7567496 , 499.74304359]), contact=array([0.52179595, 0.50376082, 0.42441609, 0.5260991 ]), action={'2': array([300, 500])}, reward=-331.67014286457714, next_state=array([300.90644726, 501.47404559]), next_contact=array([0.77871175, 0.73413943, 0.81392325, 0.63098129]), done=False),\n",
       " Experience(state=array([300.90644726, 501.47404559]), contact=array([0.77871175, 0.73413943, 0.81392325, 0.63098129]), action={'3': array([300, 300])}, reward=-430.4869139827166, next_state=array([300.24923122, 299.56000684]), next_contact=array([0.21496794, 0.16461225, 0.31102972, 0.3059832 ]), done=False),\n",
       " Experience(state=array([300.24923122, 299.56000684]), contact=array([0.21496794, 0.16461225, 0.31102972, 0.3059832 ]), action={'4': array([300, 200])}, reward=-236.89038853672795, next_state=array([300.08723852, 200.70272765]), next_contact=array([0.46770136, 0.4110171 , 0.50388031, 0.51612228]), done=False),\n",
       " Experience(state=array([300.08723852, 200.70272765]), contact=array([0.46770136, 0.4110171 , 0.50388031, 0.51612228]), action={'5': array([300, 100])}, reward=-207.8071958921845, next_state=array([301.48455764,  98.73012946]), next_contact=array([0.82928564, 0.63696333, 0.67644502, 0.70185575]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.16346465, 0.22537928, 0.26571637, 0.29965829]), action={'0': array([100, 300])}, reward=-398.33360495094877, next_state=array([ 95.6490271 , 294.87411501]), next_contact=array([0.53850808, 0.46930968, 0.34843018, 0.46918155]), done=False),\n",
       " Experience(state=array([ 95.6490271 , 294.87411501]), contact=array([0.53850808, 0.46930968, 0.34843018, 0.46918155]), action={'1': array([100, 500])}, reward=-439.25922825275984, next_state=array([ 99.38566551, 499.88444473]), next_contact=array([0.82480681, 0.65396804, 0.78806536, 0.62756201]), done=False),\n",
       " Experience(state=array([ 99.38566551, 499.88444473]), contact=array([0.82480681, 0.65396804, 0.78806536, 0.62756201]), action={'2': array([300, 500])}, reward=-312.45790186381276, next_state=array([300.41443375, 500.4056355 ]), next_contact=array([0.17986473, 0.33020723, 0.29272353, 0.2048295 ]), done=False),\n",
       " Experience(state=array([300.41443375, 500.4056355 ]), contact=array([0.17986473, 0.33020723, 0.29272353, 0.2048295 ]), action={'3': array([300, 300])}, reward=-415.67308928906755, next_state=array([300.3113023 , 301.13854611]), next_contact=array([0.45950368, 0.55245359, 0.47657964, 0.67424227]), done=False),\n",
       " Experience(state=array([300.3113023 , 301.13854611]), contact=array([0.45950368, 0.55245359, 0.47657964, 0.67424227]), action={'4': array([300, 200])}, reward=-248.62547346856206, next_state=array([299.67652241, 201.00539205]), next_contact=array([0.67747551, 0.75597197, 0.75270644, 0.6614642 ]), done=False),\n",
       " Experience(state=array([299.67652241, 201.00539205]), contact=array([0.67747551, 0.75597197, 0.75270644, 0.6614642 ]), action={'5': array([300, 100])}, reward=-187.30530793297908, next_state=array([299.51118088, 101.1864209 ]), next_contact=array([0.36714023, 0.21902467, 0.22660856, 0.30468894]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.46553318, 0.49350225, 0.52397923, 0.55146398]), action={'0': array([100, 300])}, reward=-399.76334847968496, next_state=array([ 95.89238616, 296.03246529]), next_contact=array([0.6646862 , 0.71158751, 0.79510587, 0.75412117]), done=False),\n",
       " Experience(state=array([ 95.89238616, 296.03246529]), contact=array([0.6646862 , 0.71158751, 0.79510587, 0.75412117]), action={'1': array([100, 500])}, reward=-443.1857660718289, next_state=array([100.72626256, 500.58176778]), next_contact=array([0.28325734, 0.16571993, 0.25651582, 0.37062823]), done=False),\n",
       " Experience(state=array([100.72626256, 500.58176778]), contact=array([0.28325734, 0.16571993, 0.25651582, 0.37062823]), action={'2': array([300, 500])}, reward=-299.6638942145875, next_state=array([299.70599278, 500.44930022]), next_contact=array([0.3428578 , 0.41606525, 0.50764802, 0.54665674]), done=False),\n",
       " Experience(state=array([299.70599278, 500.44930022]), contact=array([0.3428578 , 0.41606525, 0.50764802, 0.54665674]), action={'3': array([300, 300])}, reward=-442.18194293281374, next_state=array([301.47563215, 299.55468296]), next_contact=array([0.79137693, 0.60683602, 0.69375141, 0.6764146 ]), done=False),\n",
       " Experience(state=array([301.47563215, 299.55468296]), contact=array([0.79137693, 0.60683602, 0.69375141, 0.6764146 ]), action={'4': array([300, 200])}, reward=-249.30060401594974, next_state=array([300.61338749, 201.52975754]), next_contact=array([0.24428778, 0.29898578, 0.24323246, 0.14310033]), done=False),\n",
       " Experience(state=array([300.61338749, 201.52975754]), contact=array([0.24428778, 0.29898578, 0.24323246, 0.14310033]), action={'5': array([300, 100])}, reward=-190.67616784224538, next_state=array([300.85485551, 100.14544614]), next_contact=array([0.4874572 , 0.6002322 , 0.48031792, 0.50247996]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.797655  , 0.89135674, 0.69632269, 0.78432471]), action={'0': array([100, 300])}, reward=-428.61296980322464, next_state=array([110.65065274, 309.55814118]), next_contact=array([0.17828722, 0.25163904, 0.25656659, 0.19743713]), done=False),\n",
       " Experience(state=array([110.65065274, 309.55814118]), contact=array([0.17828722, 0.25163904, 0.25656659, 0.19743713]), action={'1': array([100, 500])}, reward=-443.0568193847882, next_state=array([101.67707803, 498.48547706]), next_contact=array([0.38360033, 0.41885043, 0.54754264, 0.43372065]), done=False),\n",
       " Experience(state=array([101.67707803, 498.48547706]), contact=array([0.38360033, 0.41885043, 0.54754264, 0.43372065]), action={'2': array([300, 500])}, reward=-344.3621321209901, next_state=array([301.55163105, 501.37141366]), next_contact=array([0.75215974, 0.72674622, 0.64936986, 0.81881229]), done=False),\n",
       " Experience(state=array([301.55163105, 501.37141366]), contact=array([0.75215974, 0.72674622, 0.64936986, 0.81881229]), action={'3': array([300, 300])}, reward=-427.776634959069, next_state=array([302.02219464, 298.89477772]), next_contact=array([0.31235949, 0.22006867, 0.21917091, 0.17300008]), done=False),\n",
       " Experience(state=array([302.02219464, 298.89477772]), contact=array([0.31235949, 0.22006867, 0.21917091, 0.17300008]), action={'4': array([300, 200])}, reward=-260.2477448961543, next_state=array([300.05570894, 201.52856545]), next_contact=array([0.64004265, 0.55617611, 0.56151601, 0.550948  ]), done=False),\n",
       " Experience(state=array([300.05570894, 201.52856545]), contact=array([0.64004265, 0.55617611, 0.56151601, 0.550948  ]), action={'5': array([300, 100])}, reward=-196.14962796807401, next_state=array([299.59197364,  98.83625985]), next_contact=array([0.84252158, 0.89077644, 0.65838916, 0.67285454]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.20739146, 0.30640089, 0.23804262, 0.34506611]), action={'0': array([100, 300])}, reward=-385.7452212718539, next_state=array([ 89.22611673, 288.95547275]), next_contact=array([0.43542984, 0.48701548, 0.53339462, 0.55292469]), done=False),\n",
       " Experience(state=array([ 89.22611673, 288.95547275]), contact=array([0.43542984, 0.48701548, 0.53339462, 0.55292469]), action={'1': array([100, 500])}, reward=-461.3522524047533, next_state=array([ 99.22822292, 500.68601518]), next_contact=array([0.8302482 , 0.73882473, 0.73984228, 0.79974582]), done=False),\n",
       " Experience(state=array([ 99.22822292, 500.68601518]), contact=array([0.8302482 , 0.73882473, 0.73984228, 0.79974582]), action={'2': array([300, 500])}, reward=-315.86939086098636, next_state=array([299.6610101 , 499.96175955]), next_contact=array([0.30302833, 0.32782411, 0.15531329, 0.15611193]), done=False),\n",
       " Experience(state=array([299.6610101 , 499.96175955]), contact=array([0.30302833, 0.32782411, 0.15531329, 0.15611193]), action={'3': array([300, 300])}, reward=-414.56510846886755, next_state=array([299.58294907, 300.47300382]), next_contact=array([0.37853475, 0.46675916, 0.44275608, 0.58611604]), done=False),\n",
       " Experience(state=array([299.58294907, 300.47300382]), contact=array([0.37853475, 0.46675916, 0.44275608, 0.58611604]), action={'4': array([300, 200])}, reward=-253.05450176385466, next_state=array([300.5219112 , 199.87210359]), next_contact=array([0.57075834, 0.72340685, 0.84958019, 0.72464738]), done=False),\n",
       " Experience(state=array([300.5219112 , 199.87210359]), contact=array([0.57075834, 0.72340685, 0.84958019, 0.72464738]), action={'5': array([300, 100])}, reward=-207.65435625106974, next_state=array([298.99231018,  99.57824903]), next_contact=array([0.24567373, 0.19924117, 0.21243834, 0.14248755]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.40953048, 0.48935987, 0.52733784, 0.4709979 ]), action={'0': array([100, 300])}, reward=-417.8795173849943, next_state=array([103.41004069, 306.27576066]), next_contact=array([0.75011795, 0.65113492, 0.83330765, 0.85594491]), done=False),\n",
       " Experience(state=array([103.41004069, 306.27576066]), contact=array([0.75011795, 0.65113492, 0.83330765, 0.85594491]), action={'1': array([100, 500])}, reward=-433.819424692733, next_state=array([ 99.06734129, 500.35170797]), next_contact=array([0.19422473, 0.38408906, 0.24007645, 0.15034242]), done=False),\n",
       " Experience(state=array([ 99.06734129, 500.35170797]), contact=array([0.19422473, 0.38408906, 0.24007645, 0.15034242]), action={'2': array([300, 500])}, reward=-307.26755919506235, next_state=array([300.65391721, 500.04978956]), next_contact=array([0.37108698, 0.55339897, 0.40922403, 0.53434735]), done=False),\n",
       " Experience(state=array([300.65391721, 500.04978956]), contact=array([0.37108698, 0.55339897, 0.40922403, 0.53434735]), action={'3': array([300, 300])}, reward=-419.3212098420053, next_state=array([300.88107745, 300.86820673]), next_contact=array([0.75459726, 0.82240288, 0.80022455, 0.70557606]), done=False),\n",
       " Experience(state=array([300.88107745, 300.86820673]), contact=array([0.75459726, 0.82240288, 0.80022455, 0.70557606]), action={'4': array([300, 200])}, reward=-244.17286071825305, next_state=array([300.4785012 , 201.05641367]), next_contact=array([0.34861403, 0.26929513, 0.23479865, 0.33658269]), done=False),\n",
       " Experience(state=array([300.4785012 , 201.05641367]), contact=array([0.34861403, 0.26929513, 0.23479865, 0.33658269]), action={'5': array([300, 100])}, reward=-195.8719940206535, next_state=array([299.70698096, 100.12300839]), next_contact=array([0.48138804, 0.48151622, 0.44850859, 0.54052617]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.70685697, 0.77788168, 0.83197596, 0.60185836]), action={'0': array([100, 300])}, reward=-398.2098128511488, next_state=array([ 94.52284278, 295.87893453]), next_contact=array([0.18519173, 0.15356488, 0.29408383, 0.33369519]), done=False),\n",
       " Experience(state=array([ 94.52284278, 295.87893453]), contact=array([0.18519173, 0.15356488, 0.29408383, 0.33369519]), action={'1': array([100, 500])}, reward=-441.9246376017611, next_state=array([ 99.68160132, 498.83146117]), next_contact=array([0.55818759, 0.46624789, 0.55307963, 0.67040145]), done=False),\n",
       " Experience(state=array([ 99.68160132, 498.83146117]), contact=array([0.55818759, 0.46624789, 0.55307963, 0.67040145]), action={'2': array([300, 500])}, reward=-303.9408020664872, next_state=array([299.6516835 , 498.59383032]), next_contact=array([0.6915374 , 0.65545504, 0.69786714, 0.71098957]), done=False),\n",
       " Experience(state=array([299.6516835 , 498.59383032]), contact=array([0.6915374 , 0.65545504, 0.69786714, 0.71098957]), action={'3': array([300, 300])}, reward=-432.8531411704224, next_state=array([300.77664792, 299.82029555]), next_contact=array([0.27674101, 0.34115222, 0.34587758, 0.25465127]), done=False),\n",
       " Experience(state=array([300.77664792, 299.82029555]), contact=array([0.27674101, 0.34115222, 0.34587758, 0.25465127]), action={'4': array([300, 200])}, reward=-265.9609521233553, next_state=array([298.37742547, 200.59483143]), next_contact=array([0.5773267 , 0.46335858, 0.49942681, 0.55260955]), done=False),\n",
       " Experience(state=array([298.37742547, 200.59483143]), contact=array([0.5773267 , 0.46335858, 0.49942681, 0.55260955]), action={'5': array([300, 100])}, reward=-185.33407752419353, next_state=array([298.47167585,  99.46203   ]), next_contact=array([0.72403077, 0.70880893, 0.77636426, 0.67660938]), done=False),\n",
       " Experience(state=[0, 0], contact=array([0.22859789, 0.25397012, 0.27292356, 0.33371055]), action={'0': array([100, 300])}, reward=-427.35401044979596, next_state=array([108.30976793, 310.66475212]), next_contact=array([0.44169007, 0.41223062, 0.50254869, 0.35944255]), done=False),\n",
       " Experience(state=array([108.30976793, 310.66475212]), contact=array([0.44169007, 0.41223062, 0.50254869, 0.35944255]), action={'1': array([100, 500])}, reward=-438.25664086216665, next_state=array([100.42404572, 497.9009534 ]), next_contact=array([0.84730828, 0.69881689, 0.65041535, 0.77530657]), done=False),\n",
       " Experience(state=array([100.42404572, 497.9009534 ]), contact=array([0.84730828, 0.69881689, 0.65041535, 0.77530657]), action={'2': array([300, 500])}, reward=-341.2217244373398, next_state=array([300.55927694, 500.53115006]), next_contact=array([0.29013142, 0.18956373, 0.34875904, 0.16763435]), done=False),\n",
       " Experience(state=array([300.55927694, 500.53115006]), contact=array([0.29013142, 0.18956373, 0.34875904, 0.16763435]), action={'3': array([300, 300])}, reward=-417.3373540203452, next_state=array([300.45030478, 299.4680713 ]), next_contact=array([0.51111516, 0.41471646, 0.3683614 , 0.48548526]), done=False),\n",
       " Experience(state=array([300.45030478, 299.4680713 ]), contact=array([0.51111516, 0.41471646, 0.3683614 , 0.48548526]), action={'4': array([300, 200])}, reward=-250.49703861025046, next_state=array([299.63698333, 199.32870133]), next_contact=array([0.7703268 , 0.85771516, 0.78266385, 0.80397012]), done=False),\n",
       " Experience(state=array([299.63698333, 199.32870133]), contact=array([0.7703268 , 0.85771516, 0.78266385, 0.80397012]), action={'5': array([300, 100])}, reward=-185.29491606606769, next_state=array([299.79103548, 100.64785152]), next_contact=array([0.21271375, 0.21913547, 0.36641121, 0.16472489]), done=False)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_tuple_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in exp_tuple_test:\n",
    "    if i[2].keys()[0] == '1':\n",
    "#         print(i[4])\n",
    "        plt.scatter(i[0][0],i[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = {'10':10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(action.keys()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
